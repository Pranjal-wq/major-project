
===== String Encryption =====

input\controlFlow.py: [0] -> * (XOR-encrypted string detected and decrypted)
input\controlFlow.py: [0] -> * (XOR-encrypted string detected and decrypted)
input\deadCode.py: [0] -> * (XOR-encrypted string detected and decrypted)
input\deadCode.py: [0] -> * (XOR-encrypted string detected and decrypted)
input\nameIdentifier.py: {1,3} -> +) (XOR-encrypted string detected and decrypted)
input\opaque_predicate.py: [4, 5] -> ./ (XOR-encrypted string detected and decrypted)
input\opaque_predicate.py: [0] -> * (XOR-encrypted string detected and decrypted)
input\opaque_predicate.py: [0] -> * (XOR-encrypted string detected and decrypted)



===== Identifier Cleaner =====

input\controlFlow.py: Skipped due to syntax error: invalid syntax. Perhaps you forgot a comma? (<unknown>, line 46)
input\deadCode.py: Skipped due to syntax error: invalid syntax. Perhaps you forgot a comma? (<unknown>, line 153)
input\junkcode.py: m1 -> var1 (Obfuscated identifier replaced (m1 → var1))
input\junkcode.py: m2 -> var2 (Obfuscated identifier replaced (m2 → var2))
input\junkcode.py: m1 -> var1 (Obfuscated identifier replaced (m1 → var1))
input\junkcode.py: m2 -> var2 (Obfuscated identifier replaced (m2 → var2))
input\junkcode.py: m1 -> var1 (Obfuscated identifier replaced (m1 → var1))
input\junkcode.py: m2 -> var2 (Obfuscated identifier replaced (m2 → var2))
input\junkcode.py: m1 -> var1 (Obfuscated identifier replaced (m1 → var1))
input\junkcode.py: m2 -> var2 (Obfuscated identifier replaced (m2 → var2))
input\junkcode.py: m1 -> var1 (Obfuscated identifier replaced (m1 → var1))
input\junkcode.py: m2 -> var2 (Obfuscated identifier replaced (m2 → var2))
input\junkcode.py: m1 -> var1 (Obfuscated identifier replaced (m1 → var1))
input\junkcode.py: m2 -> var2 (Obfuscated identifier replaced (m2 → var2))
input\nameIdentifier.py: Skipped due to syntax error: unmatched ')' (<unknown>, line 50)
input\opaque_predicate.py: Skipped due to syntax error: invalid syntax (<unknown>, line 100)



===== Control Flow =====

input\deadCode.py: if False:
    print("Dead branch")
 ->  (Unreachable branch (condition always False))
input\deadCode.py: if False: ...` blocks
      - replace `if True: body` with `body` (in-place)
      - record lines removed
    """
    def __init__(self):
        self.changes = []
 ->  (Unreachable branch (condition always False))
input\deadCode.py: if True:
    print("Always runs")
 -> print("Always runs")
 (Always-true condition simplified (kept body, removed if header))
input\deadCode.py: if True:
    print("Run")
 -> print("Run")
 (Always-true condition simplified (kept body, removed if header))
input\deadCode.py: if(false) { ... }` blocks ->  (Unreachable branch (condition always false))
input\deadCode.py: if(false) { ... } or if(false) statement; ->  (Unreachable branch (condition always false))
input\deadCode.py: if(false) removed (dead code)"}) ->  (Unreachable branch (condition always false))
input\deadCode.py: if(true) { ... }` with block contents (strip braces) -> { ... }` with block contents (strip braces) (Always-true condition simplified (kept statement/block, removed condition header))
input\deadCode.py: if(true) { block } => replace with block contents -> { block } => replace with block contents (Always-true condition simplified (kept statement/block, removed condition header))
input\deadCode.py: if(true) inlined (kept body)"}) ->  inlined (kept body)"}) (Always-true condition simplified (kept statement/block, removed condition header))



===== Dead Code =====

input\api_redirection.py: # analyzers/api_redirection.py
"""
Detect API redirection/wrapper patterns:
  - tiny wrappers that call another function and do nothing else
  - multiple-level wrappers
Cleaning: inline trivial wrappers (calls) conservatively.
"""

import re
from typing import List, Dict

def detect_api_redirection_clike(code: str) -> List[Dict]:
    findings = []
    # detect small wrapper function that only calls another function and returns its value
    # e.g., int wrapper() { return actual(); }
    for m in re.finditer(r'\b([A-Za-z_]\w*)\s*\((?:[^)]*)\)\s*\{\s*return\s+([A-Za-z_]\w*)\s*\(\s*\)\s*;\s*\}', code):
        findings.append({"type": "trivial_wrapper", "lineno": code[:m.start()].count("\n")+1, "wrapper": m.group(1), "target": m.group(2)})
    # wrapper that forwards single arg: return actual(a);
    for m in re.finditer(r'\b([A-Za-z_]\w*)\s*\(\s*([^\)]*)\)\s*\{\s*return\s+([A-Za-z_]\w*)\s*\(\s*\2\s*\)\s*;\s*\}', code):
        findings.append({"type": "arg_forwarding_wrapper", "lineno": code[:m.start()].count("\n")+1, "wrapper": m.group(1), "target": m.group(3)})
    return findings

def clean_api_redirection_clike(code: str) -> List[Dict]:
    changes = []
    s = code
    # Inline trivial wrappers: replace calls to wrapper() with actual()
    for m in re.finditer(r'\b([A-Za-z_]\w*)\s*\((?:\s*)\)\s*;\s*', s):
        # attempt to find wrapper definition
        call_name = m.group(1)
        # find def: return actual();
        mm = re.search(r'\b' + re.escape(call_name) + r'\s*\([^)]*\)\s*\{\s*return\s+([A-Za-z_]\w*)\s*\(\s*\)\s*;\s*\}', s)
        if mm:
            actual = mm.group(1)
            s_new = re.sub(r'\b' + re.escape(call_name) + r'\s*\(\s*\)', actual + '()', s)
            if s_new != s:
                changes.append({"original": call_name + "()", "cleaned": actual + "()", "reason": f"Inlined trivial wrapper {call_name} -> {actual}"})
                s = s_new
    if changes:
        changes.append({"original": code, "cleaned": s, "reason": "Inlined trivial API wrappers (C-like)"})
    else:
        findings = detect_api_redirection_clike(code)
        if findings:
            changes.append({"original": "", "cleaned": "", "reason": f"Detected wrapper patterns but no safe automatic inlining performed: {findings}"})
    return changes

def detect_api_redirection_python(code: str) -> List[Dict]:
    findings = []
    # def wrapper(): return actual()
    for m in re.finditer(r'def\s+([A-Za-z_]\w*)\s*\([^)]*\)\s*:\s*return\s+([A-Za-z_]\w*)\s*\(\s*\)\s*', code):
        findings.append({"type": "trivial_wrapper_py", "lineno": code[:m.start()].count("\n")+1, "wrapper": m.group(1), "target": m.group(2)})
    return findings

def clean_api_redirection_python(code: str) -> List[Dict]:
    s = code
    changes = []
    # inline trivial wrappers by replacing calls
    for m in re.finditer(r'def\s+([A-Za-z_]\w*)\s*\([^)]*\)\s*:\s*return\s+([A-Za-z_]\w*)\s*\(\s*\)\s*', s):
        wrapper = m.group(1); target = m.group(2)
        # replace calls wrapper() with target()
        s_new = re.sub(r'\b' + re.escape(wrapper) + r'\s*\(\s*\)', target + '()', s)
        if s_new != s:
            changes.append({"original": wrapper + "() calls", "cleaned": target + "()", "reason": f"Inlined trivial wrapper {wrapper} -> {target}"})
            s = s_new
    if changes:
        changes.append({"original": code, "cleaned": s, "reason": "Inlined trivial wrappers (Python)"})
    else:
        finds = detect_api_redirection_python(code)
        if finds:
            changes.append({"original": "", "cleaned": "", "reason": f"Detected wrappers: {finds}. No automatic inlining applied."})
    return changes
 -> """
Detect API redirection/wrapper patterns:
  - tiny wrappers that call another function and do nothing else
  - multiple-level wrappers
Cleaning: inline trivial wrappers (calls) conservatively.
"""
import re
from typing import List, Dict

def detect_api_redirection_clike(code: str) -> List[Dict]:
    findings = []
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*\\((?:[^)]*)\\)\\s*\\{\\s*return\\s+([A-Za-z_]\\w*)\\s*\\(\\s*\\)\\s*;\\s*\\}', code):
        findings.append({'type': 'trivial_wrapper', 'lineno': code[:m.start()].count('\n') + 1, 'wrapper': m.group(1), 'target': m.group(2)})
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*\\(\\s*([^\\)]*)\\)\\s*\\{\\s*return\\s+([A-Za-z_]\\w*)\\s*\\(\\s*\\2\\s*\\)\\s*;\\s*\\}', code):
        findings.append({'type': 'arg_forwarding_wrapper', 'lineno': code[:m.start()].count('\n') + 1, 'wrapper': m.group(1), 'target': m.group(3)})
    return findings

def clean_api_redirection_clike(code: str) -> List[Dict]:
    changes = []
    s = code
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*\\((?:\\s*)\\)\\s*;\\s*', s):
        call_name = m.group(1)
        mm = re.search('\\b' + re.escape(call_name) + '\\s*\\([^)]*\\)\\s*\\{\\s*return\\s+([A-Za-z_]\\w*)\\s*\\(\\s*\\)\\s*;\\s*\\}', s)
        if mm:
            actual = mm.group(1)
            s_new = re.sub('\\b' + re.escape(call_name) + '\\s*\\(\\s*\\)', actual + '()', s)
            if s_new != s:
                changes.append({'original': call_name + '()', 'cleaned': actual + '()', 'reason': f'Inlined trivial wrapper {call_name} -> {actual}'})
                s = s_new
    if changes:
        changes.append({'original': code, 'cleaned': s, 'reason': 'Inlined trivial API wrappers (C-like)'})
    else:
        findings = detect_api_redirection_clike(code)
        if findings:
            changes.append({'original': '', 'cleaned': '', 'reason': f'Detected wrapper patterns but no safe automatic inlining performed: {findings}'})
    return changes

def detect_api_redirection_python(code: str) -> List[Dict]:
    findings = []
    for m in re.finditer('def\\s+([A-Za-z_]\\w*)\\s*\\([^)]*\\)\\s*:\\s*return\\s+([A-Za-z_]\\w*)\\s*\\(\\s*\\)\\s*', code):
        findings.append({'type': 'trivial_wrapper_py', 'lineno': code[:m.start()].count('\n') + 1, 'wrapper': m.group(1), 'target': m.group(2)})
    return findings

def clean_api_redirection_python(code: str) -> List[Dict]:
    s = code
    changes = []
    for m in re.finditer('def\\s+([A-Za-z_]\\w*)\\s*\\([^)]*\\)\\s*:\\s*return\\s+([A-Za-z_]\\w*)\\s*\\(\\s*\\)\\s*', s):
        wrapper = m.group(1)
        target = m.group(2)
        s_new = re.sub('\\b' + re.escape(wrapper) + '\\s*\\(\\s*\\)', target + '()', s)
        if s_new != s:
            changes.append({'original': wrapper + '() calls', 'cleaned': target + '()', 'reason': f'Inlined trivial wrapper {wrapper} -> {target}'})
            s = s_new
    if changes:
        changes.append({'original': code, 'cleaned': s, 'reason': 'Inlined trivial wrappers (Python)'})
    else:
        finds = detect_api_redirection_python(code)
        if finds:
            changes.append({'original': '', 'cleaned': '', 'reason': f'Detected wrappers: {finds}. No automatic inlining applied.'})
    return changes (Full cleaned file (Python deadcode removal))
input\controlFlow.py: # -------------------- controlflow.py --------------------
import re
from typing import List, Dict, Tuple

class FakeConditionCleaner:
    """
    Detect and clean fake/unreachable conditions from source code.
    Reports detailed mapping of:
        - original (obfuscated) code snippet
        - cleaned (deobfuscated) snippet
        - reason for change
    """

    def __init__(self):
        # Patterns for fake conditions
        self.python_patterns = [
            (re.compile(r'if\s+False\s*:\s*', re.IGNORECASE), "Unreachable branch (condition always False)"),
            (re.compile(r'if\s+True\s*:\s*', re.IGNORECASE), "Always-true condition simplified (kept body, removed if header)"),
            (re.compile(r'if\s+[^\n]*>\s*\d+\s+and\s+[^\n]*<\s*\d+\s*:\s*', re.IGNORECASE),
             "Contradictory numeric range in condition (impossible)")
        ]

        self.c_like_patterns = [
            (re.compile(r'if\s*\(\s*(false|0)\s*\)', re.IGNORECASE), "Unreachable branch (condition always false)"),
            (re.compile(r'if\s*\(\s*(true|1)\s*\)', re.IGNORECASE), "Always-true condition simplified (kept statement/block, removed condition header)"),
            (re.compile(r'if\s*\([^)]*>\s*\d+\s*&&\s*[^)]*<\s*\d+\)', re.IGNORECASE),
             "Contradictory numeric range in condition (impossible)")
        ]

    # ---------- Python helper ----------
    def _extract_python_if_block(self, code: str, match_start: int) -> Tuple[str, str]:
        header_end = code.find('\n', match_start)
        if header_end == -1:
            return code[match_start:], code[:match_start]

        header = code[match_start:header_end+1]
        body_start = header_end + 1
        end = body_start
        while True:
            if end >= len(code):
                break
            nl = code.find('\n', end)
            if nl == -1:
                nl = len(code)
            line = code[end:nl]
            if not line or not (line"*" == ' ' or line"*" == '\t'):
                break
            end = nl + 1
        removed = code[match_start:end]
        new_code = code[:match_start] + code[end:]
        return removed, new_code

    def _dedent_python_body(self, body_text: str) -> str:
        lines = body_text.splitlines()
        indents = [len(re.match(r'^[ \t]+', ln).group(0)) for ln in lines if ln.strip() and re.match(r'^[ \t]+', ln)]
        if not indents:
            return "\n".join(lines) + ("\n" if body_text.endswith("\n") else "")
        min_indent = min(indents)
        dedented_lines = [ln[min_indent:] if len(ln) >= min_indent else ln for ln in lines]
        return "\n".join(dedented_lines) + ("\n" if body_text.endswith("\n") else "")

    # ---------- C-like helper ----------
    def _extract_c_like_block_or_line(self, code: str, start_idx: int) -> Tuple[str, str]:
        i = start_idx
        while i < len(code) and code[i].isspace():
            i += 1
        if i < len(code) and code[i] == '{':
            stack = ['{']
            end = i + 1
            while stack and end < len(code):
                if code[end] == '{': stack.append('{')
                elif code[end] == '}': stack.pop()
                end += 1
            removed = code[start_idx:end]
            return removed, code[:start_idx] + code[end:]
        else:
            end = i
            while end < len(code) and code[end] not in (';', '\n'):
                end += 1
            if end < len(code) and code[end] == ';': end += 1
            removed = code[start_idx:end]
            return removed, code[:start_idx] + code[end:]

    # ---------- Detection ----------
    def detect_fake_conditions(self, code: str) -> List[Dict]:
        findings = []

        # Python
        for pat, reason in self.python_patterns:
            for m in pat.finditer(code):
                findings.append({"condition": m.group(0), "position": m.start(), "reason": reason})

        # C-like
        for pat, reason in self.c_like_patterns:
            for m in pat.finditer(code):
                findings.append({"condition": m.group(0), "position": m.start(), "reason": reason})

        return findings

    # ---------- Cleaning ----------
    def clean_code(self, code: str) -> List[Dict]:
        """
        Returns a list of changes:
        [
            {"original": ..., "cleaned": ..., "reason": ...},
            ...
        ]
        """
        changes = []
        cleaned_code = code

        # Python patterns
        for pat, reason in self.python_patterns:
            while True:
                m = pat.search(cleaned_code)
                if not m: break
                start = m.start()
                removed, cleaned_code = self._extract_python_if_block(cleaned_code, start)
                if "True" in m.group(0):
                    header_end = removed.find('\n')
                    body = removed[header_end+1:] if header_end != -1 else ""
                    dedented_body = self._dedent_python_body(body)
                    cleaned_code = cleaned_code[:start] + dedented_body + cleaned_code[start:]
                    changes.append({"original": removed, "cleaned": dedented_body, "reason": reason})
                else:
                    changes.append({"original": removed, "cleaned": "", "reason": reason})

        # C-like patterns
        for pat, reason in self.c_like_patterns:
            while True:
                m = pat.search(cleaned_code)
                if not m: break
                start = m.start()
                removed, cleaned_code = self._extract_c_like_block_or_line(cleaned_code, start)
                if "true" in m.group(0).lower() or "1" in m.group(0):
                    # Keep block/statement only
                    if '{' in removed:
                        block_start = removed.find('{')
                        block = removed[block_start:]
                        cleaned_code = cleaned_code[:start] + block + cleaned_code[start:]
                        changes.append({"original": removed, "cleaned": block, "reason": reason})
                    else:
                        # single statement
                        stmt = removed[m.end()-start:]
                        cleaned_code = cleaned_code[:start] + stmt + cleaned_code[start:]
                        changes.append({"original": removed, "cleaned": stmt, "reason": reason})
                else:
                    changes.append({"original": removed, "cleaned": "", "reason": reason})

        return changes -> # -------------------- controlflow.py --------------------
import re
from typing import List, Dict, Tuple

class FakeConditionCleaner:
    """
    Detect and clean fake/unreachable conditions from source code.
    Reports detailed mapping of:
        - original (obfuscated) code snippet
        - cleaned (deobfuscated) snippet
        - reason for change
    """

    def __init__(self):
        # Patterns for fake conditions
        self.python_patterns = [
            (re.compile(r'if\s+False\s*:\s*', re.IGNORECASE), "Unreachable branch (condition always False)"),
            (re.compile(r'if\s+True\s*:\s*', re.IGNORECASE), "Always-true condition simplified (kept body, removed if header)"),
            (re.compile(r'if\s+[^\n]*>\s*\d+\s+and\s+[^\n]*<\s*\d+\s*:\s*', re.IGNORECASE),
             "Contradictory numeric range in condition (impossible)")
        ]

        self.c_like_patterns = [
            (re.compile(r'if\s*\(\s*(false|0)\s*\)', re.IGNORECASE), "Unreachable branch (condition always false)"),
            (re.compile(r'if\s*\(\s*(true|1)\s*\)', re.IGNORECASE), "Always-true condition simplified (kept statement/block, removed condition header)"),
            (re.compile(r'if\s*\([^)]*>\s*\d+\s*&&\s*[^)]*<\s*\d+\)', re.IGNORECASE),
             "Contradictory numeric range in condition (impossible)")
        ]

    # ---------- Python helper ----------
    def _extract_python_if_block(self, code: str, match_start: int) -> Tuple[str, str]:
        header_end = code.find('\n', match_start)
        if header_end == -1:
            return code[match_start:], code[:match_start]

        header = code[match_start:header_end+1]
        body_start = header_end + 1
        end = body_start
        while True:
            if end >= len(code):
                break
            nl = code.find('\n', end)
            if nl == -1:
                nl = len(code)
            line = code[end:nl]
            if not line or not (line"*" == ' ' or line"*" == '\t'):
                break
            end = nl + 1
        removed = code[match_start:end]
        new_code = code[:match_start] + code[end:]
        return removed, new_code

    def _dedent_python_body(self, body_text: str) -> str:
        lines = body_text.splitlines()
        indents = [len(re.match(r'^[ \t]+', ln).group(0)) for ln in lines if ln.strip() and re.match(r'^[ \t]+', ln)]
        if not indents:
            return "\n".join(lines) + ("\n" if body_text.endswith("\n") else "")
        min_indent = min(indents)
        dedented_lines = [ln[min_indent:] if len(ln) >= min_indent else ln for ln in lines]
        return "\n".join(dedented_lines) + ("\n" if body_text.endswith("\n") else "")

    # ---------- C-like helper ----------
    def _extract_c_like_block_or_line(self, code: str, start_idx: int) -> Tuple[str, str]:
        i = start_idx
        while i < len(code) and code[i].isspace():
            i += 1
        if i < len(code) and code[i] == '{':
            stack = ['{']
            end = i + 1
            while stack and end < len(code):
                if code[end] == '{': stack.append('{')
                elif code[end] == '}': stack.pop()
                end += 1
            removed = code[start_idx:end]
            return removed, code[:start_idx] + code[end:]
        else:
            end = i
            while end < len(code) and code[end] not in (';', '\n'):
                end += 1
            if end < len(code) and code[end] == ';': end += 1
            removed = code[start_idx:end]
            return removed, code[:start_idx] + code[end:]

    # ---------- Detection ----------
    def detect_fake_conditions(self, code: str) -> List[Dict]:
        findings = []

        # Python
        for pat, reason in self.python_patterns:
            for m in pat.finditer(code):
                findings.append({"condition": m.group(0), "position": m.start(), "reason": reason})

        # C-like
        for pat, reason in self.c_like_patterns:
            for m in pat.finditer(code):
                findings.append({"condition": m.group(0), "position": m.start(), "reason": reason})

        return findings

    # ---------- Cleaning ----------
    def clean_code(self, code: str) -> List[Dict]:
        """
        Returns a list of changes:
        [
            {"original": ..., "cleaned": ..., "reason": ...},
            ...
        ]
        """
        changes = []
        cleaned_code = code

        # Python patterns
        for pat, reason in self.python_patterns:
            while True:
                m = pat.search(cleaned_code)
                if not m: break
                start = m.start()
                removed, cleaned_code = self._extract_python_if_block(cleaned_code, start)
                if "True" in m.group(0):
                    header_end = removed.find('\n')
                    body = removed[header_end+1:] if header_end != -1 else ""
                    dedented_body = self._dedent_python_body(body)
                    cleaned_code = cleaned_code[:start] + dedented_body + cleaned_code[start:]
                    changes.append({"original": removed, "cleaned": dedented_body, "reason": reason})
                else:
                    changes.append({"original": removed, "cleaned": "", "reason": reason})

        # C-like patterns
        for pat, reason in self.c_like_patterns:
            while True:
                m = pat.search(cleaned_code)
                if not m: break
                start = m.start()
                removed, cleaned_code = self._extract_c_like_block_or_line(cleaned_code, start)
                if "true" in m.group(0).lower() or "1" in m.group(0):
                    # Keep block/statement only
                    if '{' in removed:
                        block_start = removed.find('{')
                        block = removed[block_start:]
                        cleaned_code = cleaned_code[:start] + block + cleaned_code[start:]
                        changes.append({"original": removed, "cleaned": block, "reason": reason})
                    else:
                        # single statement
                        stmt = removed[m.end()-start:]
                        cleaned_code = cleaned_code[:start] + stmt + cleaned_code[start:]
                        changes.append({"original": removed, "cleaned": stmt, "reason": reason})
                else:
                    changes.append({"original": removed, "cleaned": "", "reason": reason})

        return changes (parse_error: invalid syntax. Perhaps you forgot a comma? (<unknown>, line 46))
input\controlflow_flattening.py: # analyzers/controlflow_flattening.py
"""
Detect/control-flow flattening patterns (dispatcher loops, state-machine switch inside loop).
Conservative detection + optional simple unflatten attempt (only for tiny patterns).
"""

import re
import ast
from typing import List, Dict

def detect_controlflow_flattening_clike(code: str) -> List[Dict]:
    findings = []
    # Very common flattening pattern: state variable + while/switch inside
    pattern = re.compile(r'\bwhile\s*\(\s*(?:1|true)\s*\)\s*\{.*?\b(switch|if)\s*\s*\([^)]*\)\s*\{', re.IGNORECASE | re.DOTALL)
    if pattern.search(code):
        findings.append({"type": "dispatcher_loop", "reason": "while(true)/switch dispatcher pattern", "hint": "control-flow flattening (C-like)"})
    # state variable updates: look for `state = <const>` inside switch cases
    if re.search(r'\bstate\s*=\s*\d+\s*;', code):
        findings.append({"type": "state_var", "reason": "state variable updated inside loop", "hint": "possible flattened flow"})
    return findings

def clean_controlflow_flattening_clike(code: str) -> List[Dict]:
    """
    Conservative: we will not attempt full de-flattening.
    Instead, we:
      - detect small dispatcher with 2-3 cases and produce a suggested straight-line replacement as text,
        but do not modify code automatically unless pattern exactly matches a simple form.
    Returns list of change dicts; last item contains full cleaned placeholder if applied.
    """
    changes = []
    # match a simple dispatcher with two cases that assign/accumulate to result and exit
    m = re.search(r'while\s*\(\s*(?:1|true)\s*\)\s*\{\s*switch\s*\(\s*state\s*\)\s*\{\s*(case\s*1\s*:\s*([^}]*)break\s*;)\s*(case\s*2\s*:\s*([^}]*)break\s*;)\s*\}\s*\}', code, re.DOTALL | re.IGNORECASE)
    if m:
        case1 = m.group(2).strip()
        case2 = m.group(4).strip()
        # attempt to extract simple assignments that produce pieces of result
        # produce a suggested deobfuscated snippet
        suggested = "// Suggested deobfuscated sequence\n" + "/* case1 */\n" + case1 + "\n/* case2 */\n" + case2 + "\n"
        changes.append({"original": m.group(0), "cleaned": suggested, "reason": "Simple dispatcher unflattened into sequential suggestions"})
        # produce cleaned file placeholder (conservative)
        cleaned = code[:m.start()] + suggested + code[m.end():]
        changes.append({"original": code, "cleaned": cleaned, "reason": "Applied small-scope unflatten (C-like) - manual review required"})
    else:
        # no safe automatic transform; only report detection
        if detect_controlflow_flattening_clike(code):
            changes.append({"original": "", "cleaned": "", "reason": "Detected control-flow flattening patterns, no automatic rewrite performed (too risky)."})
    return changes

def detect_controlflow_flattening_python(code: str) -> List[Dict]:
    # Python rarely uses switch; detect weird while True + dict dispatch / state var patterns
    findings = []
    if re.search(r'while\s+True\s*:\s*', code):
        # look for dict dispatch / if chain inside loop
        if re.search(r'\b(state|mode)\b', code) and re.search(r'\bif\b.*\belse\b', code, re.DOTALL):
            findings.append({"type": "dispatcher_loop_py", "reason": "while True with state/if-dispatch found"})
    # dict-based dispatcher: table = {0: lambda: ..., 1: lambda: ...}; table[state]()
    if re.search(r'\{.*lambda.*:.*\}', code, re.DOTALL):
        findings.append({"type": "dict_dispatch", "reason": "dictionary-based dispatcher (python)"})
    return findings

def clean_controlflow_flattening_python(code: str) -> List[Dict]:
    # No safe fully automated de-flattening. Provide hints only.
    findings = detect_controlflow_flattening_python(code)
    if findings:
        return [{"original": "", "cleaned": "", "reason": "Detected Python flattened control-flow patterns. Manual reconstruction recommended."}]
    return []
 -> """
Detect/control-flow flattening patterns (dispatcher loops, state-machine switch inside loop).
Conservative detection + optional simple unflatten attempt (only for tiny patterns).
"""
import re
import ast
from typing import List, Dict

def detect_controlflow_flattening_clike(code: str) -> List[Dict]:
    findings = []
    pattern = re.compile('\\bwhile\\s*\\(\\s*(?:1|true)\\s*\\)\\s*\\{.*?\\b(switch|if)\\s*\\s*\\([^)]*\\)\\s*\\{', re.IGNORECASE | re.DOTALL)
    if pattern.search(code):
        findings.append({'type': 'dispatcher_loop', 'reason': 'while(true)/switch dispatcher pattern', 'hint': 'control-flow flattening (C-like)'})
    if re.search('\\bstate\\s*=\\s*\\d+\\s*;', code):
        findings.append({'type': 'state_var', 'reason': 'state variable updated inside loop', 'hint': 'possible flattened flow'})
    return findings

def clean_controlflow_flattening_clike(code: str) -> List[Dict]:
    """
    Conservative: we will not attempt full de-flattening.
    Instead, we:
      - detect small dispatcher with 2-3 cases and produce a suggested straight-line replacement as text,
        but do not modify code automatically unless pattern exactly matches a simple form.
    Returns list of change dicts; last item contains full cleaned placeholder if applied.
    """
    changes = []
    m = re.search('while\\s*\\(\\s*(?:1|true)\\s*\\)\\s*\\{\\s*switch\\s*\\(\\s*state\\s*\\)\\s*\\{\\s*(case\\s*1\\s*:\\s*([^}]*)break\\s*;)\\s*(case\\s*2\\s*:\\s*([^}]*)break\\s*;)\\s*\\}\\s*\\}', code, re.DOTALL | re.IGNORECASE)
    if m:
        case1 = m.group(2).strip()
        case2 = m.group(4).strip()
        suggested = '// Suggested deobfuscated sequence\n' + '/* case1 */\n' + case1 + '\n/* case2 */\n' + case2 + '\n'
        changes.append({'original': m.group(0), 'cleaned': suggested, 'reason': 'Simple dispatcher unflattened into sequential suggestions'})
        cleaned = code[:m.start()] + suggested + code[m.end():]
        changes.append({'original': code, 'cleaned': cleaned, 'reason': 'Applied small-scope unflatten (C-like) - manual review required'})
    elif detect_controlflow_flattening_clike(code):
        changes.append({'original': '', 'cleaned': '', 'reason': 'Detected control-flow flattening patterns, no automatic rewrite performed (too risky).'})
    return changes

def detect_controlflow_flattening_python(code: str) -> List[Dict]:
    findings = []
    if re.search('while\\s+True\\s*:\\s*', code):
        if re.search('\\b(state|mode)\\b', code) and re.search('\\bif\\b.*\\belse\\b', code, re.DOTALL):
            findings.append({'type': 'dispatcher_loop_py', 'reason': 'while True with state/if-dispatch found'})
    if re.search('\\{.*lambda.*:.*\\}', code, re.DOTALL):
        findings.append({'type': 'dict_dispatch', 'reason': 'dictionary-based dispatcher (python)'})
    return findings

def clean_controlflow_flattening_python(code: str) -> List[Dict]:
    findings = detect_controlflow_flattening_python(code)
    if findings:
        return [{'original': '', 'cleaned': '', 'reason': 'Detected Python flattened control-flow patterns. Manual reconstruction recommended.'}]
    return [] (Full cleaned file (Python deadcode removal))
input\deadCode.py: """# Dead Code Test Cases

# 1. Unused variable
x = 10   # dead
y = 20
print(y)

# 2. If condition always True
print("Always runs")
else:
    print("Dead branch")

# 3. If condition always False
else:
    print("Always runs")

# 4. Code after return
def f1():
    return 5
    print("Dead")  # dead

# 5. Code after break
for i in range(3):
    break
    print("Dead")  # dead

# 6. Unreachable else
print("Run")
else:
    print("Dead")

# 7. While False loop
while False:
    print("Never runs")  # dead

# 8. Constant condition (0 is False)
if 0:
    print("Dead")
else:
    print("Runs")

# 9. Constant condition (non-zero is True)
if 1:
    print("Runs")
else:
    print("Dead")

# 10. Multiple returns
def f2(x):
    if x > 0:
        return 1
        print("Dead")  # dead
    else:
        return -1
"""

# analyzers/deadcode.py
import ast
import re
from typing import List, Dict, Tuple

# --------------------------
# Python (AST) helpers
# --------------------------
class _DeadCodeRemover(ast.NodeTransformer):
    """
    Transformations:
      - remove `
    def visit_If(self, node: ast.If):
        # evaluate constant tests only
        try:
            if isinstance(node.test, ast.Constant):
                val = node.test.value
                if val is False:
                    original = ast.get_source_segment(self.source_text, node) if hasattr(self, "source_text") else ast.unparse(node)
                    # remove the entire if-block
                    self.changes.append((original, "", "If condition is constant False (dead code)"))
                    return None  # remove node
                elif val is True:
                    # keep body in place of if
                    body_nodes = [self.visit(b) for b in node.body]
                    original = ast.get_source_segment(self.source_text, node) if hasattr(self, "source_text") else ast.unparse(node)
                    cleaned = "\n".join([ast.unparse(b) for b in body_nodes if b is not None])
                    self.changes.append((original, cleaned, "If condition is constant True (inlined body)"))
                    return body_nodes  # splice body
        except Exception:
            pass
        self.generic_visit(node)
        return node

    def run(self, tree: ast.AST, source_text: str):
        self.source_text = source_text
        new_tree = self.visit(tree)
        return new_tree, self.changes


def detect_deadcode_python(code: str) -> List[Dict]:
    """
    Detect dead-code patterns in Python source using AST scanning.
    Returns list of findings (simple descriptions and line numbers).
    """
    findings = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        findings.append({"type": "parse_error", "reason": str(e)})
        return findings

    # If/While constant tests
    class V(ast.NodeVisitor):
        def visit_If(self, node):
            if isinstance(node.test, ast.Constant):
                if node.test.value is False:
                    findings.append({"type": "dead_if_false", "lineno": node.lineno, "snippet": ast.unparse(node.test)})
                elif node.test.value is True:
                    findings.append({"type": "dead_else", "lineno": node.lineno, "snippet": ast.unparse(node.test)})
            self.generic_visit(node)

        def visit_While(self, node):
            if isinstance(node.test, ast.Constant) and node.test.value is False:
                findings.append({"type": "dead_while_false", "lineno": node.lineno})
            self.generic_visit(node)

        def visit_FunctionDef(self, node):
            # detect code after return in function body
            for i, stmt in enumerate(node.body):
                if isinstance(stmt, ast.Return):
                    for later in node.body[i+1:]:
                        findings.append({"type": "dead_after_return", "lineno": getattr(later, "lineno", None), "func": node.name})
            self.generic_visit(node)

        def visit_Assign(self, node):
            # naive assigned variable capture (we'll refine in unused)
            self.generic_visit(node)

    V().visit(tree)

    # Unused variables: track simple assignments and loads
    assigned = {}
    used = set()
    class U(ast.NodeVisitor):
        def visit_Assign(self, node):
            if len(node.targets) == 1 and isinstance(node.targets"*", ast.Name):
                assigned[node.targets"*".id] = getattr(node, "lineno", None)
            self.generic_visit(node)
        def visit_Name(self, node):
            if isinstance(node.ctx, ast.Load):
                used.add(node.id)
    U().visit(tree)
    for var, lineno in assigned.items():
        if var not in used:
            findings.append({"type": "unused_var", "var": var, "lineno": lineno})

    return findings


def clean_deadcode_python(code: str) -> List[Dict]:
    """
    Attempt to remove dead code in Python source.
    Returns list of changes: {"original":..., "cleaned":..., "reason":...}
    """
    results = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{"original": code, "cleaned": code, "reason": f"parse_error: {e}"}]

    remover = _DeadCodeRemover()
    new_tree, changes = remover.run(tree, code)
    # unparse new_tree (may be list when splicing body — handle carefully)
    try:
        cleaned_code = ast.unparse(new_tree) if not isinstance(new_tree, list) else "\n".join(ast.unparse(n) for n in new_tree)
    except Exception:
        # fallback: do not change
        cleaned_code = code

    for orig, cleaned, reason in changes:
        results.append({"original": orig, "cleaned": cleaned, "reason": reason})

    # Also remove simple unused assignments by regex (safe: only single-name assigns to literal)
    # e.g., `x = 4` where x not used — remove those lines if they exist exactly.
    # We already reported unused vars above; here perform textual removal for simple case.
    facts = detect_deadcode_python(code)
    for f in facts:
        if f.get("type") == "unused_var" and isinstance(f.get("lineno"), int):
            lines = cleaned_code.splitlines()
            idx = f["lineno"] - 1
            if 0 <= idx < len(lines):
                orig_line = lines[idx]
                # verify assignment pattern
                if re.match(r'^\s*' + re.escape(f["var"]) + r'\s*=\s*[^#\n]+', orig_line):
                    lines[idx] = ""  # remove
                    results.append({"original": orig_line + "\n", "cleaned": "", "reason": f"Removed unused assignment '{f['var']}'"})
                    cleaned_code = "\n".join(lines)
    # Return changes and cleaned code appended as last item
    results.append({"original": code, "cleaned": cleaned_code, "reason": "Full cleaned file (Python deadcode removal)"})
    return results


# --------------------------
# C-like regex helpers
# --------------------------
def detect_deadcode_clike(code: str, ext_tag: str = "C-like") -> List[Dict]:
    findings = []
    lines = code.splitlines()
    for i, line in enumerate(lines, start=1):
        if re.search(r'\bif\s*\(\s*(false|0)\s*\)', line, re.IGNORECASE):
            findings.append({"type": "dead_if_false", "lineno": i, "snippet": line.strip(), "lang": ext_tag})
        if re.search(r'\bwhile\s*\(\s*(false|0)\s*\)', line, re.IGNORECASE):
            findings.append({"type": "dead_while_false", "lineno": i, "snippet": line.strip(), "lang": ext_tag})
        if re.search(r'\breturn\b.*;', line) and i < len(lines) and lines[i].strip():
            findings.append({"type": "after_return", "lineno": i+1, "snippet": lines[i].strip(), "lang": ext_tag})
    return findings


def clean_deadcode_clike(code: str) -> List[Dict]:
    """
    Clean simple C-like dead code:
      - remove `
      - replace `{ ... }` with block contents (strip braces)
      - remove single-line unused var assignments that are literal and not used elsewhere (conservative)
    Returns list of changes
    """
    changes = []
    s = code

    # remove 
    pattern_false_block = re.compile(r'\bif\s*\(\s*(?:false|0)\s*\)\s*(\{(?:[^{}]*|\{[^}]*\})*\}|[^;]*;)', re.IGNORECASE | re.DOTALL)
    while True:
        m = pattern_false_block.search(s)
        if not m: break
        orig = m.group(0)
        s = s[:m.start()] + s[m.end():]
        changes.append({"original": orig, "cleaned": "", "reason": "

    # inline { block } => replace with block contents
    pattern_true_block = re.compile(r'\bif\s*\(\s*(?:true|1)\s*\)\s*(\{(?:[^{}]*|\{[^}]*\})*\}|[^;]*;)', re.IGNORECASE | re.DOTALL)
    while True:
        m = pattern_true_block.search(s)
        if not m: break
        orig = m.group(0)
        blk = m.group(1)
        # strip outer braces if present
        if blk.strip().startswith("{") and blk.strip().endswith("}"):
            inner = blk.strip()[1:-1]
        else:
            inner = blk
        s = s[:m.start()] + inner + s[m.end():]
        changes.append({"original": orig, "cleaned": inner, "reason": " inlined (kept body)"})

    # conservative removal of simple unused assignments: pattern `int x = 4;` only if var name does not appear elsewhere
    assign_pattern = re.compile(r'\b(?:int|long|char|float|double)\s+([A-Za-z_]\w*)\s*=\s*[^;]+;')
    for m in assign_pattern.finditer(s):
        var = m.group(1)
        # if var occurs only once (the definition), remove it
        if len(re.findall(r'\b' + re.escape(var) + r'\b', s)) == 1:
            orig = m.group(0)
            s = s[:m.start()] + s[m.end():]
            changes.append({"original": orig, "cleaned": "", "reason": f"Removed likely-unused declaration '{var}'"})

    changes.append({"original": code, "cleaned": s, "reason": "Full cleaned file (C-like deadcode removal)"})
    return changes
 -> """# Dead Code Test Cases

# 1. Unused variable
x = 10   # dead
y = 20
print(y)

# 2. If condition always True
print("Always runs")
else:
    print("Dead branch")

# 3. If condition always False
else:
    print("Always runs")

# 4. Code after return
def f1():
    return 5
    print("Dead")  # dead

# 5. Code after break
for i in range(3):
    break
    print("Dead")  # dead

# 6. Unreachable else
print("Run")
else:
    print("Dead")

# 7. While False loop
while False:
    print("Never runs")  # dead

# 8. Constant condition (0 is False)
if 0:
    print("Dead")
else:
    print("Runs")

# 9. Constant condition (non-zero is True)
if 1:
    print("Runs")
else:
    print("Dead")

# 10. Multiple returns
def f2(x):
    if x > 0:
        return 1
        print("Dead")  # dead
    else:
        return -1
"""

# analyzers/deadcode.py
import ast
import re
from typing import List, Dict, Tuple

# --------------------------
# Python (AST) helpers
# --------------------------
class _DeadCodeRemover(ast.NodeTransformer):
    """
    Transformations:
      - remove `
    def visit_If(self, node: ast.If):
        # evaluate constant tests only
        try:
            if isinstance(node.test, ast.Constant):
                val = node.test.value
                if val is False:
                    original = ast.get_source_segment(self.source_text, node) if hasattr(self, "source_text") else ast.unparse(node)
                    # remove the entire if-block
                    self.changes.append((original, "", "If condition is constant False (dead code)"))
                    return None  # remove node
                elif val is True:
                    # keep body in place of if
                    body_nodes = [self.visit(b) for b in node.body]
                    original = ast.get_source_segment(self.source_text, node) if hasattr(self, "source_text") else ast.unparse(node)
                    cleaned = "\n".join([ast.unparse(b) for b in body_nodes if b is not None])
                    self.changes.append((original, cleaned, "If condition is constant True (inlined body)"))
                    return body_nodes  # splice body
        except Exception:
            pass
        self.generic_visit(node)
        return node

    def run(self, tree: ast.AST, source_text: str):
        self.source_text = source_text
        new_tree = self.visit(tree)
        return new_tree, self.changes


def detect_deadcode_python(code: str) -> List[Dict]:
    """
    Detect dead-code patterns in Python source using AST scanning.
    Returns list of findings (simple descriptions and line numbers).
    """
    findings = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        findings.append({"type": "parse_error", "reason": str(e)})
        return findings

    # If/While constant tests
    class V(ast.NodeVisitor):
        def visit_If(self, node):
            if isinstance(node.test, ast.Constant):
                if node.test.value is False:
                    findings.append({"type": "dead_if_false", "lineno": node.lineno, "snippet": ast.unparse(node.test)})
                elif node.test.value is True:
                    findings.append({"type": "dead_else", "lineno": node.lineno, "snippet": ast.unparse(node.test)})
            self.generic_visit(node)

        def visit_While(self, node):
            if isinstance(node.test, ast.Constant) and node.test.value is False:
                findings.append({"type": "dead_while_false", "lineno": node.lineno})
            self.generic_visit(node)

        def visit_FunctionDef(self, node):
            # detect code after return in function body
            for i, stmt in enumerate(node.body):
                if isinstance(stmt, ast.Return):
                    for later in node.body[i+1:]:
                        findings.append({"type": "dead_after_return", "lineno": getattr(later, "lineno", None), "func": node.name})
            self.generic_visit(node)

        def visit_Assign(self, node):
            # naive assigned variable capture (we'll refine in unused)
            self.generic_visit(node)

    V().visit(tree)

    # Unused variables: track simple assignments and loads
    assigned = {}
    used = set()
    class U(ast.NodeVisitor):
        def visit_Assign(self, node):
            if len(node.targets) == 1 and isinstance(node.targets"*", ast.Name):
                assigned[node.targets"*".id] = getattr(node, "lineno", None)
            self.generic_visit(node)
        def visit_Name(self, node):
            if isinstance(node.ctx, ast.Load):
                used.add(node.id)
    U().visit(tree)
    for var, lineno in assigned.items():
        if var not in used:
            findings.append({"type": "unused_var", "var": var, "lineno": lineno})

    return findings


def clean_deadcode_python(code: str) -> List[Dict]:
    """
    Attempt to remove dead code in Python source.
    Returns list of changes: {"original":..., "cleaned":..., "reason":...}
    """
    results = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{"original": code, "cleaned": code, "reason": f"parse_error: {e}"}]

    remover = _DeadCodeRemover()
    new_tree, changes = remover.run(tree, code)
    # unparse new_tree (may be list when splicing body — handle carefully)
    try:
        cleaned_code = ast.unparse(new_tree) if not isinstance(new_tree, list) else "\n".join(ast.unparse(n) for n in new_tree)
    except Exception:
        # fallback: do not change
        cleaned_code = code

    for orig, cleaned, reason in changes:
        results.append({"original": orig, "cleaned": cleaned, "reason": reason})

    # Also remove simple unused assignments by regex (safe: only single-name assigns to literal)
    # e.g., `x = 4` where x not used — remove those lines if they exist exactly.
    # We already reported unused vars above; here perform textual removal for simple case.
    facts = detect_deadcode_python(code)
    for f in facts:
        if f.get("type") == "unused_var" and isinstance(f.get("lineno"), int):
            lines = cleaned_code.splitlines()
            idx = f["lineno"] - 1
            if 0 <= idx < len(lines):
                orig_line = lines[idx]
                # verify assignment pattern
                if re.match(r'^\s*' + re.escape(f["var"]) + r'\s*=\s*[^#\n]+', orig_line):
                    lines[idx] = ""  # remove
                    results.append({"original": orig_line + "\n", "cleaned": "", "reason": f"Removed unused assignment '{f['var']}'"})
                    cleaned_code = "\n".join(lines)
    # Return changes and cleaned code appended as last item
    results.append({"original": code, "cleaned": cleaned_code, "reason": "Full cleaned file (Python deadcode removal)"})
    return results


# --------------------------
# C-like regex helpers
# --------------------------
def detect_deadcode_clike(code: str, ext_tag: str = "C-like") -> List[Dict]:
    findings = []
    lines = code.splitlines()
    for i, line in enumerate(lines, start=1):
        if re.search(r'\bif\s*\(\s*(false|0)\s*\)', line, re.IGNORECASE):
            findings.append({"type": "dead_if_false", "lineno": i, "snippet": line.strip(), "lang": ext_tag})
        if re.search(r'\bwhile\s*\(\s*(false|0)\s*\)', line, re.IGNORECASE):
            findings.append({"type": "dead_while_false", "lineno": i, "snippet": line.strip(), "lang": ext_tag})
        if re.search(r'\breturn\b.*;', line) and i < len(lines) and lines[i].strip():
            findings.append({"type": "after_return", "lineno": i+1, "snippet": lines[i].strip(), "lang": ext_tag})
    return findings


def clean_deadcode_clike(code: str) -> List[Dict]:
    """
    Clean simple C-like dead code:
      - remove `
      - replace `{ ... }` with block contents (strip braces)
      - remove single-line unused var assignments that are literal and not used elsewhere (conservative)
    Returns list of changes
    """
    changes = []
    s = code

    # remove 
    pattern_false_block = re.compile(r'\bif\s*\(\s*(?:false|0)\s*\)\s*(\{(?:[^{}]*|\{[^}]*\})*\}|[^;]*;)', re.IGNORECASE | re.DOTALL)
    while True:
        m = pattern_false_block.search(s)
        if not m: break
        orig = m.group(0)
        s = s[:m.start()] + s[m.end():]
        changes.append({"original": orig, "cleaned": "", "reason": "

    # inline { block } => replace with block contents
    pattern_true_block = re.compile(r'\bif\s*\(\s*(?:true|1)\s*\)\s*(\{(?:[^{}]*|\{[^}]*\})*\}|[^;]*;)', re.IGNORECASE | re.DOTALL)
    while True:
        m = pattern_true_block.search(s)
        if not m: break
        orig = m.group(0)
        blk = m.group(1)
        # strip outer braces if present
        if blk.strip().startswith("{") and blk.strip().endswith("}"):
            inner = blk.strip()[1:-1]
        else:
            inner = blk
        s = s[:m.start()] + inner + s[m.end():]
        changes.append({"original": orig, "cleaned": inner, "reason": " inlined (kept body)"})

    # conservative removal of simple unused assignments: pattern `int x = 4;` only if var name does not appear elsewhere
    assign_pattern = re.compile(r'\b(?:int|long|char|float|double)\s+([A-Za-z_]\w*)\s*=\s*[^;]+;')
    for m in assign_pattern.finditer(s):
        var = m.group(1)
        # if var occurs only once (the definition), remove it
        if len(re.findall(r'\b' + re.escape(var) + r'\b', s)) == 1:
            orig = m.group(0)
            s = s[:m.start()] + s[m.end():]
            changes.append({"original": orig, "cleaned": "", "reason": f"Removed likely-unused declaration '{var}'"})

    changes.append({"original": code, "cleaned": s, "reason": "Full cleaned file (C-like deadcode removal)"})
    return changes
 (parse_error: unterminated triple-quoted string literal (detected at line 262) (<unknown>, line 223))
input\dynamic_loading.py: # analyzers/dynamic_loading.py
"""
Detect dynamic code loading/reflection/indirect calls:
 - Python: eval, exec, compile, importlib, getattr/locals tricks
 - C/C++: function pointers, dlsym, system/exec calls
 - Java/Kotlin: reflection usage (Class.forName, Method.invoke)
Cleaning is conservative: we only report and, for trivial indirect calls (wrapper->function pointer),
we can sometimes inline wrapper.
"""

import re
from typing import List, Dict

# Python dynamic constructs
_PY_DYN = [
    re.compile(r'\beval\s*\('),
    re.compile(r'\bexec\s*\('),
    re.compile(r'\bcompile\s*\('),
    re.compile(r'\bimportlib\.'),
    re.compile(r'\b__import__\s*\('),
    re.compile(r'getattr\s*\('),
]

def detect_dynamic_code_loading_python(code: str) -> List[Dict]:
    findings = []
    for pat in _PY_DYN:
        for m in pat.finditer(code):
            findings.append({"type": "dynamic_py", "lineno": code[:m.start()].count("\n")+1, "snippet": m.group(0), "reason": "dynamic execution/reflection"})
    return findings

def detect_dynamic_code_loading_clike(code: str) -> List[Dict]:
    findings = []
    # function pointers: type (*fp)(); usage: fp();
    if re.search(r'\(\s*\*\s*[A-Za-z_]\w*\s*\)\s*\(', code):
        findings.append({"type": "func_ptr", "reason": "Function pointer usage detected (C/C++)"})
    # dlsym or GetProcAddress
    if re.search(r'\bdlsym\s*\(|\bGetProcAddress\s*\(', code):
        findings.append({"type": "dynamic_link", "reason": "dynamic symbol loading (dlsym/GetProcAddress)"})
    # system/exec
    if re.search(r'\bsystem\s*\(|\bexecve?\s*\(', code):
        findings.append({"type": "exec_call", "reason": "dynamic process creation or exec"})
    # Java reflection hints
    if re.search(r'\bClass\.forName\s*\(|\bgetMethod\s*\(|\binvoke\s*\(', code):
        findings.append({"type": "java_reflection", "reason": "Java reflection API usage"})
    return findings

def clean_dynamic_code_loading_clike(code: str) -> List[Dict]:
    # Very conservative: only inline wrappers that are direct trivial forwarding functions
    changes = []
    # detect trivial wrapper: int wrapper() { return actual(); }
    m = re.search(r'\b([A-Za-z_]\w*)\s*\([^)]*\)\s*\{\s*return\s+([A-Za-z_]\w*)\s*\(\s*\)\s*;\s*\}', code)
    if m:
        wrapper_name = m.group(1); real = m.group(2)
        # Replace calls to wrapper() with real()
        orig_wrapper = m.group(0)
        new_code = re.sub(r'\b' + re.escape(wrapper_name) + r'\s*\(\s*\)', real + '()', code)
        changes.append({"original": orig_wrapper, "cleaned": "", "reason": f"Removed trivial wrapper {wrapper_name} -> inlined calls to {real}()"})
        changes.append({"original": code, "cleaned": new_code, "reason": "Inlined trivial wrapper (C-like)"})
    else:
        # No safe changes
        dyn = detect_dynamic_code_loading_clike(code)
        if dyn:
            changes.append({"original": "", "cleaned": "", "reason": f"Detected dynamic loading/reflection: {dyn}. No automatic rewrite."})
    return changes

def clean_dynamic_code_loading_python(code: str) -> List[Dict]:
    # Do not attempt to remove eval/exec; only flag or suggest replacement.
    findings = detect_dynamic_code_loading_python(code)
    if findings:
        return [{"original": "", "cleaned": "", "reason": f"Detected dynamic constructs (eval/exec/compile/reflection). Manual review required: {findings}"}]
    return []
 -> """
Detect dynamic code loading/reflection/indirect calls:
 - Python: eval, exec, compile, importlib, getattr/locals tricks
 - C/C++: function pointers, dlsym, system/exec calls
 - Java/Kotlin: reflection usage (Class.forName, Method.invoke)
Cleaning is conservative: we only report and, for trivial indirect calls (wrapper->function pointer),
we can sometimes inline wrapper.
"""
import re
from typing import List, Dict
_PY_DYN = [re.compile('\\beval\\s*\\('), re.compile('\\bexec\\s*\\('), re.compile('\\bcompile\\s*\\('), re.compile('\\bimportlib\\.'), re.compile('\\b__import__\\s*\\('), re.compile('getattr\\s*\\(')]

def detect_dynamic_code_loading_python(code: str) -> List[Dict]:
    findings = []
    for pat in _PY_DYN:
        for m in pat.finditer(code):
            findings.append({'type': 'dynamic_py', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0), 'reason': 'dynamic execution/reflection'})
    return findings

def detect_dynamic_code_loading_clike(code: str) -> List[Dict]:
    findings = []
    if re.search('\\(\\s*\\*\\s*[A-Za-z_]\\w*\\s*\\)\\s*\\(', code):
        findings.append({'type': 'func_ptr', 'reason': 'Function pointer usage detected (C/C++)'})
    if re.search('\\bdlsym\\s*\\(|\\bGetProcAddress\\s*\\(', code):
        findings.append({'type': 'dynamic_link', 'reason': 'dynamic symbol loading (dlsym/GetProcAddress)'})
    if re.search('\\bsystem\\s*\\(|\\bexecve?\\s*\\(', code):
        findings.append({'type': 'exec_call', 'reason': 'dynamic process creation or exec'})
    if re.search('\\bClass\\.forName\\s*\\(|\\bgetMethod\\s*\\(|\\binvoke\\s*\\(', code):
        findings.append({'type': 'java_reflection', 'reason': 'Java reflection API usage'})
    return findings

def clean_dynamic_code_loading_clike(code: str) -> List[Dict]:
    changes = []
    m = re.search('\\b([A-Za-z_]\\w*)\\s*\\([^)]*\\)\\s*\\{\\s*return\\s+([A-Za-z_]\\w*)\\s*\\(\\s*\\)\\s*;\\s*\\}', code)
    if m:
        wrapper_name = m.group(1)
        real = m.group(2)
        orig_wrapper = m.group(0)
        new_code = re.sub('\\b' + re.escape(wrapper_name) + '\\s*\\(\\s*\\)', real + '()', code)
        changes.append({'original': orig_wrapper, 'cleaned': '', 'reason': f'Removed trivial wrapper {wrapper_name} -> inlined calls to {real}()'})
        changes.append({'original': code, 'cleaned': new_code, 'reason': 'Inlined trivial wrapper (C-like)'})
    else:
        dyn = detect_dynamic_code_loading_clike(code)
        if dyn:
            changes.append({'original': '', 'cleaned': '', 'reason': f'Detected dynamic loading/reflection: {dyn}. No automatic rewrite.'})
    return changes

def clean_dynamic_code_loading_python(code: str) -> List[Dict]:
    findings = detect_dynamic_code_loading_python(code)
    if findings:
        return [{'original': '', 'cleaned': '', 'reason': f'Detected dynamic constructs (eval/exec/compile/reflection). Manual review required: {findings}'}]
    return [] (Full cleaned file (Python deadcode removal))
input\inlineExpansion.py: """# Inline Expansion Complex Test Cases with Loops

# 1. Constant multiplication inside assignment
a = 12 * 4

# 2. Constant addition inside parentheses
b = (50 + 25)

# 3. Constant exponentiation (square)
c = 9 ** 2

# 4. Function returning inline multiplication
def f1():
    return (2 * 5) + 3

# 5. Inline addition inside an expression
x = (1 + 2) * (3 + 4)

# 6. Inline squaring inside variable assignment
y = (7 ** 2) + (2 ** 2)

# 7. Mixed variable + constant inline addition
z = 10 + (5 + 5)

# 8. Nested multiplications with loop
val = 1
for i in range(2):
    val *= (2 * 3) + (4 * 5)

# 9. Inline expansion inside if-condition inside loop
for i in range(3):
    if (2 + 3) > i:
        print("Inline addition in loop condition", i)

# 10. Inline exponentiation inside nested loop
for i in range(2):
    for j in range(2):
        p = (i + j) * (2 ** 2)
        print("Loop square:", p)

# 11. Inline expansion in while loop
k = 0
while k < (2 + 2):
    k += (3 * 3)
    print("While loop step:", k)

# 12. Inline in function argument (looped calls)
def square_and_add(n):
    return n + (4 ** 2)

for i in range(3):
    print("Function call:", square_and_add(i))"""








# analyzers/inline_expansion.py
import ast
import re
from typing import List, Dict

# Safe AST constant evaluator for arithmetic/comparison (Python)
_ALLOWED_BINOPS = (ast.Add, ast.Sub, ast.Mult, ast.Div, ast.Mod, ast.Pow,
                   ast.LShift, ast.RShift, ast.BitAnd, ast.BitOr, ast.BitXor, ast.FloorDiv)
_ALLOWED_UNARYOPS = (ast.UAdd, ast.USub, ast.Invert)

def _eval_constant_ast(node):


    if isinstance(node, ast.Constant):
        return node.value
    if isinstance(node, ast.UnaryOp) and isinstance(node.op, _ALLOWED_UNARYOPS):
        val = _eval_constant_ast(node.operand)
        if isinstance(node.op, ast.UAdd): return +val
        if isinstance(node.op, ast.USub): return -val
        if isinstance(node.op, ast.Invert): return ~val
    if isinstance(node, ast.BinOp) and isinstance(node.op, _ALLOWED_BINOPS):
        L = _eval_constant_ast(node.left)
        R = _eval_constant_ast(node.right)
        op = node.op
        if isinstance(op, ast.Add): return L + R
        if isinstance(op, ast.Sub): return L - R
        if isinstance(op, ast.Mult): return L * R
        if isinstance(op, ast.Div): return L / R
        if isinstance(op, ast.FloorDiv): return L // R
        if isinstance(op, ast.Mod): return L % R
        if isinstance(op, ast.Pow): return L ** R
        if isinstance(op, ast.LShift): return L << R
        if isinstance(op, ast.RShift): return L >> R
        if isinstance(op, ast.BitAnd): return L & R
        if isinstance(op, ast.BitOr): return L | R
        if isinstance(op, ast.BitXor): return L ^ R
    raise ValueError("Not a constant-evaluable expression")

# ---------------- Python constant folding transformer ----------------
class _ConstantFolder(ast.NodeTransformer):
    def __init__(self):
        self.changes = []
    def visit_BinOp(self, node):
        self.generic_visit(node)
        try:
            val = _eval_constant_ast(node)
            orig = ast.unparse(node)
            new = ast.copy_location(ast.Constant(value=val), node)
            self.changes.append((orig, repr(val), node.lineno))
            return new
        except Exception:
            return node

def detect_inline_expansion_python(code: str) -> List[Dict]:


    findings = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{"type": "parse_error", "reason": str(e)}]
    class V(ast.NodeVisitor):
        def visit_BinOp(self, node):
            try:
                val = _eval_constant_ast(node)
                findings.append({"type": "constant_fold", "lineno": node.lineno, "expr": ast.unparse(node), "value": val})
            except Exception:
                # detect x*x pattern
                if isinstance(node.op, ast.Mult) and isinstance(node.left, ast.Name) and isinstance(node.right, ast.Name) and node.left.id == node.right.id:
                    findings.append({"type": "variable_square", "lineno": node.lineno, "var": node.left.id})
            self.generic_visit(node)
    V().visit(tree)
    return findings

def clean_inline_expansion_python(code: str) -> List[Dict]:


    results = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{"original": code, "cleaned": code, "reason": f"parse_error: {e}"}]
    folder = _ConstantFolder()
    new_tree = folder.visit(tree)
    cleaned_code = None
    try:
        cleaned_code = ast.unparse(new_tree)
    except Exception:
        cleaned_code = code
    for orig, valrepr, lineno in folder.changes:
        results.append({"original": orig, "cleaned": str(valrepr), "lineno": lineno, "reason": "Constant folded"})
    results.append({"original": code, "cleaned": cleaned_code, "reason": "Full cleaned file (Python inline folding)"})
    return results

# ---------------- C-like regex heuristics ----------------
_numop_re = re.compile(r'\b(\d+)\s*([\+\-\*\/%])\s*(\d+)\b')

def detect_inline_expansion_clike(code: str, ext_tag="C-like") -> List[Dict]:
    findings = []
    for i, line in enumerate(code.splitlines(), start=1):
        for m in _numop_re.finditer(line):
            a, op, b = m.groups()
            findings.append({"type": "const_expr", "lineno": i, "expr": m.group(0), "lang": ext_tag})
        if re.search(r'\b(\w+)\s*\*\s*\1\b', line):
            findings.append({"type": "square_pattern", "lineno": i, "expr": line.strip(), "lang": ext_tag})
    return findings

def clean_inline_expansion_clike(code: str) -> List[Dict]:
    
    s = code
    changes = []
    def _eval_match(m):
        a, op, b = m.groups()
        # safe integer arithmetic
        a_i = int(a); b_i = int(b)
        if op == '+': r = a_i + b_i
        elif op == '-': r = a_i - b_i
        elif op == '*': r = a_i * b_i
        elif op == '/':
            if b_i == 0: raise ZeroDivisionError
            r = a_i // b_i
        elif op == '%': r = a_i % b_i
        else:
            raise ValueError
        changes.append({"original": m.group(0), "cleaned": str(r), "reason": "Constant arithmetic folded"})
        return str(r)

    # replace iteratively until no more matches
    while True:
        new, n = _numop_re.subn(lambda m: _eval_match(m), s, count=1)
        if n == 0:
            break
        s = new
    if changes:
        changes.append({"original": code, "cleaned": s, "reason": "Applied simple constant folding (C-like)"})
    return changes







 -> """# Inline Expansion Complex Test Cases with Loops

# 1. Constant multiplication inside assignment
a = 12 * 4

# 2. Constant addition inside parentheses
b = (50 + 25)

# 3. Constant exponentiation (square)
c = 9 ** 2

# 4. Function returning inline multiplication
def f1():
    return (2 * 5) + 3

# 5. Inline addition inside an expression
x = (1 + 2) * (3 + 4)

# 6. Inline squaring inside variable assignment
y = (7 ** 2) + (2 ** 2)

# 7. Mixed variable + constant inline addition
z = 10 + (5 + 5)

# 8. Nested multiplications with loop
val = 1
for i in range(2):
    val *= (2 * 3) + (4 * 5)

# 9. Inline expansion inside if-condition inside loop
for i in range(3):
    if (2 + 3) > i:
        print("Inline addition in loop condition", i)

# 10. Inline exponentiation inside nested loop
for i in range(2):
    for j in range(2):
        p = (i + j) * (2 ** 2)
        print("Loop square:", p)

# 11. Inline expansion in while loop
k = 0
while k < (2 + 2):
    k += (3 * 3)
    print("While loop step:", k)

# 12. Inline in function argument (looped calls)
def square_and_add(n):
    return n + (4 ** 2)

for i in range(3):
    print("Function call:", square_and_add(i))"""
import ast
import re
from typing import List, Dict
_ALLOWED_BINOPS = (ast.Add, ast.Sub, ast.Mult, ast.Div, ast.Mod, ast.Pow, ast.LShift, ast.RShift, ast.BitAnd, ast.BitOr, ast.BitXor, ast.FloorDiv)
_ALLOWED_UNARYOPS = (ast.UAdd, ast.USub, ast.Invert)

def _eval_constant_ast(node):
    if isinstance(node, ast.Constant):
        return node.value
    if isinstance(node, ast.UnaryOp) and isinstance(node.op, _ALLOWED_UNARYOPS):
        val = _eval_constant_ast(node.operand)
        if isinstance(node.op, ast.UAdd):
            return +val
        if isinstance(node.op, ast.USub):
            return -val
        if isinstance(node.op, ast.Invert):
            return ~val
    if isinstance(node, ast.BinOp) and isinstance(node.op, _ALLOWED_BINOPS):
        L = _eval_constant_ast(node.left)
        R = _eval_constant_ast(node.right)
        op = node.op
        if isinstance(op, ast.Add):
            return L + R
        if isinstance(op, ast.Sub):
            return L - R
        if isinstance(op, ast.Mult):
            return L * R
        if isinstance(op, ast.Div):
            return L / R
        if isinstance(op, ast.FloorDiv):
            return L // R
        if isinstance(op, ast.Mod):
            return L % R
        if isinstance(op, ast.Pow):
            return L ** R
        if isinstance(op, ast.LShift):
            return L << R
        if isinstance(op, ast.RShift):
            return L >> R
        if isinstance(op, ast.BitAnd):
            return L & R
        if isinstance(op, ast.BitOr):
            return L | R
        if isinstance(op, ast.BitXor):
            return L ^ R
    raise ValueError('Not a constant-evaluable expression')

class _ConstantFolder(ast.NodeTransformer):

    def __init__(self):
        self.changes = []

    def visit_BinOp(self, node):
        self.generic_visit(node)
        try:
            val = _eval_constant_ast(node)
            orig = ast.unparse(node)
            new = ast.copy_location(ast.Constant(value=val), node)
            self.changes.append((orig, repr(val), node.lineno))
            return new
        except Exception:
            return node

def detect_inline_expansion_python(code: str) -> List[Dict]:
    findings = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{'type': 'parse_error', 'reason': str(e)}]

    class V(ast.NodeVisitor):

        def visit_BinOp(self, node):
            try:
                val = _eval_constant_ast(node)
                findings.append({'type': 'constant_fold', 'lineno': node.lineno, 'expr': ast.unparse(node), 'value': val})
            except Exception:
                if isinstance(node.op, ast.Mult) and isinstance(node.left, ast.Name) and isinstance(node.right, ast.Name) and (node.left.id == node.right.id):
                    findings.append({'type': 'variable_square', 'lineno': node.lineno, 'var': node.left.id})
            self.generic_visit(node)
    V().visit(tree)
    return findings

def clean_inline_expansion_python(code: str) -> List[Dict]:
    results = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{'original': code, 'cleaned': code, 'reason': f'parse_error: {e}'}]
    folder = _ConstantFolder()
    new_tree = folder.visit(tree)
    cleaned_code = None
    try:
        cleaned_code = ast.unparse(new_tree)
    except Exception:
        cleaned_code = code
    for orig, valrepr, lineno in folder.changes:
        results.append({'original': orig, 'cleaned': str(valrepr), 'lineno': lineno, 'reason': 'Constant folded'})
    results.append({'original': code, 'cleaned': cleaned_code, 'reason': 'Full cleaned file (Python inline folding)'})
    return results
_numop_re = re.compile('\\b(\\d+)\\s*([\\+\\-\\*\\/%])\\s*(\\d+)\\b')

def detect_inline_expansion_clike(code: str, ext_tag='C-like') -> List[Dict]:
    findings = []
    for i, line in enumerate(code.splitlines(), start=1):
        for m in _numop_re.finditer(line):
            a, op, b = m.groups()
            findings.append({'type': 'const_expr', 'lineno': i, 'expr': m.group(0), 'lang': ext_tag})
        if re.search('\\b(\\w+)\\s*\\*\\s*\\1\\b', line):
            findings.append({'type': 'square_pattern', 'lineno': i, 'expr': line.strip(), 'lang': ext_tag})
    return findings

def clean_inline_expansion_clike(code: str) -> List[Dict]:
    s = code
    changes = []

    def _eval_match(m):
        a, op, b = m.groups()
        a_i = int(a)
        b_i = int(b)
        if op == '+':
            r = a_i + b_i
        elif op == '-':
            r = a_i - b_i
        elif op == '*':
            r = a_i * b_i
        elif op == '/':
            if b_i == 0:
                raise ZeroDivisionError
            r = a_i // b_i
        elif op == '%':
            r = a_i % b_i
        else:
            raise ValueError
        changes.append({'original': m.group(0), 'cleaned': str(r), 'reason': 'Constant arithmetic folded'})
        return str(r)
    while True:
        new, n = _numop_re.subn(lambda m: _eval_match(m), s, count=1)
        if n == 0:
            break
        s = new
    if changes:
        changes.append({'original': code, 'cleaned': s, 'reason': 'Applied simple constant folding (C-like)'})
    return changes (Full cleaned file (Python deadcode removal))
input\instruction_substitution.py: # analyzers/instruction_substitution.py
"""
Detect instruction substitution like:
  - x - (-1)  -> x + 1
  - x << 1    -> x * 2
  - x + x     -> 2 * x  (or x * 2)
  - bitwise tricks (x ^ -1) etc.
We'll canonicalize a few safe patterns.
"""

import re
from typing import List, Dict

# Patterns -> canonical replacement
_CLIKE_PATTERNS = [
    # x - (-1)  -> x + 1
    (re.compile(r'([A-Za-z_]\w*)\s*-\s*\(\s*-\s*1\s*\)'), r'\1 + 1', "neg-neg to plus"),
    # x << 1  -> x * 2
    (re.compile(r'([A-Za-z_]\w*)\s*<<\s*1\b'), r'\1 * 2', "shift-left to multiply"),
    # x + x -> 2 * x (note: keep order)
    (re.compile(r'\b([A-Za-z_]\w*)\s*\+\s*\1\b'), r'2 * \1', "x+x to 2*x"),
    # double-negation: --x -> x (in C/C++)
    (re.compile(r'--([A-Za-z_]\w*)'), r'\1', "double-neg"),
]

def detect_instruction_substitution_clike(code: str) -> List[Dict]:
    findings = []
    for pat, repl, reason in _CLIKE_PATTERNS:
        for m in pat.finditer(code):
            findings.append({"type": "instr_sub", "lineno": code[:m.start()].count("\n")+1, "snippet": m.group(0), "suggest": repl, "reason": reason})
    return findings

def clean_instruction_substitution_clike(code: str) -> List[Dict]:
    changes = []
    s = code
    for pat, repl, reason in _CLIKE_PATTERNS:
        # replace all occurrences, record original per replacement
        for m in pat.finditer(s):
            orig = m.group(0)
            # compute replacement on the current match
            new = pat.sub(repl, orig)
            changes.append({"original": orig, "cleaned": new, "reason": f"Canonicalized: {reason}"})
        s = pat.sub(repl, s)
    if changes:
        changes.append({"original": code, "cleaned": s, "reason": "Applied instruction substitution canonicalization (C-like)"})
    return changes

# Python variants (similar)
_PY_PATTERNS = [
    (re.compile(r'([A-Za-z_]\w*)\s*-\s*\(\s*-\s*1\s*\)'), r'\1 + 1', "neg-neg to plus"),
    (re.compile(r'\b([A-Za-z_]\w*)\s*\+\s*\1\b'), r'2 * \1', "x+x to 2*x"),
]

def detect_instruction_substitution_python(code: str) -> List[Dict]:
    findings = []
    for pat, repl, reason in _PY_PATTERNS:
        for m in pat.finditer(code):
            findings.append({"type": "instr_sub_py", "lineno": code[:m.start()].count("\n")+1, "snippet": m.group(0), "suggest": repl, "reason": reason})
    return findings

def clean_instruction_substitution_python(code: str) -> List[Dict]:
    s = code
    changes = []
    for pat, repl, reason in _PY_PATTERNS:
        for m in pat.finditer(s):
            orig = m.group(0)
            new = pat.sub(repl, orig)
            changes.append({"original": orig, "cleaned": new, "reason": f"Canonicalized: {reason}"})
        s = pat.sub(repl, s)
    if changes:
        changes.append({"original": code, "cleaned": s, "reason": "Applied instruction substitution canonicalization (Python)"})
    return changes
 -> """
Detect instruction substitution like:
  - x - (-1)  -> x + 1
  - x << 1    -> x * 2
  - x + x     -> 2 * x  (or x * 2)
  - bitwise tricks (x ^ -1) etc.
We'll canonicalize a few safe patterns.
"""
import re
from typing import List, Dict
_CLIKE_PATTERNS = [(re.compile('([A-Za-z_]\\w*)\\s*-\\s*\\(\\s*-\\s*1\\s*\\)'), '\\1 + 1', 'neg-neg to plus'), (re.compile('([A-Za-z_]\\w*)\\s*<<\\s*1\\b'), '\\1 * 2', 'shift-left to multiply'), (re.compile('\\b([A-Za-z_]\\w*)\\s*\\+\\s*\\1\\b'), '2 * \\1', 'x+x to 2*x'), (re.compile('--([A-Za-z_]\\w*)'), '\\1', 'double-neg')]

def detect_instruction_substitution_clike(code: str) -> List[Dict]:
    findings = []
    for pat, repl, reason in _CLIKE_PATTERNS:
        for m in pat.finditer(code):
            findings.append({'type': 'instr_sub', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0), 'suggest': repl, 'reason': reason})
    return findings

def clean_instruction_substitution_clike(code: str) -> List[Dict]:
    changes = []
    s = code
    for pat, repl, reason in _CLIKE_PATTERNS:
        for m in pat.finditer(s):
            orig = m.group(0)
            new = pat.sub(repl, orig)
            changes.append({'original': orig, 'cleaned': new, 'reason': f'Canonicalized: {reason}'})
        s = pat.sub(repl, s)
    if changes:
        changes.append({'original': code, 'cleaned': s, 'reason': 'Applied instruction substitution canonicalization (C-like)'})
    return changes
_PY_PATTERNS = [(re.compile('([A-Za-z_]\\w*)\\s*-\\s*\\(\\s*-\\s*1\\s*\\)'), '\\1 + 1', 'neg-neg to plus'), (re.compile('\\b([A-Za-z_]\\w*)\\s*\\+\\s*\\1\\b'), '2 * \\1', 'x+x to 2*x')]

def detect_instruction_substitution_python(code: str) -> List[Dict]:
    findings = []
    for pat, repl, reason in _PY_PATTERNS:
        for m in pat.finditer(code):
            findings.append({'type': 'instr_sub_py', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0), 'suggest': repl, 'reason': reason})
    return findings

def clean_instruction_substitution_python(code: str) -> List[Dict]:
    s = code
    changes = []
    for pat, repl, reason in _PY_PATTERNS:
        for m in pat.finditer(s):
            orig = m.group(0)
            new = pat.sub(repl, orig)
            changes.append({'original': orig, 'cleaned': new, 'reason': f'Canonicalized: {reason}'})
        s = pat.sub(repl, s)
    if changes:
        changes.append({'original': code, 'cleaned': s, 'reason': 'Applied instruction substitution canonicalization (Python)'})
    return changes (Full cleaned file (Python deadcode removal))
input\junkcode.py: # analyzers/junk_code.py
"""
Detect/remove junk code: NOPs, identity operations, redundant arithmetic, dead stores used only for obfuscation.
Conservative cleaning: only remove clear NOP-like constructs and no-op arithmetic on local vars not used in observable way.
"""

import re
from typing import List, Dict

def detect_junk_code_clike(code: str) -> List[Dict]:
    findings = []
    # inline asm nop; common patterns
    for m in re.finditer(r'\basm\s*\(\s*".*?nop.*?"\s*\)\s*;', code, re.IGNORECASE | re.DOTALL):
        findings.append({"type": "asm_nop", "lineno": code[:m.start()].count("\n")+1, "snippet": m.group(0)})
    # identity ops: x = x + 0; x = x * 1;
    for m in re.finditer(r'\b([A-Za-z_]\w*)\s*=\s*\1\s*([+\-\*\/])\s*0\b', code):
        findings.append({"type": "identity_add_zero", "lineno": code[:m.start()].count("\n")+1, "snippet": m.group(0)})
    for m in re.finditer(r'\b([A-Za-z_]\w*)\s*=\s*\1\s*\*\s*1\b', code):
        findings.append({"type": "identity_mul_one", "lineno": code[:m.start()].count("\n")+1, "snippet": m.group(0)})
    # dead stores: var assigned then immediately overwritten without use
    # simplified heuristic: pattern "x = <expr>; x = <expr2>;" on consecutive lines
    lines = code.splitlines()
    for i in range(len(lines)-1):
        a = lines[i].strip(); b = lines[i+1].strip()
        var1 = re.match(r'([A-Za-z_]\w*)\s*=\s*[^;]+;', a)
        var2 = re.match(r'([A-Za-z_]\w*)\s*=\s*[^;]+;', b)
        if var1 and var2 and var1.group(1) == var2.group(1):
            findings.append({"type": "dead_store_sequence", "lineno": i+1, "snippet": a + " " + b})
    return findings

def clean_junk_code_clike(code: str) -> List[Dict]:
    s = code
    changes = []
    # remove asm("nop"); occurrences
    s_new = re.sub(r'\basm\s*\(\s*".*?nop.*?"\s*\)\s*;', '', s, flags=re.IGNORECASE|re.DOTALL)
    if s_new != s:
        changes.append({"original": s, "cleaned": s_new, "reason": "Removed inline asm NOPs (C-like)"})
        s = s_new
    # remove identity ops x = x + 0 or x = x * 1
    s_new = re.sub(r'\b([A-Za-z_]\w*)\s*=\s*\1\s*\+\s*0\s*;', '', s)
    s_new = re.sub(r'\b([A-Za-z_]\w*)\s*=\s*\1\s*\*\s*1\s*;', s_new)
    if s_new != s:
        changes.append({"original": s, "cleaned": s_new, "reason": "Removed identity arithmetic (x = x + 0 / x = x * 1)"})
        s = s_new
    # remove consecutive dead-store sequences conservatively: drop the earlier assignment
    lines = s.splitlines()
    out_lines = []
    i = 0
    while i < len(lines):
        if i < len(lines)-1:
            a = lines[i].strip(); b = lines[i+1].strip()
            var1 = re.match(r'([A-Za-z_]\w*)\s*=\s*[^;]+;', a)
            var2 = re.match(r'([A-Za-z_]\w*)\s*=\s*[^;]+;', b)
            if var1 and var2 and var1.group(1) == var2.group(1):
                # drop the earlier assignment (conservative)
                changes.append({"original": a + "\n" + b + "\n", "cleaned": b + "\n", "reason": "Removed redundant earlier store (dead store)"})
                out_lines.append(b)
                i += 2
                continue
        out_lines.append(lines[i])
        i += 1
    cleaned = "\n".join(out_lines)
    if cleaned != code and not changes:
        changes.append({"original": code, "cleaned": cleaned, "reason": "Junk cleaning applied (C-like)"})
    elif cleaned != code:
        changes.append({"original": code, "cleaned": cleaned, "reason": "Junk cleaning applied (C-like)"})
    return changes

# Python junk detection (no-ops, redundant ops)
def detect_junk_code_python(code: str) -> List[Dict]:
    findings = []
    # pass statements that do nothing (but pass is meaningful syntactically)
    for m in re.finditer(r'^\s*pass\s*$', code, re.MULTILINE):
        findings.append({"type": "pass_stmt", "lineno": code[:m.start()].count("\n")+1, "snippet": m.group(0)})
    # x = x + 0
    for m in re.finditer(r'\b([A-Za-z_]\w*)\s*=\s*\1\s*\+\s*0\b', code):
        findings.append({"type": "identity_add_zero", "lineno": code[:m.start()].count("\n")+1, "snippet": m.group(0)})
    return findings

def clean_junk_code_python(code: str) -> List[Dict]:
    s = code
    changes = []
    # remove pass lines that are alone
    s_new = re.sub(r'^\s*pass\s*$(?:\n)?', '', s, flags=re.MULTILINE)
    if s_new != s:
        changes.append({"original": s, "cleaned": s_new, "reason": "Removed redundant pass statements"})
        s = s_new
    # remove x = x + 0
    s_new = re.sub(r'\b([A-Za-z_]\w*)\s*=\s*\1\s*\+\s*0\b', r'\1 = \1', s)
    if s_new != s:
        changes.append({"original": s, "cleaned": s_new, "reason": "Removed identity addition (x = x + 0)."})
        s = s_new
    return changes
 -> """
Detect/remove junk code: NOPs, identity operations, redundant arithmetic, dead stores used only for obfuscation.
Conservative cleaning: only remove clear NOP-like constructs and no-op arithmetic on local vars not used in observable way.
"""
import re
from typing import List, Dict

def detect_junk_code_clike(code: str) -> List[Dict]:
    findings = []
    for m in re.finditer('\\basm\\s*\\(\\s*".*?nop.*?"\\s*\\)\\s*;', code, re.IGNORECASE | re.DOTALL):
        findings.append({'type': 'asm_nop', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*([+\\-\\*\\/])\\s*0\\b', code):
        findings.append({'type': 'identity_add_zero', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\*\\s*1\\b', code):
        findings.append({'type': 'identity_mul_one', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    lines = code.splitlines()
    for i in range(len(lines) - 1):
        a = lines[i].strip()
        b = lines[i + 1].strip()
        var1 = re.match('([A-Za-z_]\\w*)\\s*=\\s*[^;]+;', a)
        var2 = re.match('([A-Za-z_]\\w*)\\s*=\\s*[^;]+;', b)
        if var1 and var2 and (var1.group(1) == var2.group(1)):
            findings.append({'type': 'dead_store_sequence', 'lineno': i + 1, 'snippet': a + ' ' + b})
    return findings

def clean_junk_code_clike(code: str) -> List[Dict]:
    s = code
    changes = []
    s_new = re.sub('\\basm\\s*\\(\\s*".*?nop.*?"\\s*\\)\\s*;', '', s, flags=re.IGNORECASE | re.DOTALL)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed inline asm NOPs (C-like)'})
        s = s_new
    s_new = re.sub('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\+\\s*0\\s*;', '', s)
    s_new = re.sub('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\*\\s*1\\s*;', s_new)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed identity arithmetic (x = x + 0 / x = x * 1)'})
        s = s_new
    lines = s.splitlines()
    out_lines = []
    i = 0
    while i < len(lines):
        if i < len(lines) - 1:
            a = lines[i].strip()
            b = lines[i + 1].strip()
            var1 = re.match('([A-Za-z_]\\w*)\\s*=\\s*[^;]+;', a)
            var2 = re.match('([A-Za-z_]\\w*)\\s*=\\s*[^;]+;', b)
            if var1 and var2 and (var1.group(1) == var2.group(1)):
                changes.append({'original': a + '\n' + b + '\n', 'cleaned': b + '\n', 'reason': 'Removed redundant earlier store (dead store)'})
                out_lines.append(b)
                i += 2
                continue
        out_lines.append(lines[i])
        i += 1
    cleaned = '\n'.join(out_lines)
    if cleaned != code and (not changes):
        changes.append({'original': code, 'cleaned': cleaned, 'reason': 'Junk cleaning applied (C-like)'})
    elif cleaned != code:
        changes.append({'original': code, 'cleaned': cleaned, 'reason': 'Junk cleaning applied (C-like)'})
    return changes

def detect_junk_code_python(code: str) -> List[Dict]:
    findings = []
    for m in re.finditer('^\\s*pass\\s*$', code, re.MULTILINE):
        findings.append({'type': 'pass_stmt', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\+\\s*0\\b', code):
        findings.append({'type': 'identity_add_zero', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    return findings

def clean_junk_code_python(code: str) -> List[Dict]:
    s = code
    changes = []
    s_new = re.sub('^\\s*pass\\s*$(?:\\n)?', '', s, flags=re.MULTILINE)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed redundant pass statements'})
        s = s_new
    s_new = re.sub('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\+\\s*0\\b', '\\1 = \\1', s)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed identity addition (x = x + 0).'})
        s = s_new
    return changes (Full cleaned file (Python deadcode removal))
input\mixed_language.py: # analyzers/mixed_language.py
"""
Detect mixed-language obfuscation signals, such as:
 - inline assembly or ASM blocks inside C/C++  
 - presence of JNI-like bridging code (native method definitions)  
 - generated code markers or embedded Java/Kotlin code segments in C comments
Cleaning: only report and optionally remove pure ASM nop sections or trivial inline assembler used as junk.
"""

import re
from typing import List, Dict

def detect_mixed_language(code: str) -> List[Dict]:
    findings = []
    # inline asm in C: __asm__("..."); or asm("...");
    if re.search(r'\b(__asm__|asm)\s*\(', code):
        findings.append({"type": "inline_asm", "reason": "Inline assembler block detected"})
    # JNI: Java native method / System.loadLibrary or 'jni.h' inclusion
    if re.search(r'#\s*include\s*<jni.h>', code) or re.search(r'System\.loadLibrary', code):
        findings.append({"type": "jni_bridge", "reason": "JNI/native bridge detected"})
    # Kotlin/Java embedded strings (large embedded source snippets)
    if re.search(r'class\s+[A-Z]\w+\s*\{', code) and re.search(r'#include', code):
        findings.append({"type": "mixed_java_c", "reason": "Mixed Java/C code smells (both class and #include present)"})
    return findings

# -------------------- Python cleaning --------------------
def clean_mixed_language_python(code: str) -> List[Dict]:
    changes = []
    # For Python, just detect and annotate mixed constructs (no auto removal)
    findings = detect_mixed_language(code)
    if findings:
        changes.append({"original": "", "cleaned": "", "reason": f"Detected mixed-language constructs: {findings}. No automatic cleaning applied."})
    return changes

# -------------------- C-like cleaning --------------------
def clean_mixed_language_clike(code: str) -> List[Dict]:
    changes = []
    s = code
    # remove asm("nop") etc
    s_new = re.sub(r'\basm\s*\(\s*".*?nop.*?"\s*\)\s*;', '', s, flags=re.DOTALL | re.IGNORECASE)
    if s_new != s:
        changes.append({"original": s, "cleaned": s_new, "reason": "Removed inline asm nop occurrences (mixed-language cleaning)"})
    else:
        findings = detect_mixed_language(code)
        if findings:
            changes.append({"original": "", "cleaned": "", "reason": f"Detected mixed-language constructs: {findings}. No automatic cleaning applied."})
    return changes
 -> """
Detect mixed-language obfuscation signals, such as:
 - inline assembly or ASM blocks inside C/C++  
 - presence of JNI-like bridging code (native method definitions)  
 - generated code markers or embedded Java/Kotlin code segments in C comments
Cleaning: only report and optionally remove pure ASM nop sections or trivial inline assembler used as junk.
"""
import re
from typing import List, Dict

def detect_mixed_language(code: str) -> List[Dict]:
    findings = []
    if re.search('\\b(__asm__|asm)\\s*\\(', code):
        findings.append({'type': 'inline_asm', 'reason': 'Inline assembler block detected'})
    if re.search('#\\s*include\\s*<jni.h>', code) or re.search('System\\.loadLibrary', code):
        findings.append({'type': 'jni_bridge', 'reason': 'JNI/native bridge detected'})
    if re.search('class\\s+[A-Z]\\w+\\s*\\{', code) and re.search('#include', code):
        findings.append({'type': 'mixed_java_c', 'reason': 'Mixed Java/C code smells (both class and #include present)'})
    return findings

def clean_mixed_language_python(code: str) -> List[Dict]:
    changes = []
    findings = detect_mixed_language(code)
    if findings:
        changes.append({'original': '', 'cleaned': '', 'reason': f'Detected mixed-language constructs: {findings}. No automatic cleaning applied.'})
    return changes

def clean_mixed_language_clike(code: str) -> List[Dict]:
    changes = []
    s = code
    s_new = re.sub('\\basm\\s*\\(\\s*".*?nop.*?"\\s*\\)\\s*;', '', s, flags=re.DOTALL | re.IGNORECASE)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed inline asm nop occurrences (mixed-language cleaning)'})
    else:
        findings = detect_mixed_language(code)
        if findings:
            changes.append({'original': '', 'cleaned': '', 'reason': f'Detected mixed-language constructs: {findings}. No automatic cleaning applied.'})
    return changes (Full cleaned file (Python deadcode removal))
input\nameIdentifier.py: import re
import ast
import keyword
import builtins

# ----------------------------------------
# Reserved keywords for multiple languages
# ----------------------------------------
LANG_KEYWORDS = {
    "python": set(keyword.kwlist) | set(dir(builtins)),
    "c": {
        "auto","break","case","char","const","continue","default","do","double",
        "else","enum","extern","float","for","goto","if","inline","int","long",
        "register","restrict","return","short","signed","sizeof","static",
        "struct","switch","typedef","union","unsigned","void","volatile","while"
    },
    "cpp": {
        "asm","auto","bool","break","case","catch","char","class","const","const_cast",
        "continue","default","delete","do","double","dynamic_cast","else","enum","explicit",
        "export","extern","false","float","for","friend","goto","if","inline","int","long",
        "mutable","namespace","new","operator","private","protected","public","register",
        "reinterpret_cast","return","short","signed","sizeof","static","static_cast",
        "struct","switch","template","this","throw","true","try","typedef","typeid",
        "typename","union","unsigned","using","virtual","void","volatile","wchar_t","while"
    },
    "java": {
        "abstract","assert","boolean","break","byte","case","catch","char","class","const",
        "continue","default","do","double","else","enum","extends","final","finally","float",
        "for","goto","if","implements","import","instanceof","int","interface","long",
        "native","new","package","private","protected","public","return","short","static",
        "strictfp","super","switch","synchronized","this","throw","throws","transient","try",
        "void","volatile","while"
    },
    "kotlin": {
        "as","break","class","continue","do","else","false","for","fun","if","in",
        "interface","is","null","object","package","return","super","this","throw",
        "true","try","typealias","typeof","val","var","when","while"
    }
}

# ----------------------------------------
# Identifier Obfuscation Detection
# ----------------------------------------
def is_obfuscated_name(name: str, language: str = "python") -> bool:
    """Detect obfuscated identifiers like x1a3, a1, f2 but exclude language keywords."""
    reserved = LANG_KEYWORDS.get(language, set())
    if name in reserved:
        return False
    # Rule: short name with numbers inside
    return bool(re.fullmatch(r"[a-zA-Z]"+)"\d+[a-zA-Z0-9]*", name))


# ----------------------------------------
# AST Visitor for Python
# ----------------------------------------
class NameCollector(ast.NodeVisitor):
    """Collects identifiers from Python AST."""
    def __init__(self, language="python"):
        self.funcs = set()
        self.classes = set()
        self.vars = set()
        self.language = language

    def visit_FunctionDef(self, node):
        if is_obfuscated_name(node.name, self.language):
            self.funcs.add(node.name)
        for arg in node.args.args:
            if is_obfuscated_name(arg.arg, self.language):
                self.vars.add(arg.arg)
        self.generic_visit(node)

    def visit_ClassDef(self, node):
        if is_obfuscated_name(node.name, self.language):
            self.classes.add(node.name)
        self.generic_visit(node)

    def visit_Name(self, node):
        if is_obfuscated_name(node.id, self.language):
            self.vars.add(node.id)


# ----------------------------------------
# Main Cleaner Class (like FakeConditionCleaner)
# ----------------------------------------
class IdentifierCleaner:
    """Detects obfuscated identifiers and returns original, cleaned, reason."""

    def __init__(self, language="python"):
        self.language = language

    def detect_and_clean(self, code):
        """
        Returns:
            changes: list of dicts with keys ['original', 'cleaned', 'reason']
            cleaned_code: code after replacing obfuscated identifiers
        """
        mapping = {}
        changes = []
        func_count, class_count, var_count = 1, 1, 1

        # ----------------------------------------
        # Python AST-based collection
        # ----------------------------------------
        if self.language == "python":
            tree = ast.parse(code)
            collector = NameCollector(self.language)
            collector.visit(tree)

            for f in sorted(collector.funcs):
                mapping[f] = f"func{func_count}"; func_count += 1
            for c in sorted(collector.classes):
                mapping[c] = f"Class{class_count}"; class_count += 1
            for v in sorted(collector.vars):
                mapping[v] = f"var{var_count}"; var_count += 1

        # ----------------------------------------
        # Regex-based collection for other languages
        # ----------------------------------------
        else:
            identifiers = re.findall(r"\b[a-zA-Z_][a-zA-Z0-9_]*\b", code)
            for name in set(identifiers):
                if is_obfuscated_name(name, self.language):
                    if re.match(r"^[A-Z]", name):  # Class
                        mapping[name] = f"Class{class_count}"; class_count += 1
                    elif re.match(r"^[a-z]", name):
                        if re.search(r"\d", name):  # func-like
                            mapping[name] = f"func{func_count}"; func_count += 1
                        else:
                            mapping[name] = f"var{var_count}"; var_count += 1

        # ----------------------------------------
        # Apply mapping and generate change log
        # ----------------------------------------
        def replace_identifier(match):
            word = match.group(0)
            new_word = mapping.get(word, word)
            if word != new_word:
                changes.append({
                    "original": word,
                    "cleaned": new_word,
                    "reason": f"Obfuscated identifier replaced ({word} → {new_word})"
                })
            return new_word

        cleaned_code = re.sub(r"\b[a-zA-Z_][a-zA-Z0-9_]*\b", replace_identifier, code)
        return changes, cleaned_code


# ----------------------------------------
# Language Detection Helper
# ----------------------------------------
def detect_language(filename: str) -> str:
    """Detect programming language from file extension."""
    ext = filename.split(".")[-1].lower()
    if ext == "py":
        return "python"
    elif ext in ("c", "h"):
        return "c"
    elif ext == "cpp":
        return "cpp"
    elif ext == "java":
        return "java"
    elif ext == "kt":
        return "kotlin"
    return "unknown" -> import re
import ast
import keyword
import builtins

# ----------------------------------------
# Reserved keywords for multiple languages
# ----------------------------------------
LANG_KEYWORDS = {
    "python": set(keyword.kwlist) | set(dir(builtins)),
    "c": {
        "auto","break","case","char","const","continue","default","do","double",
        "else","enum","extern","float","for","goto","if","inline","int","long",
        "register","restrict","return","short","signed","sizeof","static",
        "struct","switch","typedef","union","unsigned","void","volatile","while"
    },
    "cpp": {
        "asm","auto","bool","break","case","catch","char","class","const","const_cast",
        "continue","default","delete","do","double","dynamic_cast","else","enum","explicit",
        "export","extern","false","float","for","friend","goto","if","inline","int","long",
        "mutable","namespace","new","operator","private","protected","public","register",
        "reinterpret_cast","return","short","signed","sizeof","static","static_cast",
        "struct","switch","template","this","throw","true","try","typedef","typeid",
        "typename","union","unsigned","using","virtual","void","volatile","wchar_t","while"
    },
    "java": {
        "abstract","assert","boolean","break","byte","case","catch","char","class","const",
        "continue","default","do","double","else","enum","extends","final","finally","float",
        "for","goto","if","implements","import","instanceof","int","interface","long",
        "native","new","package","private","protected","public","return","short","static",
        "strictfp","super","switch","synchronized","this","throw","throws","transient","try",
        "void","volatile","while"
    },
    "kotlin": {
        "as","break","class","continue","do","else","false","for","fun","if","in",
        "interface","is","null","object","package","return","super","this","throw",
        "true","try","typealias","typeof","val","var","when","while"
    }
}

# ----------------------------------------
# Identifier Obfuscation Detection
# ----------------------------------------
def is_obfuscated_name(name: str, language: str = "python") -> bool:
    """Detect obfuscated identifiers like x1a3, a1, f2 but exclude language keywords."""
    reserved = LANG_KEYWORDS.get(language, set())
    if name in reserved:
        return False
    # Rule: short name with numbers inside
    return bool(re.fullmatch(r"[a-zA-Z]"+)"\d+[a-zA-Z0-9]*", name))


# ----------------------------------------
# AST Visitor for Python
# ----------------------------------------
class NameCollector(ast.NodeVisitor):
    """Collects identifiers from Python AST."""
    def __init__(self, language="python"):
        self.funcs = set()
        self.classes = set()
        self.vars = set()
        self.language = language

    def visit_FunctionDef(self, node):
        if is_obfuscated_name(node.name, self.language):
            self.funcs.add(node.name)
        for arg in node.args.args:
            if is_obfuscated_name(arg.arg, self.language):
                self.vars.add(arg.arg)
        self.generic_visit(node)

    def visit_ClassDef(self, node):
        if is_obfuscated_name(node.name, self.language):
            self.classes.add(node.name)
        self.generic_visit(node)

    def visit_Name(self, node):
        if is_obfuscated_name(node.id, self.language):
            self.vars.add(node.id)


# ----------------------------------------
# Main Cleaner Class (like FakeConditionCleaner)
# ----------------------------------------
class IdentifierCleaner:
    """Detects obfuscated identifiers and returns original, cleaned, reason."""

    def __init__(self, language="python"):
        self.language = language

    def detect_and_clean(self, code):
        """
        Returns:
            changes: list of dicts with keys ['original', 'cleaned', 'reason']
            cleaned_code: code after replacing obfuscated identifiers
        """
        mapping = {}
        changes = []
        func_count, class_count, var_count = 1, 1, 1

        # ----------------------------------------
        # Python AST-based collection
        # ----------------------------------------
        if self.language == "python":
            tree = ast.parse(code)
            collector = NameCollector(self.language)
            collector.visit(tree)

            for f in sorted(collector.funcs):
                mapping[f] = f"func{func_count}"; func_count += 1
            for c in sorted(collector.classes):
                mapping[c] = f"Class{class_count}"; class_count += 1
            for v in sorted(collector.vars):
                mapping[v] = f"var{var_count}"; var_count += 1

        # ----------------------------------------
        # Regex-based collection for other languages
        # ----------------------------------------
        else:
            identifiers = re.findall(r"\b[a-zA-Z_][a-zA-Z0-9_]*\b", code)
            for name in set(identifiers):
                if is_obfuscated_name(name, self.language):
                    if re.match(r"^[A-Z]", name):  # Class
                        mapping[name] = f"Class{class_count}"; class_count += 1
                    elif re.match(r"^[a-z]", name):
                        if re.search(r"\d", name):  # func-like
                            mapping[name] = f"func{func_count}"; func_count += 1
                        else:
                            mapping[name] = f"var{var_count}"; var_count += 1

        # ----------------------------------------
        # Apply mapping and generate change log
        # ----------------------------------------
        def replace_identifier(match):
            word = match.group(0)
            new_word = mapping.get(word, word)
            if word != new_word:
                changes.append({
                    "original": word,
                    "cleaned": new_word,
                    "reason": f"Obfuscated identifier replaced ({word} → {new_word})"
                })
            return new_word

        cleaned_code = re.sub(r"\b[a-zA-Z_][a-zA-Z0-9_]*\b", replace_identifier, code)
        return changes, cleaned_code


# ----------------------------------------
# Language Detection Helper
# ----------------------------------------
def detect_language(filename: str) -> str:
    """Detect programming language from file extension."""
    ext = filename.split(".")[-1].lower()
    if ext == "py":
        return "python"
    elif ext in ("c", "h"):
        return "c"
    elif ext == "cpp":
        return "cpp"
    elif ext == "java":
        return "java"
    elif ext == "kt":
        return "kotlin"
    return "unknown" (parse_error: unmatched ')' (<unknown>, line 50))
input\opaque_predicate.py: # Opaque Predicate Complex Test Cases

# 1. Always true with redundant check inside loop

"""for i in range(2):
    if (2 + 2 == 4) and (3 > 1):
        print("Loop always true:", i)

# 2. Always false predicate (never executes)
for j in range(3):
    if (5 < 2) or (10 < 3):
        print("This will never print", j)

# 3. Constant comparison with while loop
k = 0
while k < 2:
    if (100 == 100):
        print("While loop always true", k)
    k += 1

# 4. Arithmetic inside comparison
if (2 * 3 == 6) and (4 - 1 == 3):
    print("Inline arithmetic always true")

# 5. Complex but always true condition in function
def check_predicate():
    if (50 - 25 == 25) and (4**2 == 16):
        return "Function always true"
    return "Unreachable"

print(check_predicate())

# 6. Complex but false inside loop
for i in range(2):
    if (9 % 2 == 0) or (7 < 3):
        print("Never executes")

# 7. Nested opaque predicates
if ((10/2) == 5):
    if ((3*3) == 9):
        print("Nested always true")

# 8. Redundant always true inside loop
for i in range(2):
    if (8 > 3) and (2 < 5):
        print("Redundant always true", i)

# 9. Impossible opaque condition
if (1 == 2) or (0 > 10):
    print("Impossible branch")

# 10. Hidden constant compare inside function + loop
def hidden_check(x):
    if (x * 2 == 8) and (16/4 == 4):
        return True
    return False

for val in "./":
    if hidden_check(val):
        print("Hidden opaque true for", val)"""


# analyzers/opaque_predicate.py
import ast
import re
from typing import List, Dict

# Reuse the same safe AST evaluator from inline_expansion; to avoid circular import, copy minimal evaluator:
_ALLOWED_BINOPS = (ast.Add, ast.Sub, ast.Mult, ast.Div, ast.Mod, ast.Pow,
                   ast.LShift, ast.RShift, ast.BitAnd, ast.BitOr, ast.BitXor, ast.FloorDiv)
_ALLOWED_UNARYOPS = (ast.UAdd, ast.USub, ast.Invert)

def _eval_constant_ast(node):
    if isinstance(node, ast.Constant):
        return node.value
    if isinstance(node, ast.UnaryOp) and isinstance(node.op, _ALLOWED_UNARYOPS):
        val = _eval_constant_ast(node.operand)
        if isinstance(node.op, ast.UAdd): return +val
        if isinstance(node.op, ast.USub): return -val
        if isinstance(node.op, ast.Invert): return ~val
    if isinstance(node, ast.BinOp) and isinstance(node.op, _ALLOWED_BINOPS):
        L = _eval_constant_ast(node.left)
        R = _eval_constant_ast(node.right)
        op = node.op
        if isinstance(op, ast.Add): return L + R
        if isinstance(op, ast.Sub): return L - R
        if isinstance(op, ast.Mult): return L * R
        if isinstance(op, ast.Div): return L / R
        if isinstance(op, ast.FloorDiv): return L // R
        if isinstance(op, ast.Mod): return L % R
        if isinstance(op, ast.Pow): return L ** R
        if isinstance(op, ast.LShift): return L << R
        if isinstance(op, ast.RShift): return L >> R
        if isinstance(op, ast.BitAnd): return L & R
        if isinstance(op, ast.BitOr): return L | R
        if isinstance(op, ast.BitXor): return L ^ R
    if isinstance(node, ast.Compare):
        left = _eval_constant_ast(node.left)
        # single comparator supported
        comp = node.comparators"*"
        right = _eval_constant_ast(comp)
        op = node.ops"*"
        if isinstance(op, ast.Eq): return left == right
        if isinstance(op, ast.NotEq): return left != right
        if isinstance(op, ast.Lt): return left < right
        if isinstance(op, ast.LtE): return left <= right
        if isinstance(op, ast.Gt): return left > right
        if isinstance(op, ast.GtE): return left >= right
    if isinstance(node, ast.BoolOp):
        # evaluate values if possible
        values = [_eval_constant_ast(v) for v in node.values]
        if isinstance(node.op, ast.And):
            return all(values)
        else:
            return any(values)
    raise ValueError("Not constant-evaluable")

# ---------------- Python detection/cleaning ----------------
def detect_opaque_predicate_python(code: str) -> List[Dict]:
    findings = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{"type": "parse_error", "reason": str(e)}]
    class V(ast.NodeVisitor):
        def visit_If(self, node):
            # try to evaluate the test
            try:
                val = _eval_constant_ast(node.test)
                findings.append({"type": "opaque_always", "lineno": node.lineno, "value": bool(val), "expr": ast.unparse(node.test)})
            except Exception:
                # check for Compare with constant operands inside BoolOp
                if isinstance(node.test, ast.BoolOp):
                    for v in node.test.values:
                        if isinstance(v, ast.Compare):
                            left = v.left
                            if isinstance(left, ast.BinOp) and isinstance(left.left, ast.Constant) and isinstance(left.right, ast.Constant):
                                findings.append({"type": "opaque_arith", "lineno": node.lineno, "expr": ast.unparse(v)})
            self.generic_visit(node)
    V().visit(tree)
    return findings

def clean_opaque_predicate_python(code: str) -> List[Dict]:
    """
    Replace opaque predicates that evaluate to True with their body,
    remove those that evaluate to False.
    """
    results = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{"original": code, "cleaned": code, "reason": f"parse_error: {e}"}]

    class Transformer(ast.NodeTransformer):
        def __init__(self):
            self.changes = []
        def visit_If(self, node):
            # try eval test
            try:
                val = _eval_constant_ast(node.test)
                orig = ast.unparse(node)
                if bool(val):
                    # keep body (inline)
                    cleaned = "\n".join([ast.unparse(n) for n in node.body])
                    self.changes.append({"original": orig, "cleaned": cleaned, "reason": "Opaque predicate evaluated True -> inlined body"})
                    return node.body
                else:
                    # remove if entirely or keep else if present
                    cleaned = ""
                    if node.orelse:
                        cleaned = "\n".join([ast.unparse(n) for n in node.orelse])
                    self.changes.append({"original": orig, "cleaned": cleaned, "reason": "Opaque predicate evaluated False -> removed or replaced with else"})
                    # replace with else-body if exists
                    return node.orelse or []
            except Exception:
                return self.generic_visit(node)

    t = Transformer()
    new_tree = t.visit(tree)
    try:
        new_code = ast.unparse(new_tree)
    except Exception:
        new_code = code
    results.extend(t.changes)
    results.append({"original": code, "cleaned": new_code, "reason": "Full cleaned file (Python opaque predicate simplification)"})
    return results

# ---------------- C-like detection/cleaning (regex) ----------------
_cmp_re = re.compile(r'\b(\d+(?:\s*[\+\-\*\/]\s*\d+)*)\s*(==|!=|>|<|>=|<=)\s*(\d+(?:\s*[\+\-\*\/]\s*\d+)*)')

def _safe_eval_num_expr(expr: str):
    # only digits, whitespace, and operators allowed
    if not re.fullmatch(r'[0-9\+\-\*\/%\s\(\)]+', expr):
        raise ValueError("unsafe expr")
    # evaluate using Python integer math (floor division)
    # replace / with // for integer division
    expr2 = expr.replace('/', '//')
    return eval(expr2)

def detect_opaque_predicate_clike(code: str, lang="C-like") -> List[Dict]:
    findings = []
    for i, line in enumerate(code.splitlines(), start=1):
        for m in _cmp_re.finditer(line):
            left, op, right = m.groups()
            try:
                lv = _safe_eval_num_expr(left)
                rv = _safe_eval_num_expr(right)
                # compare
                ok = False
                if op == '==': ok = (lv == rv)
                elif op == '!=': ok = (lv != rv)
                elif op == '<': ok = (lv < rv)
                elif op == '<=': ok = (lv <= rv)
                elif op == '>': ok = (lv > rv)
                elif op == '>=': ok = (lv >= rv)
                findings.append({"type": "opaque_cmp_const", "lineno": i, "expr": m.group(0), "value": ok, "lang": lang})
            except Exception:
                findings.append({"type": "opaque_cmp_unknown", "lineno": i, "expr": m.group(0), "lang": lang})
    return findings

def clean_opaque_predicate_clike(code: str) -> List[Dict]:
    """
    For identified constant comparisons, attempt to simplify:
      - if condition is always true: replace `if(cond){block}else{else}` -> keep block
      - if always false: remove block or keep else
    Very conservative textual approach: only handles simple one-line if statements and braced blocks.
    """
    changes = []
    s = code
    # find simple if (...) { ... } else { ... } patterns with constant numeric comparisons inside parentheses
    if_pattern = re.compile(r'if\s*\(\s*([^\)]+)\s*\)\s*(\{(?:[^{}]|\{[^}]*\})*\}|[^\n;]*;)\s*(else\s*(\{(?:[^{}]|\{[^}]*\})*\}|[^\n;]*;))?', re.DOTALL)
    pos = 0
    while True:
        m = if_pattern.search(s, pos)
        if not m:
            break
        cond = m.group(1)
        body = m.group(2)
        else_part = m.group(3) or ""
        try:
            # attempt to evaluate cond if it's a simple arithmetic comparison
            mm = _cmp_re.search(cond)
            if mm:
                left, op, right = mm.groups()
                lv = _safe_eval_num_expr(left)
                rv = _safe_eval_num_expr(right)
                if op == '==': val = (lv == rv)
                elif op == '!=': val = (lv != rv)
                elif op == '<': val = (lv < rv)
                elif op == '<=': val = (lv <= rv)
                elif op == '>': val = (lv > rv)
                elif op == '>=': val = (lv >= rv)
                if val:
                    # keep body, remove if(...) and else
                    cleaned = body
                    changes.append({"original": m.group(0), "cleaned": cleaned, "reason": "Opaque condition evaluated True — inlined body"})
                    s = s[:m.start()] + cleaned + s[m.end():]
                    pos = m.start() + len(cleaned)
                    continue
                else:
                    # remove body, keep else if present
                    cleaned = else_part if else_part else ""
                    changes.append({"original": m.group(0), "cleaned": cleaned, "reason": "Opaque condition evaluated False — removed body / kept else"})
                    s = s[:m.start()] + cleaned + s[m.end():]
                    pos = m.start() + len(cleaned)
                    continue
        except Exception:
            pass
        pos = m.end()
    if changes:
        changes.append({"original": code, "cleaned": s, "reason": "Applied simple opaque predicate simplification (C-like)"})
    return changes
 -> # Opaque Predicate Complex Test Cases

# 1. Always true with redundant check inside loop

"""for i in range(2):
    if (2 + 2 == 4) and (3 > 1):
        print("Loop always true:", i)

# 2. Always false predicate (never executes)
for j in range(3):
    if (5 < 2) or (10 < 3):
        print("This will never print", j)

# 3. Constant comparison with while loop
k = 0
while k < 2:
    if (100 == 100):
        print("While loop always true", k)
    k += 1

# 4. Arithmetic inside comparison
if (2 * 3 == 6) and (4 - 1 == 3):
    print("Inline arithmetic always true")

# 5. Complex but always true condition in function
def check_predicate():
    if (50 - 25 == 25) and (4**2 == 16):
        return "Function always true"
    return "Unreachable"

print(check_predicate())

# 6. Complex but false inside loop
for i in range(2):
    if (9 % 2 == 0) or (7 < 3):
        print("Never executes")

# 7. Nested opaque predicates
if ((10/2) == 5):
    if ((3*3) == 9):
        print("Nested always true")

# 8. Redundant always true inside loop
for i in range(2):
    if (8 > 3) and (2 < 5):
        print("Redundant always true", i)

# 9. Impossible opaque condition
if (1 == 2) or (0 > 10):
    print("Impossible branch")

# 10. Hidden constant compare inside function + loop
def hidden_check(x):
    if (x * 2 == 8) and (16/4 == 4):
        return True
    return False

for val in "./":
    if hidden_check(val):
        print("Hidden opaque true for", val)"""


# analyzers/opaque_predicate.py
import ast
import re
from typing import List, Dict

# Reuse the same safe AST evaluator from inline_expansion; to avoid circular import, copy minimal evaluator:
_ALLOWED_BINOPS = (ast.Add, ast.Sub, ast.Mult, ast.Div, ast.Mod, ast.Pow,
                   ast.LShift, ast.RShift, ast.BitAnd, ast.BitOr, ast.BitXor, ast.FloorDiv)
_ALLOWED_UNARYOPS = (ast.UAdd, ast.USub, ast.Invert)

def _eval_constant_ast(node):
    if isinstance(node, ast.Constant):
        return node.value
    if isinstance(node, ast.UnaryOp) and isinstance(node.op, _ALLOWED_UNARYOPS):
        val = _eval_constant_ast(node.operand)
        if isinstance(node.op, ast.UAdd): return +val
        if isinstance(node.op, ast.USub): return -val
        if isinstance(node.op, ast.Invert): return ~val
    if isinstance(node, ast.BinOp) and isinstance(node.op, _ALLOWED_BINOPS):
        L = _eval_constant_ast(node.left)
        R = _eval_constant_ast(node.right)
        op = node.op
        if isinstance(op, ast.Add): return L + R
        if isinstance(op, ast.Sub): return L - R
        if isinstance(op, ast.Mult): return L * R
        if isinstance(op, ast.Div): return L / R
        if isinstance(op, ast.FloorDiv): return L // R
        if isinstance(op, ast.Mod): return L % R
        if isinstance(op, ast.Pow): return L ** R
        if isinstance(op, ast.LShift): return L << R
        if isinstance(op, ast.RShift): return L >> R
        if isinstance(op, ast.BitAnd): return L & R
        if isinstance(op, ast.BitOr): return L | R
        if isinstance(op, ast.BitXor): return L ^ R
    if isinstance(node, ast.Compare):
        left = _eval_constant_ast(node.left)
        # single comparator supported
        comp = node.comparators"*"
        right = _eval_constant_ast(comp)
        op = node.ops"*"
        if isinstance(op, ast.Eq): return left == right
        if isinstance(op, ast.NotEq): return left != right
        if isinstance(op, ast.Lt): return left < right
        if isinstance(op, ast.LtE): return left <= right
        if isinstance(op, ast.Gt): return left > right
        if isinstance(op, ast.GtE): return left >= right
    if isinstance(node, ast.BoolOp):
        # evaluate values if possible
        values = [_eval_constant_ast(v) for v in node.values]
        if isinstance(node.op, ast.And):
            return all(values)
        else:
            return any(values)
    raise ValueError("Not constant-evaluable")

# ---------------- Python detection/cleaning ----------------
def detect_opaque_predicate_python(code: str) -> List[Dict]:
    findings = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{"type": "parse_error", "reason": str(e)}]
    class V(ast.NodeVisitor):
        def visit_If(self, node):
            # try to evaluate the test
            try:
                val = _eval_constant_ast(node.test)
                findings.append({"type": "opaque_always", "lineno": node.lineno, "value": bool(val), "expr": ast.unparse(node.test)})
            except Exception:
                # check for Compare with constant operands inside BoolOp
                if isinstance(node.test, ast.BoolOp):
                    for v in node.test.values:
                        if isinstance(v, ast.Compare):
                            left = v.left
                            if isinstance(left, ast.BinOp) and isinstance(left.left, ast.Constant) and isinstance(left.right, ast.Constant):
                                findings.append({"type": "opaque_arith", "lineno": node.lineno, "expr": ast.unparse(v)})
            self.generic_visit(node)
    V().visit(tree)
    return findings

def clean_opaque_predicate_python(code: str) -> List[Dict]:
    """
    Replace opaque predicates that evaluate to True with their body,
    remove those that evaluate to False.
    """
    results = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{"original": code, "cleaned": code, "reason": f"parse_error: {e}"}]

    class Transformer(ast.NodeTransformer):
        def __init__(self):
            self.changes = []
        def visit_If(self, node):
            # try eval test
            try:
                val = _eval_constant_ast(node.test)
                orig = ast.unparse(node)
                if bool(val):
                    # keep body (inline)
                    cleaned = "\n".join([ast.unparse(n) for n in node.body])
                    self.changes.append({"original": orig, "cleaned": cleaned, "reason": "Opaque predicate evaluated True -> inlined body"})
                    return node.body
                else:
                    # remove if entirely or keep else if present
                    cleaned = ""
                    if node.orelse:
                        cleaned = "\n".join([ast.unparse(n) for n in node.orelse])
                    self.changes.append({"original": orig, "cleaned": cleaned, "reason": "Opaque predicate evaluated False -> removed or replaced with else"})
                    # replace with else-body if exists
                    return node.orelse or []
            except Exception:
                return self.generic_visit(node)

    t = Transformer()
    new_tree = t.visit(tree)
    try:
        new_code = ast.unparse(new_tree)
    except Exception:
        new_code = code
    results.extend(t.changes)
    results.append({"original": code, "cleaned": new_code, "reason": "Full cleaned file (Python opaque predicate simplification)"})
    return results

# ---------------- C-like detection/cleaning (regex) ----------------
_cmp_re = re.compile(r'\b(\d+(?:\s*[\+\-\*\/]\s*\d+)*)\s*(==|!=|>|<|>=|<=)\s*(\d+(?:\s*[\+\-\*\/]\s*\d+)*)')

def _safe_eval_num_expr(expr: str):
    # only digits, whitespace, and operators allowed
    if not re.fullmatch(r'[0-9\+\-\*\/%\s\(\)]+', expr):
        raise ValueError("unsafe expr")
    # evaluate using Python integer math (floor division)
    # replace / with // for integer division
    expr2 = expr.replace('/', '//')
    return eval(expr2)

def detect_opaque_predicate_clike(code: str, lang="C-like") -> List[Dict]:
    findings = []
    for i, line in enumerate(code.splitlines(), start=1):
        for m in _cmp_re.finditer(line):
            left, op, right = m.groups()
            try:
                lv = _safe_eval_num_expr(left)
                rv = _safe_eval_num_expr(right)
                # compare
                ok = False
                if op == '==': ok = (lv == rv)
                elif op == '!=': ok = (lv != rv)
                elif op == '<': ok = (lv < rv)
                elif op == '<=': ok = (lv <= rv)
                elif op == '>': ok = (lv > rv)
                elif op == '>=': ok = (lv >= rv)
                findings.append({"type": "opaque_cmp_const", "lineno": i, "expr": m.group(0), "value": ok, "lang": lang})
            except Exception:
                findings.append({"type": "opaque_cmp_unknown", "lineno": i, "expr": m.group(0), "lang": lang})
    return findings

def clean_opaque_predicate_clike(code: str) -> List[Dict]:
    """
    For identified constant comparisons, attempt to simplify:
      - if condition is always true: replace `if(cond){block}else{else}` -> keep block
      - if always false: remove block or keep else
    Very conservative textual approach: only handles simple one-line if statements and braced blocks.
    """
    changes = []
    s = code
    # find simple if (...) { ... } else { ... } patterns with constant numeric comparisons inside parentheses
    if_pattern = re.compile(r'if\s*\(\s*([^\)]+)\s*\)\s*(\{(?:[^{}]|\{[^}]*\})*\}|[^\n;]*;)\s*(else\s*(\{(?:[^{}]|\{[^}]*\})*\}|[^\n;]*;))?', re.DOTALL)
    pos = 0
    while True:
        m = if_pattern.search(s, pos)
        if not m:
            break
        cond = m.group(1)
        body = m.group(2)
        else_part = m.group(3) or ""
        try:
            # attempt to evaluate cond if it's a simple arithmetic comparison
            mm = _cmp_re.search(cond)
            if mm:
                left, op, right = mm.groups()
                lv = _safe_eval_num_expr(left)
                rv = _safe_eval_num_expr(right)
                if op == '==': val = (lv == rv)
                elif op == '!=': val = (lv != rv)
                elif op == '<': val = (lv < rv)
                elif op == '<=': val = (lv <= rv)
                elif op == '>': val = (lv > rv)
                elif op == '>=': val = (lv >= rv)
                if val:
                    # keep body, remove if(...) and else
                    cleaned = body
                    changes.append({"original": m.group(0), "cleaned": cleaned, "reason": "Opaque condition evaluated True — inlined body"})
                    s = s[:m.start()] + cleaned + s[m.end():]
                    pos = m.start() + len(cleaned)
                    continue
                else:
                    # remove body, keep else if present
                    cleaned = else_part if else_part else ""
                    changes.append({"original": m.group(0), "cleaned": cleaned, "reason": "Opaque condition evaluated False — removed body / kept else"})
                    s = s[:m.start()] + cleaned + s[m.end():]
                    pos = m.start() + len(cleaned)
                    continue
        except Exception:
            pass
        pos = m.end()
    if changes:
        changes.append({"original": code, "cleaned": s, "reason": "Applied simple opaque predicate simplification (C-like)"})
    return changes
 (parse_error: invalid syntax (<unknown>, line 100))
input\stringEncryption.py: # input/stringDecryptor.py
import re

def xor_decrypt(enc_list, key=42):
    """XOR decrypt a list of integers to a string."""
    try:
        return ''.join(chr(c ^ key) for c in enc_list)
    except Exception:
        return None

class StringDecryptor:
    """Detects and decrypts XOR-encrypted strings in code."""
    def __init__(self, key=42):
        self.key = key

    def detect_strings(self, code: str):
        """Detect candidate encrypted strings as list of integers."""
        pattern = re.compile(r'[\[{]([0-9,\s]+)[\]}]')
        results = []
        for match in pattern.finditer(code):
            str_bytes = match.group(1)
            try:
                enc_list = [int(b.strip()) for b in str_bytes.split(',') if b.strip().isdigit()]
                decrypted = xor_decrypt(enc_list, self.key)
                if decrypted and all(32 <= ord(ch) <= 126 for ch in decrypted):
                    results.append({
                        "original": match.group(0),
                        "decrypted": decrypted,
                        "position": match.start(),
                        "reason": "XOR-encrypted string detected and decrypted"
                    })
            except Exception:
                continue
        return results

    def detect_and_clean(self, code: str):
        """Detect encrypted strings, replace them, and return changes and final code."""
        results = self.detect_strings(code)
        cleaned_code = code
        # Apply replacements from end to start to avoid index shifting
        for res in reversed(results):
            start_idx = cleaned_code.find(res['original'])
            if start_idx != -1:
                cleaned_code = cleaned_code[:start_idx] + f'"{res["decrypted"]}"' + cleaned_code[start_idx+len(res['original']):]
                res['cleaned'] = f'"{res["decrypted"]}"'
        return results, cleaned_code -> import re

def xor_decrypt(enc_list, key=42):
    """XOR decrypt a list of integers to a string."""
    try:
        return ''.join((chr(c ^ key) for c in enc_list))
    except Exception:
        return None

class StringDecryptor:
    """Detects and decrypts XOR-encrypted strings in code."""

    def __init__(self, key=42):
        self.key = key

    def detect_strings(self, code: str):
        """Detect candidate encrypted strings as list of integers."""
        pattern = re.compile('[\\[{]([0-9,\\s]+)[\\]}]')
        results = []
        for match in pattern.finditer(code):
            str_bytes = match.group(1)
            try:
                enc_list = [int(b.strip()) for b in str_bytes.split(',') if b.strip().isdigit()]
                decrypted = xor_decrypt(enc_list, self.key)
                if decrypted and all((32 <= ord(ch) <= 126 for ch in decrypted)):
                    results.append({'original': match.group(0), 'decrypted': decrypted, 'position': match.start(), 'reason': 'XOR-encrypted string detected and decrypted'})
            except Exception:
                continue
        return results

    def detect_and_clean(self, code: str):
        """Detect encrypted strings, replace them, and return changes and final code."""
        results = self.detect_strings(code)
        cleaned_code = code
        for res in reversed(results):
            start_idx = cleaned_code.find(res['original'])
            if start_idx != -1:
                cleaned_code = cleaned_code[:start_idx] + f'"{res['decrypted']}"' + cleaned_code[start_idx + len(res['original']):]
                res['cleaned'] = f'"{res['decrypted']}"'
        return (results, cleaned_code) (Full cleaned file (Python deadcode removal))



===== Inline Expansion =====

input\api_redirection.py: """
Detect API redirection/wrapper patterns:
  - tiny wrappers that call another function and do nothing else
  - multiple-level wrappers
Cleaning: inline trivial wrappers (calls) conservatively.
"""
import re
from typing import List, Dict

def detect_api_redirection_clike(code: str) -> List[Dict]:
    findings = []
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*\\((?:[^)]*)\\)\\s*\\{\\s*return\\s+([A-Za-z_]\\w*)\\s*\\(\\s*\\)\\s*;\\s*\\}', code):
        findings.append({'type': 'trivial_wrapper', 'lineno': code[:m.start()].count('\n') + 1, 'wrapper': m.group(1), 'target': m.group(2)})
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*\\(\\s*([^\\)]*)\\)\\s*\\{\\s*return\\s+([A-Za-z_]\\w*)\\s*\\(\\s*\\2\\s*\\)\\s*;\\s*\\}', code):
        findings.append({'type': 'arg_forwarding_wrapper', 'lineno': code[:m.start()].count('\n') + 1, 'wrapper': m.group(1), 'target': m.group(3)})
    return findings

def clean_api_redirection_clike(code: str) -> List[Dict]:
    changes = []
    s = code
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*\\((?:\\s*)\\)\\s*;\\s*', s):
        call_name = m.group(1)
        mm = re.search('\\b' + re.escape(call_name) + '\\s*\\([^)]*\\)\\s*\\{\\s*return\\s+([A-Za-z_]\\w*)\\s*\\(\\s*\\)\\s*;\\s*\\}', s)
        if mm:
            actual = mm.group(1)
            s_new = re.sub('\\b' + re.escape(call_name) + '\\s*\\(\\s*\\)', actual + '()', s)
            if s_new != s:
                changes.append({'original': call_name + '()', 'cleaned': actual + '()', 'reason': f'Inlined trivial wrapper {call_name} -> {actual}'})
                s = s_new
    if changes:
        changes.append({'original': code, 'cleaned': s, 'reason': 'Inlined trivial API wrappers (C-like)'})
    else:
        findings = detect_api_redirection_clike(code)
        if findings:
            changes.append({'original': '', 'cleaned': '', 'reason': f'Detected wrapper patterns but no safe automatic inlining performed: {findings}'})
    return changes

def detect_api_redirection_python(code: str) -> List[Dict]:
    findings = []
    for m in re.finditer('def\\s+([A-Za-z_]\\w*)\\s*\\([^)]*\\)\\s*:\\s*return\\s+([A-Za-z_]\\w*)\\s*\\(\\s*\\)\\s*', code):
        findings.append({'type': 'trivial_wrapper_py', 'lineno': code[:m.start()].count('\n') + 1, 'wrapper': m.group(1), 'target': m.group(2)})
    return findings

def clean_api_redirection_python(code: str) -> List[Dict]:
    s = code
    changes = []
    for m in re.finditer('def\\s+([A-Za-z_]\\w*)\\s*\\([^)]*\\)\\s*:\\s*return\\s+([A-Za-z_]\\w*)\\s*\\(\\s*\\)\\s*', s):
        wrapper = m.group(1)
        target = m.group(2)
        s_new = re.sub('\\b' + re.escape(wrapper) + '\\s*\\(\\s*\\)', target + '()', s)
        if s_new != s:
            changes.append({'original': wrapper + '() calls', 'cleaned': target + '()', 'reason': f'Inlined trivial wrapper {wrapper} -> {target}'})
            s = s_new
    if changes:
        changes.append({'original': code, 'cleaned': s, 'reason': 'Inlined trivial wrappers (Python)'})
    else:
        finds = detect_api_redirection_python(code)
        if finds:
            changes.append({'original': '', 'cleaned': '', 'reason': f'Detected wrappers: {finds}. No automatic inlining applied.'})
    return changes -> """
Detect API redirection/wrapper patterns:
  - tiny wrappers that call another function and do nothing else
  - multiple-level wrappers
Cleaning: inline trivial wrappers (calls) conservatively.
"""
import re
from typing import List, Dict

def detect_api_redirection_clike(code: str) -> List[Dict]:
    findings = []
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*\\((?:[^)]*)\\)\\s*\\{\\s*return\\s+([A-Za-z_]\\w*)\\s*\\(\\s*\\)\\s*;\\s*\\}', code):
        findings.append({'type': 'trivial_wrapper', 'lineno': code[:m.start()].count('\n') + 1, 'wrapper': m.group(1), 'target': m.group(2)})
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*\\(\\s*([^\\)]*)\\)\\s*\\{\\s*return\\s+([A-Za-z_]\\w*)\\s*\\(\\s*\\2\\s*\\)\\s*;\\s*\\}', code):
        findings.append({'type': 'arg_forwarding_wrapper', 'lineno': code[:m.start()].count('\n') + 1, 'wrapper': m.group(1), 'target': m.group(3)})
    return findings

def clean_api_redirection_clike(code: str) -> List[Dict]:
    changes = []
    s = code
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*\\((?:\\s*)\\)\\s*;\\s*', s):
        call_name = m.group(1)
        mm = re.search('\\b' + re.escape(call_name) + '\\s*\\([^)]*\\)\\s*\\{\\s*return\\s+([A-Za-z_]\\w*)\\s*\\(\\s*\\)\\s*;\\s*\\}', s)
        if mm:
            actual = mm.group(1)
            s_new = re.sub('\\b' + re.escape(call_name) + '\\s*\\(\\s*\\)', actual + '()', s)
            if s_new != s:
                changes.append({'original': call_name + '()', 'cleaned': actual + '()', 'reason': f'Inlined trivial wrapper {call_name} -> {actual}'})
                s = s_new
    if changes:
        changes.append({'original': code, 'cleaned': s, 'reason': 'Inlined trivial API wrappers (C-like)'})
    else:
        findings = detect_api_redirection_clike(code)
        if findings:
            changes.append({'original': '', 'cleaned': '', 'reason': f'Detected wrapper patterns but no safe automatic inlining performed: {findings}'})
    return changes

def detect_api_redirection_python(code: str) -> List[Dict]:
    findings = []
    for m in re.finditer('def\\s+([A-Za-z_]\\w*)\\s*\\([^)]*\\)\\s*:\\s*return\\s+([A-Za-z_]\\w*)\\s*\\(\\s*\\)\\s*', code):
        findings.append({'type': 'trivial_wrapper_py', 'lineno': code[:m.start()].count('\n') + 1, 'wrapper': m.group(1), 'target': m.group(2)})
    return findings

def clean_api_redirection_python(code: str) -> List[Dict]:
    s = code
    changes = []
    for m in re.finditer('def\\s+([A-Za-z_]\\w*)\\s*\\([^)]*\\)\\s*:\\s*return\\s+([A-Za-z_]\\w*)\\s*\\(\\s*\\)\\s*', s):
        wrapper = m.group(1)
        target = m.group(2)
        s_new = re.sub('\\b' + re.escape(wrapper) + '\\s*\\(\\s*\\)', target + '()', s)
        if s_new != s:
            changes.append({'original': wrapper + '() calls', 'cleaned': target + '()', 'reason': f'Inlined trivial wrapper {wrapper} -> {target}'})
            s = s_new
    if changes:
        changes.append({'original': code, 'cleaned': s, 'reason': 'Inlined trivial wrappers (Python)'})
    else:
        finds = detect_api_redirection_python(code)
        if finds:
            changes.append({'original': '', 'cleaned': '', 'reason': f'Detected wrappers: {finds}. No automatic inlining applied.'})
    return changes (Full cleaned file (Python inline folding))
input\controlFlow.py: # -------------------- controlflow.py --------------------
import re
from typing import List, Dict, Tuple

class FakeConditionCleaner:
    """
    Detect and clean fake/unreachable conditions from source code.
    Reports detailed mapping of:
        - original (obfuscated) code snippet
        - cleaned (deobfuscated) snippet
        - reason for change
    """

    def __init__(self):
        # Patterns for fake conditions
        self.python_patterns = [
            (re.compile(r'if\s+False\s*:\s*', re.IGNORECASE), "Unreachable branch (condition always False)"),
            (re.compile(r'if\s+True\s*:\s*', re.IGNORECASE), "Always-true condition simplified (kept body, removed if header)"),
            (re.compile(r'if\s+[^\n]*>\s*\d+\s+and\s+[^\n]*<\s*\d+\s*:\s*', re.IGNORECASE),
             "Contradictory numeric range in condition (impossible)")
        ]

        self.c_like_patterns = [
            (re.compile(r'if\s*\(\s*(false|0)\s*\)', re.IGNORECASE), "Unreachable branch (condition always false)"),
            (re.compile(r'if\s*\(\s*(true|1)\s*\)', re.IGNORECASE), "Always-true condition simplified (kept statement/block, removed condition header)"),
            (re.compile(r'if\s*\([^)]*>\s*\d+\s*&&\s*[^)]*<\s*\d+\)', re.IGNORECASE),
             "Contradictory numeric range in condition (impossible)")
        ]

    # ---------- Python helper ----------
    def _extract_python_if_block(self, code: str, match_start: int) -> Tuple[str, str]:
        header_end = code.find('\n', match_start)
        if header_end == -1:
            return code[match_start:], code[:match_start]

        header = code[match_start:header_end+1]
        body_start = header_end + 1
        end = body_start
        while True:
            if end >= len(code):
                break
            nl = code.find('\n', end)
            if nl == -1:
                nl = len(code)
            line = code[end:nl]
            if not line or not (line"*" == ' ' or line"*" == '\t'):
                break
            end = nl + 1
        removed = code[match_start:end]
        new_code = code[:match_start] + code[end:]
        return removed, new_code

    def _dedent_python_body(self, body_text: str) -> str:
        lines = body_text.splitlines()
        indents = [len(re.match(r'^[ \t]+', ln).group(0)) for ln in lines if ln.strip() and re.match(r'^[ \t]+', ln)]
        if not indents:
            return "\n".join(lines) + ("\n" if body_text.endswith("\n") else "")
        min_indent = min(indents)
        dedented_lines = [ln[min_indent:] if len(ln) >= min_indent else ln for ln in lines]
        return "\n".join(dedented_lines) + ("\n" if body_text.endswith("\n") else "")

    # ---------- C-like helper ----------
    def _extract_c_like_block_or_line(self, code: str, start_idx: int) -> Tuple[str, str]:
        i = start_idx
        while i < len(code) and code[i].isspace():
            i += 1
        if i < len(code) and code[i] == '{':
            stack = ['{']
            end = i + 1
            while stack and end < len(code):
                if code[end] == '{': stack.append('{')
                elif code[end] == '}': stack.pop()
                end += 1
            removed = code[start_idx:end]
            return removed, code[:start_idx] + code[end:]
        else:
            end = i
            while end < len(code) and code[end] not in (';', '\n'):
                end += 1
            if end < len(code) and code[end] == ';': end += 1
            removed = code[start_idx:end]
            return removed, code[:start_idx] + code[end:]

    # ---------- Detection ----------
    def detect_fake_conditions(self, code: str) -> List[Dict]:
        findings = []

        # Python
        for pat, reason in self.python_patterns:
            for m in pat.finditer(code):
                findings.append({"condition": m.group(0), "position": m.start(), "reason": reason})

        # C-like
        for pat, reason in self.c_like_patterns:
            for m in pat.finditer(code):
                findings.append({"condition": m.group(0), "position": m.start(), "reason": reason})

        return findings

    # ---------- Cleaning ----------
    def clean_code(self, code: str) -> List[Dict]:
        """
        Returns a list of changes:
        [
            {"original": ..., "cleaned": ..., "reason": ...},
            ...
        ]
        """
        changes = []
        cleaned_code = code

        # Python patterns
        for pat, reason in self.python_patterns:
            while True:
                m = pat.search(cleaned_code)
                if not m: break
                start = m.start()
                removed, cleaned_code = self._extract_python_if_block(cleaned_code, start)
                if "True" in m.group(0):
                    header_end = removed.find('\n')
                    body = removed[header_end+1:] if header_end != -1 else ""
                    dedented_body = self._dedent_python_body(body)
                    cleaned_code = cleaned_code[:start] + dedented_body + cleaned_code[start:]
                    changes.append({"original": removed, "cleaned": dedented_body, "reason": reason})
                else:
                    changes.append({"original": removed, "cleaned": "", "reason": reason})

        # C-like patterns
        for pat, reason in self.c_like_patterns:
            while True:
                m = pat.search(cleaned_code)
                if not m: break
                start = m.start()
                removed, cleaned_code = self._extract_c_like_block_or_line(cleaned_code, start)
                if "true" in m.group(0).lower() or "1" in m.group(0):
                    # Keep block/statement only
                    if '{' in removed:
                        block_start = removed.find('{')
                        block = removed[block_start:]
                        cleaned_code = cleaned_code[:start] + block + cleaned_code[start:]
                        changes.append({"original": removed, "cleaned": block, "reason": reason})
                    else:
                        # single statement
                        stmt = removed[m.end()-start:]
                        cleaned_code = cleaned_code[:start] + stmt + cleaned_code[start:]
                        changes.append({"original": removed, "cleaned": stmt, "reason": reason})
                else:
                    changes.append({"original": removed, "cleaned": "", "reason": reason})

        return changes -> # -------------------- controlflow.py --------------------
import re
from typing import List, Dict, Tuple

class FakeConditionCleaner:
    """
    Detect and clean fake/unreachable conditions from source code.
    Reports detailed mapping of:
        - original (obfuscated) code snippet
        - cleaned (deobfuscated) snippet
        - reason for change
    """

    def __init__(self):
        # Patterns for fake conditions
        self.python_patterns = [
            (re.compile(r'if\s+False\s*:\s*', re.IGNORECASE), "Unreachable branch (condition always False)"),
            (re.compile(r'if\s+True\s*:\s*', re.IGNORECASE), "Always-true condition simplified (kept body, removed if header)"),
            (re.compile(r'if\s+[^\n]*>\s*\d+\s+and\s+[^\n]*<\s*\d+\s*:\s*', re.IGNORECASE),
             "Contradictory numeric range in condition (impossible)")
        ]

        self.c_like_patterns = [
            (re.compile(r'if\s*\(\s*(false|0)\s*\)', re.IGNORECASE), "Unreachable branch (condition always false)"),
            (re.compile(r'if\s*\(\s*(true|1)\s*\)', re.IGNORECASE), "Always-true condition simplified (kept statement/block, removed condition header)"),
            (re.compile(r'if\s*\([^)]*>\s*\d+\s*&&\s*[^)]*<\s*\d+\)', re.IGNORECASE),
             "Contradictory numeric range in condition (impossible)")
        ]

    # ---------- Python helper ----------
    def _extract_python_if_block(self, code: str, match_start: int) -> Tuple[str, str]:
        header_end = code.find('\n', match_start)
        if header_end == -1:
            return code[match_start:], code[:match_start]

        header = code[match_start:header_end+1]
        body_start = header_end + 1
        end = body_start
        while True:
            if end >= len(code):
                break
            nl = code.find('\n', end)
            if nl == -1:
                nl = len(code)
            line = code[end:nl]
            if not line or not (line"*" == ' ' or line"*" == '\t'):
                break
            end = nl + 1
        removed = code[match_start:end]
        new_code = code[:match_start] + code[end:]
        return removed, new_code

    def _dedent_python_body(self, body_text: str) -> str:
        lines = body_text.splitlines()
        indents = [len(re.match(r'^[ \t]+', ln).group(0)) for ln in lines if ln.strip() and re.match(r'^[ \t]+', ln)]
        if not indents:
            return "\n".join(lines) + ("\n" if body_text.endswith("\n") else "")
        min_indent = min(indents)
        dedented_lines = [ln[min_indent:] if len(ln) >= min_indent else ln for ln in lines]
        return "\n".join(dedented_lines) + ("\n" if body_text.endswith("\n") else "")

    # ---------- C-like helper ----------
    def _extract_c_like_block_or_line(self, code: str, start_idx: int) -> Tuple[str, str]:
        i = start_idx
        while i < len(code) and code[i].isspace():
            i += 1
        if i < len(code) and code[i] == '{':
            stack = ['{']
            end = i + 1
            while stack and end < len(code):
                if code[end] == '{': stack.append('{')
                elif code[end] == '}': stack.pop()
                end += 1
            removed = code[start_idx:end]
            return removed, code[:start_idx] + code[end:]
        else:
            end = i
            while end < len(code) and code[end] not in (';', '\n'):
                end += 1
            if end < len(code) and code[end] == ';': end += 1
            removed = code[start_idx:end]
            return removed, code[:start_idx] + code[end:]

    # ---------- Detection ----------
    def detect_fake_conditions(self, code: str) -> List[Dict]:
        findings = []

        # Python
        for pat, reason in self.python_patterns:
            for m in pat.finditer(code):
                findings.append({"condition": m.group(0), "position": m.start(), "reason": reason})

        # C-like
        for pat, reason in self.c_like_patterns:
            for m in pat.finditer(code):
                findings.append({"condition": m.group(0), "position": m.start(), "reason": reason})

        return findings

    # ---------- Cleaning ----------
    def clean_code(self, code: str) -> List[Dict]:
        """
        Returns a list of changes:
        [
            {"original": ..., "cleaned": ..., "reason": ...},
            ...
        ]
        """
        changes = []
        cleaned_code = code

        # Python patterns
        for pat, reason in self.python_patterns:
            while True:
                m = pat.search(cleaned_code)
                if not m: break
                start = m.start()
                removed, cleaned_code = self._extract_python_if_block(cleaned_code, start)
                if "True" in m.group(0):
                    header_end = removed.find('\n')
                    body = removed[header_end+1:] if header_end != -1 else ""
                    dedented_body = self._dedent_python_body(body)
                    cleaned_code = cleaned_code[:start] + dedented_body + cleaned_code[start:]
                    changes.append({"original": removed, "cleaned": dedented_body, "reason": reason})
                else:
                    changes.append({"original": removed, "cleaned": "", "reason": reason})

        # C-like patterns
        for pat, reason in self.c_like_patterns:
            while True:
                m = pat.search(cleaned_code)
                if not m: break
                start = m.start()
                removed, cleaned_code = self._extract_c_like_block_or_line(cleaned_code, start)
                if "true" in m.group(0).lower() or "1" in m.group(0):
                    # Keep block/statement only
                    if '{' in removed:
                        block_start = removed.find('{')
                        block = removed[block_start:]
                        cleaned_code = cleaned_code[:start] + block + cleaned_code[start:]
                        changes.append({"original": removed, "cleaned": block, "reason": reason})
                    else:
                        # single statement
                        stmt = removed[m.end()-start:]
                        cleaned_code = cleaned_code[:start] + stmt + cleaned_code[start:]
                        changes.append({"original": removed, "cleaned": stmt, "reason": reason})
                else:
                    changes.append({"original": removed, "cleaned": "", "reason": reason})

        return changes (parse_error: invalid syntax. Perhaps you forgot a comma? (<unknown>, line 46))
input\controlflow_flattening.py: '// Suggested deobfuscated sequence\n' + '/* case1 */\n' -> '// Suggested deobfuscated sequence\n/* case1 */\n' (Constant folded)
input\controlflow_flattening.py: """
Detect/control-flow flattening patterns (dispatcher loops, state-machine switch inside loop).
Conservative detection + optional simple unflatten attempt (only for tiny patterns).
"""
import re
import ast
from typing import List, Dict

def detect_controlflow_flattening_clike(code: str) -> List[Dict]:
    findings = []
    pattern = re.compile('\\bwhile\\s*\\(\\s*(?:1|true)\\s*\\)\\s*\\{.*?\\b(switch|if)\\s*\\s*\\([^)]*\\)\\s*\\{', re.IGNORECASE | re.DOTALL)
    if pattern.search(code):
        findings.append({'type': 'dispatcher_loop', 'reason': 'while(true)/switch dispatcher pattern', 'hint': 'control-flow flattening (C-like)'})
    if re.search('\\bstate\\s*=\\s*\\d+\\s*;', code):
        findings.append({'type': 'state_var', 'reason': 'state variable updated inside loop', 'hint': 'possible flattened flow'})
    return findings

def clean_controlflow_flattening_clike(code: str) -> List[Dict]:
    """
    Conservative: we will not attempt full de-flattening.
    Instead, we:
      - detect small dispatcher with 2-3 cases and produce a suggested straight-line replacement as text,
        but do not modify code automatically unless pattern exactly matches a simple form.
    Returns list of change dicts; last item contains full cleaned placeholder if applied.
    """
    changes = []
    m = re.search('while\\s*\\(\\s*(?:1|true)\\s*\\)\\s*\\{\\s*switch\\s*\\(\\s*state\\s*\\)\\s*\\{\\s*(case\\s*1\\s*:\\s*([^}]*)break\\s*;)\\s*(case\\s*2\\s*:\\s*([^}]*)break\\s*;)\\s*\\}\\s*\\}', code, re.DOTALL | re.IGNORECASE)
    if m:
        case1 = m.group(2).strip()
        case2 = m.group(4).strip()
        suggested = '// Suggested deobfuscated sequence\n' + '/* case1 */\n' + case1 + '\n/* case2 */\n' + case2 + '\n'
        changes.append({'original': m.group(0), 'cleaned': suggested, 'reason': 'Simple dispatcher unflattened into sequential suggestions'})
        cleaned = code[:m.start()] + suggested + code[m.end():]
        changes.append({'original': code, 'cleaned': cleaned, 'reason': 'Applied small-scope unflatten (C-like) - manual review required'})
    elif detect_controlflow_flattening_clike(code):
        changes.append({'original': '', 'cleaned': '', 'reason': 'Detected control-flow flattening patterns, no automatic rewrite performed (too risky).'})
    return changes

def detect_controlflow_flattening_python(code: str) -> List[Dict]:
    findings = []
    if re.search('while\\s+True\\s*:\\s*', code):
        if re.search('\\b(state|mode)\\b', code) and re.search('\\bif\\b.*\\belse\\b', code, re.DOTALL):
            findings.append({'type': 'dispatcher_loop_py', 'reason': 'while True with state/if-dispatch found'})
    if re.search('\\{.*lambda.*:.*\\}', code, re.DOTALL):
        findings.append({'type': 'dict_dispatch', 'reason': 'dictionary-based dispatcher (python)'})
    return findings

def clean_controlflow_flattening_python(code: str) -> List[Dict]:
    findings = detect_controlflow_flattening_python(code)
    if findings:
        return [{'original': '', 'cleaned': '', 'reason': 'Detected Python flattened control-flow patterns. Manual reconstruction recommended.'}]
    return [] -> """
Detect/control-flow flattening patterns (dispatcher loops, state-machine switch inside loop).
Conservative detection + optional simple unflatten attempt (only for tiny patterns).
"""
import re
import ast
from typing import List, Dict

def detect_controlflow_flattening_clike(code: str) -> List[Dict]:
    findings = []
    pattern = re.compile('\\bwhile\\s*\\(\\s*(?:1|true)\\s*\\)\\s*\\{.*?\\b(switch|if)\\s*\\s*\\([^)]*\\)\\s*\\{', re.IGNORECASE | re.DOTALL)
    if pattern.search(code):
        findings.append({'type': 'dispatcher_loop', 'reason': 'while(true)/switch dispatcher pattern', 'hint': 'control-flow flattening (C-like)'})
    if re.search('\\bstate\\s*=\\s*\\d+\\s*;', code):
        findings.append({'type': 'state_var', 'reason': 'state variable updated inside loop', 'hint': 'possible flattened flow'})
    return findings

def clean_controlflow_flattening_clike(code: str) -> List[Dict]:
    """
    Conservative: we will not attempt full de-flattening.
    Instead, we:
      - detect small dispatcher with 2-3 cases and produce a suggested straight-line replacement as text,
        but do not modify code automatically unless pattern exactly matches a simple form.
    Returns list of change dicts; last item contains full cleaned placeholder if applied.
    """
    changes = []
    m = re.search('while\\s*\\(\\s*(?:1|true)\\s*\\)\\s*\\{\\s*switch\\s*\\(\\s*state\\s*\\)\\s*\\{\\s*(case\\s*1\\s*:\\s*([^}]*)break\\s*;)\\s*(case\\s*2\\s*:\\s*([^}]*)break\\s*;)\\s*\\}\\s*\\}', code, re.DOTALL | re.IGNORECASE)
    if m:
        case1 = m.group(2).strip()
        case2 = m.group(4).strip()
        suggested = '// Suggested deobfuscated sequence\n/* case1 */\n' + case1 + '\n/* case2 */\n' + case2 + '\n'
        changes.append({'original': m.group(0), 'cleaned': suggested, 'reason': 'Simple dispatcher unflattened into sequential suggestions'})
        cleaned = code[:m.start()] + suggested + code[m.end():]
        changes.append({'original': code, 'cleaned': cleaned, 'reason': 'Applied small-scope unflatten (C-like) - manual review required'})
    elif detect_controlflow_flattening_clike(code):
        changes.append({'original': '', 'cleaned': '', 'reason': 'Detected control-flow flattening patterns, no automatic rewrite performed (too risky).'})
    return changes

def detect_controlflow_flattening_python(code: str) -> List[Dict]:
    findings = []
    if re.search('while\\s+True\\s*:\\s*', code):
        if re.search('\\b(state|mode)\\b', code) and re.search('\\bif\\b.*\\belse\\b', code, re.DOTALL):
            findings.append({'type': 'dispatcher_loop_py', 'reason': 'while True with state/if-dispatch found'})
    if re.search('\\{.*lambda.*:.*\\}', code, re.DOTALL):
        findings.append({'type': 'dict_dispatch', 'reason': 'dictionary-based dispatcher (python)'})
    return findings

def clean_controlflow_flattening_python(code: str) -> List[Dict]:
    findings = detect_controlflow_flattening_python(code)
    if findings:
        return [{'original': '', 'cleaned': '', 'reason': 'Detected Python flattened control-flow patterns. Manual reconstruction recommended.'}]
    return [] (Full cleaned file (Python inline folding))
input\deadCode.py: """# Dead Code Test Cases

# 1. Unused variable
x = 10   # dead
y = 20
print(y)

# 2. If condition always True
print("Always runs")
else:
    print("Dead branch")

# 3. If condition always False
else:
    print("Always runs")

# 4. Code after return
def f1():
    return 5
    print("Dead")  # dead

# 5. Code after break
for i in range(3):
    break
    print("Dead")  # dead

# 6. Unreachable else
print("Run")
else:
    print("Dead")

# 7. While False loop
while False:
    print("Never runs")  # dead

# 8. Constant condition (0 is False)
if 0:
    print("Dead")
else:
    print("Runs")

# 9. Constant condition (non-zero is True)
if 1:
    print("Runs")
else:
    print("Dead")

# 10. Multiple returns
def f2(x):
    if x > 0:
        return 1
        print("Dead")  # dead
    else:
        return -1
"""

# analyzers/deadcode.py
import ast
import re
from typing import List, Dict, Tuple

# --------------------------
# Python (AST) helpers
# --------------------------
class _DeadCodeRemover(ast.NodeTransformer):
    """
    Transformations:
      - remove `
    def visit_If(self, node: ast.If):
        # evaluate constant tests only
        try:
            if isinstance(node.test, ast.Constant):
                val = node.test.value
                if val is False:
                    original = ast.get_source_segment(self.source_text, node) if hasattr(self, "source_text") else ast.unparse(node)
                    # remove the entire if-block
                    self.changes.append((original, "", "If condition is constant False (dead code)"))
                    return None  # remove node
                elif val is True:
                    # keep body in place of if
                    body_nodes = [self.visit(b) for b in node.body]
                    original = ast.get_source_segment(self.source_text, node) if hasattr(self, "source_text") else ast.unparse(node)
                    cleaned = "\n".join([ast.unparse(b) for b in body_nodes if b is not None])
                    self.changes.append((original, cleaned, "If condition is constant True (inlined body)"))
                    return body_nodes  # splice body
        except Exception:
            pass
        self.generic_visit(node)
        return node

    def run(self, tree: ast.AST, source_text: str):
        self.source_text = source_text
        new_tree = self.visit(tree)
        return new_tree, self.changes


def detect_deadcode_python(code: str) -> List[Dict]:
    """
    Detect dead-code patterns in Python source using AST scanning.
    Returns list of findings (simple descriptions and line numbers).
    """
    findings = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        findings.append({"type": "parse_error", "reason": str(e)})
        return findings

    # If/While constant tests
    class V(ast.NodeVisitor):
        def visit_If(self, node):
            if isinstance(node.test, ast.Constant):
                if node.test.value is False:
                    findings.append({"type": "dead_if_false", "lineno": node.lineno, "snippet": ast.unparse(node.test)})
                elif node.test.value is True:
                    findings.append({"type": "dead_else", "lineno": node.lineno, "snippet": ast.unparse(node.test)})
            self.generic_visit(node)

        def visit_While(self, node):
            if isinstance(node.test, ast.Constant) and node.test.value is False:
                findings.append({"type": "dead_while_false", "lineno": node.lineno})
            self.generic_visit(node)

        def visit_FunctionDef(self, node):
            # detect code after return in function body
            for i, stmt in enumerate(node.body):
                if isinstance(stmt, ast.Return):
                    for later in node.body[i+1:]:
                        findings.append({"type": "dead_after_return", "lineno": getattr(later, "lineno", None), "func": node.name})
            self.generic_visit(node)

        def visit_Assign(self, node):
            # naive assigned variable capture (we'll refine in unused)
            self.generic_visit(node)

    V().visit(tree)

    # Unused variables: track simple assignments and loads
    assigned = {}
    used = set()
    class U(ast.NodeVisitor):
        def visit_Assign(self, node):
            if len(node.targets) == 1 and isinstance(node.targets"*", ast.Name):
                assigned[node.targets"*".id] = getattr(node, "lineno", None)
            self.generic_visit(node)
        def visit_Name(self, node):
            if isinstance(node.ctx, ast.Load):
                used.add(node.id)
    U().visit(tree)
    for var, lineno in assigned.items():
        if var not in used:
            findings.append({"type": "unused_var", "var": var, "lineno": lineno})

    return findings


def clean_deadcode_python(code: str) -> List[Dict]:
    """
    Attempt to remove dead code in Python source.
    Returns list of changes: {"original":..., "cleaned":..., "reason":...}
    """
    results = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{"original": code, "cleaned": code, "reason": f"parse_error: {e}"}]

    remover = _DeadCodeRemover()
    new_tree, changes = remover.run(tree, code)
    # unparse new_tree (may be list when splicing body — handle carefully)
    try:
        cleaned_code = ast.unparse(new_tree) if not isinstance(new_tree, list) else "\n".join(ast.unparse(n) for n in new_tree)
    except Exception:
        # fallback: do not change
        cleaned_code = code

    for orig, cleaned, reason in changes:
        results.append({"original": orig, "cleaned": cleaned, "reason": reason})

    # Also remove simple unused assignments by regex (safe: only single-name assigns to literal)
    # e.g., `x = 4` where x not used — remove those lines if they exist exactly.
    # We already reported unused vars above; here perform textual removal for simple case.
    facts = detect_deadcode_python(code)
    for f in facts:
        if f.get("type") == "unused_var" and isinstance(f.get("lineno"), int):
            lines = cleaned_code.splitlines()
            idx = f["lineno"] - 1
            if 0 <= idx < len(lines):
                orig_line = lines[idx]
                # verify assignment pattern
                if re.match(r'^\s*' + re.escape(f["var"]) + r'\s*=\s*[^#\n]+', orig_line):
                    lines[idx] = ""  # remove
                    results.append({"original": orig_line + "\n", "cleaned": "", "reason": f"Removed unused assignment '{f['var']}'"})
                    cleaned_code = "\n".join(lines)
    # Return changes and cleaned code appended as last item
    results.append({"original": code, "cleaned": cleaned_code, "reason": "Full cleaned file (Python deadcode removal)"})
    return results


# --------------------------
# C-like regex helpers
# --------------------------
def detect_deadcode_clike(code: str, ext_tag: str = "C-like") -> List[Dict]:
    findings = []
    lines = code.splitlines()
    for i, line in enumerate(lines, start=1):
        if re.search(r'\bif\s*\(\s*(false|0)\s*\)', line, re.IGNORECASE):
            findings.append({"type": "dead_if_false", "lineno": i, "snippet": line.strip(), "lang": ext_tag})
        if re.search(r'\bwhile\s*\(\s*(false|0)\s*\)', line, re.IGNORECASE):
            findings.append({"type": "dead_while_false", "lineno": i, "snippet": line.strip(), "lang": ext_tag})
        if re.search(r'\breturn\b.*;', line) and i < len(lines) and lines[i].strip():
            findings.append({"type": "after_return", "lineno": i+1, "snippet": lines[i].strip(), "lang": ext_tag})
    return findings


def clean_deadcode_clike(code: str) -> List[Dict]:
    """
    Clean simple C-like dead code:
      - remove `
      - replace `{ ... }` with block contents (strip braces)
      - remove single-line unused var assignments that are literal and not used elsewhere (conservative)
    Returns list of changes
    """
    changes = []
    s = code

    # remove 
    pattern_false_block = re.compile(r'\bif\s*\(\s*(?:false|0)\s*\)\s*(\{(?:[^{}]*|\{[^}]*\})*\}|[^;]*;)', re.IGNORECASE | re.DOTALL)
    while True:
        m = pattern_false_block.search(s)
        if not m: break
        orig = m.group(0)
        s = s[:m.start()] + s[m.end():]
        changes.append({"original": orig, "cleaned": "", "reason": "

    # inline { block } => replace with block contents
    pattern_true_block = re.compile(r'\bif\s*\(\s*(?:true|1)\s*\)\s*(\{(?:[^{}]*|\{[^}]*\})*\}|[^;]*;)', re.IGNORECASE | re.DOTALL)
    while True:
        m = pattern_true_block.search(s)
        if not m: break
        orig = m.group(0)
        blk = m.group(1)
        # strip outer braces if present
        if blk.strip().startswith("{") and blk.strip().endswith("}"):
            inner = blk.strip()[1:-1]
        else:
            inner = blk
        s = s[:m.start()] + inner + s[m.end():]
        changes.append({"original": orig, "cleaned": inner, "reason": " inlined (kept body)"})

    # conservative removal of simple unused assignments: pattern `int x = 4;` only if var name does not appear elsewhere
    assign_pattern = re.compile(r'\b(?:int|long|char|float|double)\s+([A-Za-z_]\w*)\s*=\s*[^;]+;')
    for m in assign_pattern.finditer(s):
        var = m.group(1)
        # if var occurs only once (the definition), remove it
        if len(re.findall(r'\b' + re.escape(var) + r'\b', s)) == 1:
            orig = m.group(0)
            s = s[:m.start()] + s[m.end():]
            changes.append({"original": orig, "cleaned": "", "reason": f"Removed likely-unused declaration '{var}'"})

    changes.append({"original": code, "cleaned": s, "reason": "Full cleaned file (C-like deadcode removal)"})
    return changes
 -> """# Dead Code Test Cases

# 1. Unused variable
x = 10   # dead
y = 20
print(y)

# 2. If condition always True
print("Always runs")
else:
    print("Dead branch")

# 3. If condition always False
else:
    print("Always runs")

# 4. Code after return
def f1():
    return 5
    print("Dead")  # dead

# 5. Code after break
for i in range(3):
    break
    print("Dead")  # dead

# 6. Unreachable else
print("Run")
else:
    print("Dead")

# 7. While False loop
while False:
    print("Never runs")  # dead

# 8. Constant condition (0 is False)
if 0:
    print("Dead")
else:
    print("Runs")

# 9. Constant condition (non-zero is True)
if 1:
    print("Runs")
else:
    print("Dead")

# 10. Multiple returns
def f2(x):
    if x > 0:
        return 1
        print("Dead")  # dead
    else:
        return -1
"""

# analyzers/deadcode.py
import ast
import re
from typing import List, Dict, Tuple

# --------------------------
# Python (AST) helpers
# --------------------------
class _DeadCodeRemover(ast.NodeTransformer):
    """
    Transformations:
      - remove `
    def visit_If(self, node: ast.If):
        # evaluate constant tests only
        try:
            if isinstance(node.test, ast.Constant):
                val = node.test.value
                if val is False:
                    original = ast.get_source_segment(self.source_text, node) if hasattr(self, "source_text") else ast.unparse(node)
                    # remove the entire if-block
                    self.changes.append((original, "", "If condition is constant False (dead code)"))
                    return None  # remove node
                elif val is True:
                    # keep body in place of if
                    body_nodes = [self.visit(b) for b in node.body]
                    original = ast.get_source_segment(self.source_text, node) if hasattr(self, "source_text") else ast.unparse(node)
                    cleaned = "\n".join([ast.unparse(b) for b in body_nodes if b is not None])
                    self.changes.append((original, cleaned, "If condition is constant True (inlined body)"))
                    return body_nodes  # splice body
        except Exception:
            pass
        self.generic_visit(node)
        return node

    def run(self, tree: ast.AST, source_text: str):
        self.source_text = source_text
        new_tree = self.visit(tree)
        return new_tree, self.changes


def detect_deadcode_python(code: str) -> List[Dict]:
    """
    Detect dead-code patterns in Python source using AST scanning.
    Returns list of findings (simple descriptions and line numbers).
    """
    findings = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        findings.append({"type": "parse_error", "reason": str(e)})
        return findings

    # If/While constant tests
    class V(ast.NodeVisitor):
        def visit_If(self, node):
            if isinstance(node.test, ast.Constant):
                if node.test.value is False:
                    findings.append({"type": "dead_if_false", "lineno": node.lineno, "snippet": ast.unparse(node.test)})
                elif node.test.value is True:
                    findings.append({"type": "dead_else", "lineno": node.lineno, "snippet": ast.unparse(node.test)})
            self.generic_visit(node)

        def visit_While(self, node):
            if isinstance(node.test, ast.Constant) and node.test.value is False:
                findings.append({"type": "dead_while_false", "lineno": node.lineno})
            self.generic_visit(node)

        def visit_FunctionDef(self, node):
            # detect code after return in function body
            for i, stmt in enumerate(node.body):
                if isinstance(stmt, ast.Return):
                    for later in node.body[i+1:]:
                        findings.append({"type": "dead_after_return", "lineno": getattr(later, "lineno", None), "func": node.name})
            self.generic_visit(node)

        def visit_Assign(self, node):
            # naive assigned variable capture (we'll refine in unused)
            self.generic_visit(node)

    V().visit(tree)

    # Unused variables: track simple assignments and loads
    assigned = {}
    used = set()
    class U(ast.NodeVisitor):
        def visit_Assign(self, node):
            if len(node.targets) == 1 and isinstance(node.targets"*", ast.Name):
                assigned[node.targets"*".id] = getattr(node, "lineno", None)
            self.generic_visit(node)
        def visit_Name(self, node):
            if isinstance(node.ctx, ast.Load):
                used.add(node.id)
    U().visit(tree)
    for var, lineno in assigned.items():
        if var not in used:
            findings.append({"type": "unused_var", "var": var, "lineno": lineno})

    return findings


def clean_deadcode_python(code: str) -> List[Dict]:
    """
    Attempt to remove dead code in Python source.
    Returns list of changes: {"original":..., "cleaned":..., "reason":...}
    """
    results = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{"original": code, "cleaned": code, "reason": f"parse_error: {e}"}]

    remover = _DeadCodeRemover()
    new_tree, changes = remover.run(tree, code)
    # unparse new_tree (may be list when splicing body — handle carefully)
    try:
        cleaned_code = ast.unparse(new_tree) if not isinstance(new_tree, list) else "\n".join(ast.unparse(n) for n in new_tree)
    except Exception:
        # fallback: do not change
        cleaned_code = code

    for orig, cleaned, reason in changes:
        results.append({"original": orig, "cleaned": cleaned, "reason": reason})

    # Also remove simple unused assignments by regex (safe: only single-name assigns to literal)
    # e.g., `x = 4` where x not used — remove those lines if they exist exactly.
    # We already reported unused vars above; here perform textual removal for simple case.
    facts = detect_deadcode_python(code)
    for f in facts:
        if f.get("type") == "unused_var" and isinstance(f.get("lineno"), int):
            lines = cleaned_code.splitlines()
            idx = f["lineno"] - 1
            if 0 <= idx < len(lines):
                orig_line = lines[idx]
                # verify assignment pattern
                if re.match(r'^\s*' + re.escape(f["var"]) + r'\s*=\s*[^#\n]+', orig_line):
                    lines[idx] = ""  # remove
                    results.append({"original": orig_line + "\n", "cleaned": "", "reason": f"Removed unused assignment '{f['var']}'"})
                    cleaned_code = "\n".join(lines)
    # Return changes and cleaned code appended as last item
    results.append({"original": code, "cleaned": cleaned_code, "reason": "Full cleaned file (Python deadcode removal)"})
    return results


# --------------------------
# C-like regex helpers
# --------------------------
def detect_deadcode_clike(code: str, ext_tag: str = "C-like") -> List[Dict]:
    findings = []
    lines = code.splitlines()
    for i, line in enumerate(lines, start=1):
        if re.search(r'\bif\s*\(\s*(false|0)\s*\)', line, re.IGNORECASE):
            findings.append({"type": "dead_if_false", "lineno": i, "snippet": line.strip(), "lang": ext_tag})
        if re.search(r'\bwhile\s*\(\s*(false|0)\s*\)', line, re.IGNORECASE):
            findings.append({"type": "dead_while_false", "lineno": i, "snippet": line.strip(), "lang": ext_tag})
        if re.search(r'\breturn\b.*;', line) and i < len(lines) and lines[i].strip():
            findings.append({"type": "after_return", "lineno": i+1, "snippet": lines[i].strip(), "lang": ext_tag})
    return findings


def clean_deadcode_clike(code: str) -> List[Dict]:
    """
    Clean simple C-like dead code:
      - remove `
      - replace `{ ... }` with block contents (strip braces)
      - remove single-line unused var assignments that are literal and not used elsewhere (conservative)
    Returns list of changes
    """
    changes = []
    s = code

    # remove 
    pattern_false_block = re.compile(r'\bif\s*\(\s*(?:false|0)\s*\)\s*(\{(?:[^{}]*|\{[^}]*\})*\}|[^;]*;)', re.IGNORECASE | re.DOTALL)
    while True:
        m = pattern_false_block.search(s)
        if not m: break
        orig = m.group(0)
        s = s[:m.start()] + s[m.end():]
        changes.append({"original": orig, "cleaned": "", "reason": "

    # inline { block } => replace with block contents
    pattern_true_block = re.compile(r'\bif\s*\(\s*(?:true|1)\s*\)\s*(\{(?:[^{}]*|\{[^}]*\})*\}|[^;]*;)', re.IGNORECASE | re.DOTALL)
    while True:
        m = pattern_true_block.search(s)
        if not m: break
        orig = m.group(0)
        blk = m.group(1)
        # strip outer braces if present
        if blk.strip().startswith("{") and blk.strip().endswith("}"):
            inner = blk.strip()[1:-1]
        else:
            inner = blk
        s = s[:m.start()] + inner + s[m.end():]
        changes.append({"original": orig, "cleaned": inner, "reason": " inlined (kept body)"})

    # conservative removal of simple unused assignments: pattern `int x = 4;` only if var name does not appear elsewhere
    assign_pattern = re.compile(r'\b(?:int|long|char|float|double)\s+([A-Za-z_]\w*)\s*=\s*[^;]+;')
    for m in assign_pattern.finditer(s):
        var = m.group(1)
        # if var occurs only once (the definition), remove it
        if len(re.findall(r'\b' + re.escape(var) + r'\b', s)) == 1:
            orig = m.group(0)
            s = s[:m.start()] + s[m.end():]
            changes.append({"original": orig, "cleaned": "", "reason": f"Removed likely-unused declaration '{var}'"})

    changes.append({"original": code, "cleaned": s, "reason": "Full cleaned file (C-like deadcode removal)"})
    return changes
 (parse_error: unterminated triple-quoted string literal (detected at line 262) (<unknown>, line 223))
input\dynamic_loading.py: """
Detect dynamic code loading/reflection/indirect calls:
 - Python: eval, exec, compile, importlib, getattr/locals tricks
 - C/C++: function pointers, dlsym, system/exec calls
 - Java/Kotlin: reflection usage (Class.forName, Method.invoke)
Cleaning is conservative: we only report and, for trivial indirect calls (wrapper->function pointer),
we can sometimes inline wrapper.
"""
import re
from typing import List, Dict
_PY_DYN = [re.compile('\\beval\\s*\\('), re.compile('\\bexec\\s*\\('), re.compile('\\bcompile\\s*\\('), re.compile('\\bimportlib\\.'), re.compile('\\b__import__\\s*\\('), re.compile('getattr\\s*\\(')]

def detect_dynamic_code_loading_python(code: str) -> List[Dict]:
    findings = []
    for pat in _PY_DYN:
        for m in pat.finditer(code):
            findings.append({'type': 'dynamic_py', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0), 'reason': 'dynamic execution/reflection'})
    return findings

def detect_dynamic_code_loading_clike(code: str) -> List[Dict]:
    findings = []
    if re.search('\\(\\s*\\*\\s*[A-Za-z_]\\w*\\s*\\)\\s*\\(', code):
        findings.append({'type': 'func_ptr', 'reason': 'Function pointer usage detected (C/C++)'})
    if re.search('\\bdlsym\\s*\\(|\\bGetProcAddress\\s*\\(', code):
        findings.append({'type': 'dynamic_link', 'reason': 'dynamic symbol loading (dlsym/GetProcAddress)'})
    if re.search('\\bsystem\\s*\\(|\\bexecve?\\s*\\(', code):
        findings.append({'type': 'exec_call', 'reason': 'dynamic process creation or exec'})
    if re.search('\\bClass\\.forName\\s*\\(|\\bgetMethod\\s*\\(|\\binvoke\\s*\\(', code):
        findings.append({'type': 'java_reflection', 'reason': 'Java reflection API usage'})
    return findings

def clean_dynamic_code_loading_clike(code: str) -> List[Dict]:
    changes = []
    m = re.search('\\b([A-Za-z_]\\w*)\\s*\\([^)]*\\)\\s*\\{\\s*return\\s+([A-Za-z_]\\w*)\\s*\\(\\s*\\)\\s*;\\s*\\}', code)
    if m:
        wrapper_name = m.group(1)
        real = m.group(2)
        orig_wrapper = m.group(0)
        new_code = re.sub('\\b' + re.escape(wrapper_name) + '\\s*\\(\\s*\\)', real + '()', code)
        changes.append({'original': orig_wrapper, 'cleaned': '', 'reason': f'Removed trivial wrapper {wrapper_name} -> inlined calls to {real}()'})
        changes.append({'original': code, 'cleaned': new_code, 'reason': 'Inlined trivial wrapper (C-like)'})
    else:
        dyn = detect_dynamic_code_loading_clike(code)
        if dyn:
            changes.append({'original': '', 'cleaned': '', 'reason': f'Detected dynamic loading/reflection: {dyn}. No automatic rewrite.'})
    return changes

def clean_dynamic_code_loading_python(code: str) -> List[Dict]:
    findings = detect_dynamic_code_loading_python(code)
    if findings:
        return [{'original': '', 'cleaned': '', 'reason': f'Detected dynamic constructs (eval/exec/compile/reflection). Manual review required: {findings}'}]
    return [] -> """
Detect dynamic code loading/reflection/indirect calls:
 - Python: eval, exec, compile, importlib, getattr/locals tricks
 - C/C++: function pointers, dlsym, system/exec calls
 - Java/Kotlin: reflection usage (Class.forName, Method.invoke)
Cleaning is conservative: we only report and, for trivial indirect calls (wrapper->function pointer),
we can sometimes inline wrapper.
"""
import re
from typing import List, Dict
_PY_DYN = [re.compile('\\beval\\s*\\('), re.compile('\\bexec\\s*\\('), re.compile('\\bcompile\\s*\\('), re.compile('\\bimportlib\\.'), re.compile('\\b__import__\\s*\\('), re.compile('getattr\\s*\\(')]

def detect_dynamic_code_loading_python(code: str) -> List[Dict]:
    findings = []
    for pat in _PY_DYN:
        for m in pat.finditer(code):
            findings.append({'type': 'dynamic_py', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0), 'reason': 'dynamic execution/reflection'})
    return findings

def detect_dynamic_code_loading_clike(code: str) -> List[Dict]:
    findings = []
    if re.search('\\(\\s*\\*\\s*[A-Za-z_]\\w*\\s*\\)\\s*\\(', code):
        findings.append({'type': 'func_ptr', 'reason': 'Function pointer usage detected (C/C++)'})
    if re.search('\\bdlsym\\s*\\(|\\bGetProcAddress\\s*\\(', code):
        findings.append({'type': 'dynamic_link', 'reason': 'dynamic symbol loading (dlsym/GetProcAddress)'})
    if re.search('\\bsystem\\s*\\(|\\bexecve?\\s*\\(', code):
        findings.append({'type': 'exec_call', 'reason': 'dynamic process creation or exec'})
    if re.search('\\bClass\\.forName\\s*\\(|\\bgetMethod\\s*\\(|\\binvoke\\s*\\(', code):
        findings.append({'type': 'java_reflection', 'reason': 'Java reflection API usage'})
    return findings

def clean_dynamic_code_loading_clike(code: str) -> List[Dict]:
    changes = []
    m = re.search('\\b([A-Za-z_]\\w*)\\s*\\([^)]*\\)\\s*\\{\\s*return\\s+([A-Za-z_]\\w*)\\s*\\(\\s*\\)\\s*;\\s*\\}', code)
    if m:
        wrapper_name = m.group(1)
        real = m.group(2)
        orig_wrapper = m.group(0)
        new_code = re.sub('\\b' + re.escape(wrapper_name) + '\\s*\\(\\s*\\)', real + '()', code)
        changes.append({'original': orig_wrapper, 'cleaned': '', 'reason': f'Removed trivial wrapper {wrapper_name} -> inlined calls to {real}()'})
        changes.append({'original': code, 'cleaned': new_code, 'reason': 'Inlined trivial wrapper (C-like)'})
    else:
        dyn = detect_dynamic_code_loading_clike(code)
        if dyn:
            changes.append({'original': '', 'cleaned': '', 'reason': f'Detected dynamic loading/reflection: {dyn}. No automatic rewrite.'})
    return changes

def clean_dynamic_code_loading_python(code: str) -> List[Dict]:
    findings = detect_dynamic_code_loading_python(code)
    if findings:
        return [{'original': '', 'cleaned': '', 'reason': f'Detected dynamic constructs (eval/exec/compile/reflection). Manual review required: {findings}'}]
    return [] (Full cleaned file (Python inline folding))
input\inlineExpansion.py: """# Inline Expansion Complex Test Cases with Loops

# 1. Constant multiplication inside assignment
a = 12 * 4

# 2. Constant addition inside parentheses
b = (50 + 25)

# 3. Constant exponentiation (square)
c = 9 ** 2

# 4. Function returning inline multiplication
def f1():
    return (2 * 5) + 3

# 5. Inline addition inside an expression
x = (1 + 2) * (3 + 4)

# 6. Inline squaring inside variable assignment
y = (7 ** 2) + (2 ** 2)

# 7. Mixed variable + constant inline addition
z = 10 + (5 + 5)

# 8. Nested multiplications with loop
val = 1
for i in range(2):
    val *= (2 * 3) + (4 * 5)

# 9. Inline expansion inside if-condition inside loop
for i in range(3):
    if (2 + 3) > i:
        print("Inline addition in loop condition", i)

# 10. Inline exponentiation inside nested loop
for i in range(2):
    for j in range(2):
        p = (i + j) * (2 ** 2)
        print("Loop square:", p)

# 11. Inline expansion in while loop
k = 0
while k < (2 + 2):
    k += (3 * 3)
    print("While loop step:", k)

# 12. Inline in function argument (looped calls)
def square_and_add(n):
    return n + (4 ** 2)

for i in range(3):
    print("Function call:", square_and_add(i))"""
import ast
import re
from typing import List, Dict
_ALLOWED_BINOPS = (ast.Add, ast.Sub, ast.Mult, ast.Div, ast.Mod, ast.Pow, ast.LShift, ast.RShift, ast.BitAnd, ast.BitOr, ast.BitXor, ast.FloorDiv)
_ALLOWED_UNARYOPS = (ast.UAdd, ast.USub, ast.Invert)

def _eval_constant_ast(node):
    if isinstance(node, ast.Constant):
        return node.value
    if isinstance(node, ast.UnaryOp) and isinstance(node.op, _ALLOWED_UNARYOPS):
        val = _eval_constant_ast(node.operand)
        if isinstance(node.op, ast.UAdd):
            return +val
        if isinstance(node.op, ast.USub):
            return -val
        if isinstance(node.op, ast.Invert):
            return ~val
    if isinstance(node, ast.BinOp) and isinstance(node.op, _ALLOWED_BINOPS):
        L = _eval_constant_ast(node.left)
        R = _eval_constant_ast(node.right)
        op = node.op
        if isinstance(op, ast.Add):
            return L + R
        if isinstance(op, ast.Sub):
            return L - R
        if isinstance(op, ast.Mult):
            return L * R
        if isinstance(op, ast.Div):
            return L / R
        if isinstance(op, ast.FloorDiv):
            return L // R
        if isinstance(op, ast.Mod):
            return L % R
        if isinstance(op, ast.Pow):
            return L ** R
        if isinstance(op, ast.LShift):
            return L << R
        if isinstance(op, ast.RShift):
            return L >> R
        if isinstance(op, ast.BitAnd):
            return L & R
        if isinstance(op, ast.BitOr):
            return L | R
        if isinstance(op, ast.BitXor):
            return L ^ R
    raise ValueError('Not a constant-evaluable expression')

class _ConstantFolder(ast.NodeTransformer):

    def __init__(self):
        self.changes = []

    def visit_BinOp(self, node):
        self.generic_visit(node)
        try:
            val = _eval_constant_ast(node)
            orig = ast.unparse(node)
            new = ast.copy_location(ast.Constant(value=val), node)
            self.changes.append((orig, repr(val), node.lineno))
            return new
        except Exception:
            return node

def detect_inline_expansion_python(code: str) -> List[Dict]:
    findings = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{'type': 'parse_error', 'reason': str(e)}]

    class V(ast.NodeVisitor):

        def visit_BinOp(self, node):
            try:
                val = _eval_constant_ast(node)
                findings.append({'type': 'constant_fold', 'lineno': node.lineno, 'expr': ast.unparse(node), 'value': val})
            except Exception:
                if isinstance(node.op, ast.Mult) and isinstance(node.left, ast.Name) and isinstance(node.right, ast.Name) and (node.left.id == node.right.id):
                    findings.append({'type': 'variable_square', 'lineno': node.lineno, 'var': node.left.id})
            self.generic_visit(node)
    V().visit(tree)
    return findings

def clean_inline_expansion_python(code: str) -> List[Dict]:
    results = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{'original': code, 'cleaned': code, 'reason': f'parse_error: {e}'}]
    folder = _ConstantFolder()
    new_tree = folder.visit(tree)
    cleaned_code = None
    try:
        cleaned_code = ast.unparse(new_tree)
    except Exception:
        cleaned_code = code
    for orig, valrepr, lineno in folder.changes:
        results.append({'original': orig, 'cleaned': str(valrepr), 'lineno': lineno, 'reason': 'Constant folded'})
    results.append({'original': code, 'cleaned': cleaned_code, 'reason': 'Full cleaned file (Python inline folding)'})
    return results
_numop_re = re.compile('\\b(\\d+)\\s*([\\+\\-\\*\\/%])\\s*(\\d+)\\b')

def detect_inline_expansion_clike(code: str, ext_tag='C-like') -> List[Dict]:
    findings = []
    for i, line in enumerate(code.splitlines(), start=1):
        for m in _numop_re.finditer(line):
            a, op, b = m.groups()
            findings.append({'type': 'const_expr', 'lineno': i, 'expr': m.group(0), 'lang': ext_tag})
        if re.search('\\b(\\w+)\\s*\\*\\s*\\1\\b', line):
            findings.append({'type': 'square_pattern', 'lineno': i, 'expr': line.strip(), 'lang': ext_tag})
    return findings

def clean_inline_expansion_clike(code: str) -> List[Dict]:
    s = code
    changes = []

    def _eval_match(m):
        a, op, b = m.groups()
        a_i = int(a)
        b_i = int(b)
        if op == '+':
            r = a_i + b_i
        elif op == '-':
            r = a_i - b_i
        elif op == '*':
            r = a_i * b_i
        elif op == '/':
            if b_i == 0:
                raise ZeroDivisionError
            r = a_i // b_i
        elif op == '%':
            r = a_i % b_i
        else:
            raise ValueError
        changes.append({'original': m.group(0), 'cleaned': str(r), 'reason': 'Constant arithmetic folded'})
        return str(r)
    while True:
        new, n = _numop_re.subn(lambda m: _eval_match(m), s, count=1)
        if n == 0:
            break
        s = new
    if changes:
        changes.append({'original': code, 'cleaned': s, 'reason': 'Applied simple constant folding (C-like)'})
    return changes -> """# Inline Expansion Complex Test Cases with Loops

# 1. Constant multiplication inside assignment
a = 12 * 4

# 2. Constant addition inside parentheses
b = (50 + 25)

# 3. Constant exponentiation (square)
c = 9 ** 2

# 4. Function returning inline multiplication
def f1():
    return (2 * 5) + 3

# 5. Inline addition inside an expression
x = (1 + 2) * (3 + 4)

# 6. Inline squaring inside variable assignment
y = (7 ** 2) + (2 ** 2)

# 7. Mixed variable + constant inline addition
z = 10 + (5 + 5)

# 8. Nested multiplications with loop
val = 1
for i in range(2):
    val *= (2 * 3) + (4 * 5)

# 9. Inline expansion inside if-condition inside loop
for i in range(3):
    if (2 + 3) > i:
        print("Inline addition in loop condition", i)

# 10. Inline exponentiation inside nested loop
for i in range(2):
    for j in range(2):
        p = (i + j) * (2 ** 2)
        print("Loop square:", p)

# 11. Inline expansion in while loop
k = 0
while k < (2 + 2):
    k += (3 * 3)
    print("While loop step:", k)

# 12. Inline in function argument (looped calls)
def square_and_add(n):
    return n + (4 ** 2)

for i in range(3):
    print("Function call:", square_and_add(i))"""
import ast
import re
from typing import List, Dict
_ALLOWED_BINOPS = (ast.Add, ast.Sub, ast.Mult, ast.Div, ast.Mod, ast.Pow, ast.LShift, ast.RShift, ast.BitAnd, ast.BitOr, ast.BitXor, ast.FloorDiv)
_ALLOWED_UNARYOPS = (ast.UAdd, ast.USub, ast.Invert)

def _eval_constant_ast(node):
    if isinstance(node, ast.Constant):
        return node.value
    if isinstance(node, ast.UnaryOp) and isinstance(node.op, _ALLOWED_UNARYOPS):
        val = _eval_constant_ast(node.operand)
        if isinstance(node.op, ast.UAdd):
            return +val
        if isinstance(node.op, ast.USub):
            return -val
        if isinstance(node.op, ast.Invert):
            return ~val
    if isinstance(node, ast.BinOp) and isinstance(node.op, _ALLOWED_BINOPS):
        L = _eval_constant_ast(node.left)
        R = _eval_constant_ast(node.right)
        op = node.op
        if isinstance(op, ast.Add):
            return L + R
        if isinstance(op, ast.Sub):
            return L - R
        if isinstance(op, ast.Mult):
            return L * R
        if isinstance(op, ast.Div):
            return L / R
        if isinstance(op, ast.FloorDiv):
            return L // R
        if isinstance(op, ast.Mod):
            return L % R
        if isinstance(op, ast.Pow):
            return L ** R
        if isinstance(op, ast.LShift):
            return L << R
        if isinstance(op, ast.RShift):
            return L >> R
        if isinstance(op, ast.BitAnd):
            return L & R
        if isinstance(op, ast.BitOr):
            return L | R
        if isinstance(op, ast.BitXor):
            return L ^ R
    raise ValueError('Not a constant-evaluable expression')

class _ConstantFolder(ast.NodeTransformer):

    def __init__(self):
        self.changes = []

    def visit_BinOp(self, node):
        self.generic_visit(node)
        try:
            val = _eval_constant_ast(node)
            orig = ast.unparse(node)
            new = ast.copy_location(ast.Constant(value=val), node)
            self.changes.append((orig, repr(val), node.lineno))
            return new
        except Exception:
            return node

def detect_inline_expansion_python(code: str) -> List[Dict]:
    findings = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{'type': 'parse_error', 'reason': str(e)}]

    class V(ast.NodeVisitor):

        def visit_BinOp(self, node):
            try:
                val = _eval_constant_ast(node)
                findings.append({'type': 'constant_fold', 'lineno': node.lineno, 'expr': ast.unparse(node), 'value': val})
            except Exception:
                if isinstance(node.op, ast.Mult) and isinstance(node.left, ast.Name) and isinstance(node.right, ast.Name) and (node.left.id == node.right.id):
                    findings.append({'type': 'variable_square', 'lineno': node.lineno, 'var': node.left.id})
            self.generic_visit(node)
    V().visit(tree)
    return findings

def clean_inline_expansion_python(code: str) -> List[Dict]:
    results = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{'original': code, 'cleaned': code, 'reason': f'parse_error: {e}'}]
    folder = _ConstantFolder()
    new_tree = folder.visit(tree)
    cleaned_code = None
    try:
        cleaned_code = ast.unparse(new_tree)
    except Exception:
        cleaned_code = code
    for orig, valrepr, lineno in folder.changes:
        results.append({'original': orig, 'cleaned': str(valrepr), 'lineno': lineno, 'reason': 'Constant folded'})
    results.append({'original': code, 'cleaned': cleaned_code, 'reason': 'Full cleaned file (Python inline folding)'})
    return results
_numop_re = re.compile('\\b(\\d+)\\s*([\\+\\-\\*\\/%])\\s*(\\d+)\\b')

def detect_inline_expansion_clike(code: str, ext_tag='C-like') -> List[Dict]:
    findings = []
    for i, line in enumerate(code.splitlines(), start=1):
        for m in _numop_re.finditer(line):
            a, op, b = m.groups()
            findings.append({'type': 'const_expr', 'lineno': i, 'expr': m.group(0), 'lang': ext_tag})
        if re.search('\\b(\\w+)\\s*\\*\\s*\\1\\b', line):
            findings.append({'type': 'square_pattern', 'lineno': i, 'expr': line.strip(), 'lang': ext_tag})
    return findings

def clean_inline_expansion_clike(code: str) -> List[Dict]:
    s = code
    changes = []

    def _eval_match(m):
        a, op, b = m.groups()
        a_i = int(a)
        b_i = int(b)
        if op == '+':
            r = a_i + b_i
        elif op == '-':
            r = a_i - b_i
        elif op == '*':
            r = a_i * b_i
        elif op == '/':
            if b_i == 0:
                raise ZeroDivisionError
            r = a_i // b_i
        elif op == '%':
            r = a_i % b_i
        else:
            raise ValueError
        changes.append({'original': m.group(0), 'cleaned': str(r), 'reason': 'Constant arithmetic folded'})
        return str(r)
    while True:
        new, n = _numop_re.subn(lambda m: _eval_match(m), s, count=1)
        if n == 0:
            break
        s = new
    if changes:
        changes.append({'original': code, 'cleaned': s, 'reason': 'Applied simple constant folding (C-like)'})
    return changes (Full cleaned file (Python inline folding))
input\instruction_substitution.py: """
Detect instruction substitution like:
  - x - (-1)  -> x + 1
  - x << 1    -> x * 2
  - x + x     -> 2 * x  (or x * 2)
  - bitwise tricks (x ^ -1) etc.
We'll canonicalize a few safe patterns.
"""
import re
from typing import List, Dict
_CLIKE_PATTERNS = [(re.compile('([A-Za-z_]\\w*)\\s*-\\s*\\(\\s*-\\s*1\\s*\\)'), '\\1 + 1', 'neg-neg to plus'), (re.compile('([A-Za-z_]\\w*)\\s*<<\\s*1\\b'), '\\1 * 2', 'shift-left to multiply'), (re.compile('\\b([A-Za-z_]\\w*)\\s*\\+\\s*\\1\\b'), '2 * \\1', 'x+x to 2*x'), (re.compile('--([A-Za-z_]\\w*)'), '\\1', 'double-neg')]

def detect_instruction_substitution_clike(code: str) -> List[Dict]:
    findings = []
    for pat, repl, reason in _CLIKE_PATTERNS:
        for m in pat.finditer(code):
            findings.append({'type': 'instr_sub', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0), 'suggest': repl, 'reason': reason})
    return findings

def clean_instruction_substitution_clike(code: str) -> List[Dict]:
    changes = []
    s = code
    for pat, repl, reason in _CLIKE_PATTERNS:
        for m in pat.finditer(s):
            orig = m.group(0)
            new = pat.sub(repl, orig)
            changes.append({'original': orig, 'cleaned': new, 'reason': f'Canonicalized: {reason}'})
        s = pat.sub(repl, s)
    if changes:
        changes.append({'original': code, 'cleaned': s, 'reason': 'Applied instruction substitution canonicalization (C-like)'})
    return changes
_PY_PATTERNS = [(re.compile('([A-Za-z_]\\w*)\\s*-\\s*\\(\\s*-\\s*1\\s*\\)'), '\\1 + 1', 'neg-neg to plus'), (re.compile('\\b([A-Za-z_]\\w*)\\s*\\+\\s*\\1\\b'), '2 * \\1', 'x+x to 2*x')]

def detect_instruction_substitution_python(code: str) -> List[Dict]:
    findings = []
    for pat, repl, reason in _PY_PATTERNS:
        for m in pat.finditer(code):
            findings.append({'type': 'instr_sub_py', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0), 'suggest': repl, 'reason': reason})
    return findings

def clean_instruction_substitution_python(code: str) -> List[Dict]:
    s = code
    changes = []
    for pat, repl, reason in _PY_PATTERNS:
        for m in pat.finditer(s):
            orig = m.group(0)
            new = pat.sub(repl, orig)
            changes.append({'original': orig, 'cleaned': new, 'reason': f'Canonicalized: {reason}'})
        s = pat.sub(repl, s)
    if changes:
        changes.append({'original': code, 'cleaned': s, 'reason': 'Applied instruction substitution canonicalization (Python)'})
    return changes -> """
Detect instruction substitution like:
  - x - (-1)  -> x + 1
  - x << 1    -> x * 2
  - x + x     -> 2 * x  (or x * 2)
  - bitwise tricks (x ^ -1) etc.
We'll canonicalize a few safe patterns.
"""
import re
from typing import List, Dict
_CLIKE_PATTERNS = [(re.compile('([A-Za-z_]\\w*)\\s*-\\s*\\(\\s*-\\s*1\\s*\\)'), '\\1 + 1', 'neg-neg to plus'), (re.compile('([A-Za-z_]\\w*)\\s*<<\\s*1\\b'), '\\1 * 2', 'shift-left to multiply'), (re.compile('\\b([A-Za-z_]\\w*)\\s*\\+\\s*\\1\\b'), '2 * \\1', 'x+x to 2*x'), (re.compile('--([A-Za-z_]\\w*)'), '\\1', 'double-neg')]

def detect_instruction_substitution_clike(code: str) -> List[Dict]:
    findings = []
    for pat, repl, reason in _CLIKE_PATTERNS:
        for m in pat.finditer(code):
            findings.append({'type': 'instr_sub', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0), 'suggest': repl, 'reason': reason})
    return findings

def clean_instruction_substitution_clike(code: str) -> List[Dict]:
    changes = []
    s = code
    for pat, repl, reason in _CLIKE_PATTERNS:
        for m in pat.finditer(s):
            orig = m.group(0)
            new = pat.sub(repl, orig)
            changes.append({'original': orig, 'cleaned': new, 'reason': f'Canonicalized: {reason}'})
        s = pat.sub(repl, s)
    if changes:
        changes.append({'original': code, 'cleaned': s, 'reason': 'Applied instruction substitution canonicalization (C-like)'})
    return changes
_PY_PATTERNS = [(re.compile('([A-Za-z_]\\w*)\\s*-\\s*\\(\\s*-\\s*1\\s*\\)'), '\\1 + 1', 'neg-neg to plus'), (re.compile('\\b([A-Za-z_]\\w*)\\s*\\+\\s*\\1\\b'), '2 * \\1', 'x+x to 2*x')]

def detect_instruction_substitution_python(code: str) -> List[Dict]:
    findings = []
    for pat, repl, reason in _PY_PATTERNS:
        for m in pat.finditer(code):
            findings.append({'type': 'instr_sub_py', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0), 'suggest': repl, 'reason': reason})
    return findings

def clean_instruction_substitution_python(code: str) -> List[Dict]:
    s = code
    changes = []
    for pat, repl, reason in _PY_PATTERNS:
        for m in pat.finditer(s):
            orig = m.group(0)
            new = pat.sub(repl, orig)
            changes.append({'original': orig, 'cleaned': new, 'reason': f'Canonicalized: {reason}'})
        s = pat.sub(repl, s)
    if changes:
        changes.append({'original': code, 'cleaned': s, 'reason': 'Applied instruction substitution canonicalization (Python)'})
    return changes (Full cleaned file (Python inline folding))
input\junkcode.py: """
Detect/remove junk code: NOPs, identity operations, redundant arithmetic, dead stores used only for obfuscation.
Conservative cleaning: only remove clear NOP-like constructs and no-op arithmetic on local vars not used in observable way.
"""
import re
from typing import List, Dict

def detect_junk_code_clike(code: str) -> List[Dict]:
    findings = []
    for m in re.finditer('\\basm\\s*\\(\\s*".*?nop.*?"\\s*\\)\\s*;', code, re.IGNORECASE | re.DOTALL):
        findings.append({'type': 'asm_nop', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*([+\\-\\*\\/])\\s*0\\b', code):
        findings.append({'type': 'identity_add_zero', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\*\\s*1\\b', code):
        findings.append({'type': 'identity_mul_one', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    lines = code.splitlines()
    for i in range(len(lines) - 1):
        a = lines[i].strip()
        b = lines[i + 1].strip()
        var1 = re.match('([A-Za-z_]\\w*)\\s*=\\s*[^;]+;', a)
        var2 = re.match('([A-Za-z_]\\w*)\\s*=\\s*[^;]+;', b)
        if var1 and var2 and (var1.group(1) == var2.group(1)):
            findings.append({'type': 'dead_store_sequence', 'lineno': i + 1, 'snippet': a + ' ' + b})
    return findings

def clean_junk_code_clike(code: str) -> List[Dict]:
    s = code
    changes = []
    s_new = re.sub('\\basm\\s*\\(\\s*".*?nop.*?"\\s*\\)\\s*;', '', s, flags=re.IGNORECASE | re.DOTALL)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed inline asm NOPs (C-like)'})
        s = s_new
    s_new = re.sub('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\+\\s*0\\s*;', '', s)
    s_new = re.sub('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\*\\s*1\\s*;', s_new)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed identity arithmetic (x = x + 0 / x = x * 1)'})
        s = s_new
    lines = s.splitlines()
    out_lines = []
    i = 0
    while i < len(lines):
        if i < len(lines) - 1:
            a = lines[i].strip()
            b = lines[i + 1].strip()
            var1 = re.match('([A-Za-z_]\\w*)\\s*=\\s*[^;]+;', a)
            var2 = re.match('([A-Za-z_]\\w*)\\s*=\\s*[^;]+;', b)
            if var1 and var2 and (var1.group(1) == var2.group(1)):
                changes.append({'original': a + '\n' + b + '\n', 'cleaned': b + '\n', 'reason': 'Removed redundant earlier store (dead store)'})
                out_lines.append(b)
                i += 2
                continue
        out_lines.append(lines[i])
        i += 1
    cleaned = '\n'.join(out_lines)
    if cleaned != code and (not changes):
        changes.append({'original': code, 'cleaned': cleaned, 'reason': 'Junk cleaning applied (C-like)'})
    elif cleaned != code:
        changes.append({'original': code, 'cleaned': cleaned, 'reason': 'Junk cleaning applied (C-like)'})
    return changes

def detect_junk_code_python(code: str) -> List[Dict]:
    findings = []
    for m in re.finditer('^\\s*pass\\s*$', code, re.MULTILINE):
        findings.append({'type': 'pass_stmt', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\+\\s*0\\b', code):
        findings.append({'type': 'identity_add_zero', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    return findings

def clean_junk_code_python(code: str) -> List[Dict]:
    s = code
    changes = []
    s_new = re.sub('^\\s*pass\\s*$(?:\\n)?', '', s, flags=re.MULTILINE)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed redundant pass statements'})
        s = s_new
    s_new = re.sub('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\+\\s*0\\b', '\\1 = \\1', s)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed identity addition (x = x + 0).'})
        s = s_new
    return changes -> """
Detect/remove junk code: NOPs, identity operations, redundant arithmetic, dead stores used only for obfuscation.
Conservative cleaning: only remove clear NOP-like constructs and no-op arithmetic on local vars not used in observable way.
"""
import re
from typing import List, Dict

def detect_junk_code_clike(code: str) -> List[Dict]:
    findings = []
    for m in re.finditer('\\basm\\s*\\(\\s*".*?nop.*?"\\s*\\)\\s*;', code, re.IGNORECASE | re.DOTALL):
        findings.append({'type': 'asm_nop', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*([+\\-\\*\\/])\\s*0\\b', code):
        findings.append({'type': 'identity_add_zero', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\*\\s*1\\b', code):
        findings.append({'type': 'identity_mul_one', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    lines = code.splitlines()
    for i in range(len(lines) - 1):
        a = lines[i].strip()
        b = lines[i + 1].strip()
        var1 = re.match('([A-Za-z_]\\w*)\\s*=\\s*[^;]+;', a)
        var2 = re.match('([A-Za-z_]\\w*)\\s*=\\s*[^;]+;', b)
        if var1 and var2 and (var1.group(1) == var2.group(1)):
            findings.append({'type': 'dead_store_sequence', 'lineno': i + 1, 'snippet': a + ' ' + b})
    return findings

def clean_junk_code_clike(code: str) -> List[Dict]:
    s = code
    changes = []
    s_new = re.sub('\\basm\\s*\\(\\s*".*?nop.*?"\\s*\\)\\s*;', '', s, flags=re.IGNORECASE | re.DOTALL)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed inline asm NOPs (C-like)'})
        s = s_new
    s_new = re.sub('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\+\\s*0\\s*;', '', s)
    s_new = re.sub('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\*\\s*1\\s*;', s_new)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed identity arithmetic (x = x + 0 / x = x * 1)'})
        s = s_new
    lines = s.splitlines()
    out_lines = []
    i = 0
    while i < len(lines):
        if i < len(lines) - 1:
            a = lines[i].strip()
            b = lines[i + 1].strip()
            var1 = re.match('([A-Za-z_]\\w*)\\s*=\\s*[^;]+;', a)
            var2 = re.match('([A-Za-z_]\\w*)\\s*=\\s*[^;]+;', b)
            if var1 and var2 and (var1.group(1) == var2.group(1)):
                changes.append({'original': a + '\n' + b + '\n', 'cleaned': b + '\n', 'reason': 'Removed redundant earlier store (dead store)'})
                out_lines.append(b)
                i += 2
                continue
        out_lines.append(lines[i])
        i += 1
    cleaned = '\n'.join(out_lines)
    if cleaned != code and (not changes):
        changes.append({'original': code, 'cleaned': cleaned, 'reason': 'Junk cleaning applied (C-like)'})
    elif cleaned != code:
        changes.append({'original': code, 'cleaned': cleaned, 'reason': 'Junk cleaning applied (C-like)'})
    return changes

def detect_junk_code_python(code: str) -> List[Dict]:
    findings = []
    for m in re.finditer('^\\s*pass\\s*$', code, re.MULTILINE):
        findings.append({'type': 'pass_stmt', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\+\\s*0\\b', code):
        findings.append({'type': 'identity_add_zero', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    return findings

def clean_junk_code_python(code: str) -> List[Dict]:
    s = code
    changes = []
    s_new = re.sub('^\\s*pass\\s*$(?:\\n)?', '', s, flags=re.MULTILINE)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed redundant pass statements'})
        s = s_new
    s_new = re.sub('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\+\\s*0\\b', '\\1 = \\1', s)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed identity addition (x = x + 0).'})
        s = s_new
    return changes (Full cleaned file (Python inline folding))
input\mixed_language.py: """
Detect mixed-language obfuscation signals, such as:
 - inline assembly or ASM blocks inside C/C++  
 - presence of JNI-like bridging code (native method definitions)  
 - generated code markers or embedded Java/Kotlin code segments in C comments
Cleaning: only report and optionally remove pure ASM nop sections or trivial inline assembler used as junk.
"""
import re
from typing import List, Dict

def detect_mixed_language(code: str) -> List[Dict]:
    findings = []
    if re.search('\\b(__asm__|asm)\\s*\\(', code):
        findings.append({'type': 'inline_asm', 'reason': 'Inline assembler block detected'})
    if re.search('#\\s*include\\s*<jni.h>', code) or re.search('System\\.loadLibrary', code):
        findings.append({'type': 'jni_bridge', 'reason': 'JNI/native bridge detected'})
    if re.search('class\\s+[A-Z]\\w+\\s*\\{', code) and re.search('#include', code):
        findings.append({'type': 'mixed_java_c', 'reason': 'Mixed Java/C code smells (both class and #include present)'})
    return findings

def clean_mixed_language_python(code: str) -> List[Dict]:
    changes = []
    findings = detect_mixed_language(code)
    if findings:
        changes.append({'original': '', 'cleaned': '', 'reason': f'Detected mixed-language constructs: {findings}. No automatic cleaning applied.'})
    return changes

def clean_mixed_language_clike(code: str) -> List[Dict]:
    changes = []
    s = code
    s_new = re.sub('\\basm\\s*\\(\\s*".*?nop.*?"\\s*\\)\\s*;', '', s, flags=re.DOTALL | re.IGNORECASE)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed inline asm nop occurrences (mixed-language cleaning)'})
    else:
        findings = detect_mixed_language(code)
        if findings:
            changes.append({'original': '', 'cleaned': '', 'reason': f'Detected mixed-language constructs: {findings}. No automatic cleaning applied.'})
    return changes -> """
Detect mixed-language obfuscation signals, such as:
 - inline assembly or ASM blocks inside C/C++  
 - presence of JNI-like bridging code (native method definitions)  
 - generated code markers or embedded Java/Kotlin code segments in C comments
Cleaning: only report and optionally remove pure ASM nop sections or trivial inline assembler used as junk.
"""
import re
from typing import List, Dict

def detect_mixed_language(code: str) -> List[Dict]:
    findings = []
    if re.search('\\b(__asm__|asm)\\s*\\(', code):
        findings.append({'type': 'inline_asm', 'reason': 'Inline assembler block detected'})
    if re.search('#\\s*include\\s*<jni.h>', code) or re.search('System\\.loadLibrary', code):
        findings.append({'type': 'jni_bridge', 'reason': 'JNI/native bridge detected'})
    if re.search('class\\s+[A-Z]\\w+\\s*\\{', code) and re.search('#include', code):
        findings.append({'type': 'mixed_java_c', 'reason': 'Mixed Java/C code smells (both class and #include present)'})
    return findings

def clean_mixed_language_python(code: str) -> List[Dict]:
    changes = []
    findings = detect_mixed_language(code)
    if findings:
        changes.append({'original': '', 'cleaned': '', 'reason': f'Detected mixed-language constructs: {findings}. No automatic cleaning applied.'})
    return changes

def clean_mixed_language_clike(code: str) -> List[Dict]:
    changes = []
    s = code
    s_new = re.sub('\\basm\\s*\\(\\s*".*?nop.*?"\\s*\\)\\s*;', '', s, flags=re.DOTALL | re.IGNORECASE)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed inline asm nop occurrences (mixed-language cleaning)'})
    else:
        findings = detect_mixed_language(code)
        if findings:
            changes.append({'original': '', 'cleaned': '', 'reason': f'Detected mixed-language constructs: {findings}. No automatic cleaning applied.'})
    return changes (Full cleaned file (Python inline folding))
input\nameIdentifier.py: import re
import ast
import keyword
import builtins

# ----------------------------------------
# Reserved keywords for multiple languages
# ----------------------------------------
LANG_KEYWORDS = {
    "python": set(keyword.kwlist) | set(dir(builtins)),
    "c": {
        "auto","break","case","char","const","continue","default","do","double",
        "else","enum","extern","float","for","goto","if","inline","int","long",
        "register","restrict","return","short","signed","sizeof","static",
        "struct","switch","typedef","union","unsigned","void","volatile","while"
    },
    "cpp": {
        "asm","auto","bool","break","case","catch","char","class","const","const_cast",
        "continue","default","delete","do","double","dynamic_cast","else","enum","explicit",
        "export","extern","false","float","for","friend","goto","if","inline","int","long",
        "mutable","namespace","new","operator","private","protected","public","register",
        "reinterpret_cast","return","short","signed","sizeof","static","static_cast",
        "struct","switch","template","this","throw","true","try","typedef","typeid",
        "typename","union","unsigned","using","virtual","void","volatile","wchar_t","while"
    },
    "java": {
        "abstract","assert","boolean","break","byte","case","catch","char","class","const",
        "continue","default","do","double","else","enum","extends","final","finally","float",
        "for","goto","if","implements","import","instanceof","int","interface","long",
        "native","new","package","private","protected","public","return","short","static",
        "strictfp","super","switch","synchronized","this","throw","throws","transient","try",
        "void","volatile","while"
    },
    "kotlin": {
        "as","break","class","continue","do","else","false","for","fun","if","in",
        "interface","is","null","object","package","return","super","this","throw",
        "true","try","typealias","typeof","val","var","when","while"
    }
}

# ----------------------------------------
# Identifier Obfuscation Detection
# ----------------------------------------
def is_obfuscated_name(name: str, language: str = "python") -> bool:
    """Detect obfuscated identifiers like x1a3, a1, f2 but exclude language keywords."""
    reserved = LANG_KEYWORDS.get(language, set())
    if name in reserved:
        return False
    # Rule: short name with numbers inside
    return bool(re.fullmatch(r"[a-zA-Z]"+)"\d+[a-zA-Z0-9]*", name))


# ----------------------------------------
# AST Visitor for Python
# ----------------------------------------
class NameCollector(ast.NodeVisitor):
    """Collects identifiers from Python AST."""
    def __init__(self, language="python"):
        self.funcs = set()
        self.classes = set()
        self.vars = set()
        self.language = language

    def visit_FunctionDef(self, node):
        if is_obfuscated_name(node.name, self.language):
            self.funcs.add(node.name)
        for arg in node.args.args:
            if is_obfuscated_name(arg.arg, self.language):
                self.vars.add(arg.arg)
        self.generic_visit(node)

    def visit_ClassDef(self, node):
        if is_obfuscated_name(node.name, self.language):
            self.classes.add(node.name)
        self.generic_visit(node)

    def visit_Name(self, node):
        if is_obfuscated_name(node.id, self.language):
            self.vars.add(node.id)


# ----------------------------------------
# Main Cleaner Class (like FakeConditionCleaner)
# ----------------------------------------
class IdentifierCleaner:
    """Detects obfuscated identifiers and returns original, cleaned, reason."""

    def __init__(self, language="python"):
        self.language = language

    def detect_and_clean(self, code):
        """
        Returns:
            changes: list of dicts with keys ['original', 'cleaned', 'reason']
            cleaned_code: code after replacing obfuscated identifiers
        """
        mapping = {}
        changes = []
        func_count, class_count, var_count = 1, 1, 1

        # ----------------------------------------
        # Python AST-based collection
        # ----------------------------------------
        if self.language == "python":
            tree = ast.parse(code)
            collector = NameCollector(self.language)
            collector.visit(tree)

            for f in sorted(collector.funcs):
                mapping[f] = f"func{func_count}"; func_count += 1
            for c in sorted(collector.classes):
                mapping[c] = f"Class{class_count}"; class_count += 1
            for v in sorted(collector.vars):
                mapping[v] = f"var{var_count}"; var_count += 1

        # ----------------------------------------
        # Regex-based collection for other languages
        # ----------------------------------------
        else:
            identifiers = re.findall(r"\b[a-zA-Z_][a-zA-Z0-9_]*\b", code)
            for name in set(identifiers):
                if is_obfuscated_name(name, self.language):
                    if re.match(r"^[A-Z]", name):  # Class
                        mapping[name] = f"Class{class_count}"; class_count += 1
                    elif re.match(r"^[a-z]", name):
                        if re.search(r"\d", name):  # func-like
                            mapping[name] = f"func{func_count}"; func_count += 1
                        else:
                            mapping[name] = f"var{var_count}"; var_count += 1

        # ----------------------------------------
        # Apply mapping and generate change log
        # ----------------------------------------
        def replace_identifier(match):
            word = match.group(0)
            new_word = mapping.get(word, word)
            if word != new_word:
                changes.append({
                    "original": word,
                    "cleaned": new_word,
                    "reason": f"Obfuscated identifier replaced ({word} → {new_word})"
                })
            return new_word

        cleaned_code = re.sub(r"\b[a-zA-Z_][a-zA-Z0-9_]*\b", replace_identifier, code)
        return changes, cleaned_code


# ----------------------------------------
# Language Detection Helper
# ----------------------------------------
def detect_language(filename: str) -> str:
    """Detect programming language from file extension."""
    ext = filename.split(".")[-1].lower()
    if ext == "py":
        return "python"
    elif ext in ("c", "h"):
        return "c"
    elif ext == "cpp":
        return "cpp"
    elif ext == "java":
        return "java"
    elif ext == "kt":
        return "kotlin"
    return "unknown" -> import re
import ast
import keyword
import builtins

# ----------------------------------------
# Reserved keywords for multiple languages
# ----------------------------------------
LANG_KEYWORDS = {
    "python": set(keyword.kwlist) | set(dir(builtins)),
    "c": {
        "auto","break","case","char","const","continue","default","do","double",
        "else","enum","extern","float","for","goto","if","inline","int","long",
        "register","restrict","return","short","signed","sizeof","static",
        "struct","switch","typedef","union","unsigned","void","volatile","while"
    },
    "cpp": {
        "asm","auto","bool","break","case","catch","char","class","const","const_cast",
        "continue","default","delete","do","double","dynamic_cast","else","enum","explicit",
        "export","extern","false","float","for","friend","goto","if","inline","int","long",
        "mutable","namespace","new","operator","private","protected","public","register",
        "reinterpret_cast","return","short","signed","sizeof","static","static_cast",
        "struct","switch","template","this","throw","true","try","typedef","typeid",
        "typename","union","unsigned","using","virtual","void","volatile","wchar_t","while"
    },
    "java": {
        "abstract","assert","boolean","break","byte","case","catch","char","class","const",
        "continue","default","do","double","else","enum","extends","final","finally","float",
        "for","goto","if","implements","import","instanceof","int","interface","long",
        "native","new","package","private","protected","public","return","short","static",
        "strictfp","super","switch","synchronized","this","throw","throws","transient","try",
        "void","volatile","while"
    },
    "kotlin": {
        "as","break","class","continue","do","else","false","for","fun","if","in",
        "interface","is","null","object","package","return","super","this","throw",
        "true","try","typealias","typeof","val","var","when","while"
    }
}

# ----------------------------------------
# Identifier Obfuscation Detection
# ----------------------------------------
def is_obfuscated_name(name: str, language: str = "python") -> bool:
    """Detect obfuscated identifiers like x1a3, a1, f2 but exclude language keywords."""
    reserved = LANG_KEYWORDS.get(language, set())
    if name in reserved:
        return False
    # Rule: short name with numbers inside
    return bool(re.fullmatch(r"[a-zA-Z]"+)"\d+[a-zA-Z0-9]*", name))


# ----------------------------------------
# AST Visitor for Python
# ----------------------------------------
class NameCollector(ast.NodeVisitor):
    """Collects identifiers from Python AST."""
    def __init__(self, language="python"):
        self.funcs = set()
        self.classes = set()
        self.vars = set()
        self.language = language

    def visit_FunctionDef(self, node):
        if is_obfuscated_name(node.name, self.language):
            self.funcs.add(node.name)
        for arg in node.args.args:
            if is_obfuscated_name(arg.arg, self.language):
                self.vars.add(arg.arg)
        self.generic_visit(node)

    def visit_ClassDef(self, node):
        if is_obfuscated_name(node.name, self.language):
            self.classes.add(node.name)
        self.generic_visit(node)

    def visit_Name(self, node):
        if is_obfuscated_name(node.id, self.language):
            self.vars.add(node.id)


# ----------------------------------------
# Main Cleaner Class (like FakeConditionCleaner)
# ----------------------------------------
class IdentifierCleaner:
    """Detects obfuscated identifiers and returns original, cleaned, reason."""

    def __init__(self, language="python"):
        self.language = language

    def detect_and_clean(self, code):
        """
        Returns:
            changes: list of dicts with keys ['original', 'cleaned', 'reason']
            cleaned_code: code after replacing obfuscated identifiers
        """
        mapping = {}
        changes = []
        func_count, class_count, var_count = 1, 1, 1

        # ----------------------------------------
        # Python AST-based collection
        # ----------------------------------------
        if self.language == "python":
            tree = ast.parse(code)
            collector = NameCollector(self.language)
            collector.visit(tree)

            for f in sorted(collector.funcs):
                mapping[f] = f"func{func_count}"; func_count += 1
            for c in sorted(collector.classes):
                mapping[c] = f"Class{class_count}"; class_count += 1
            for v in sorted(collector.vars):
                mapping[v] = f"var{var_count}"; var_count += 1

        # ----------------------------------------
        # Regex-based collection for other languages
        # ----------------------------------------
        else:
            identifiers = re.findall(r"\b[a-zA-Z_][a-zA-Z0-9_]*\b", code)
            for name in set(identifiers):
                if is_obfuscated_name(name, self.language):
                    if re.match(r"^[A-Z]", name):  # Class
                        mapping[name] = f"Class{class_count}"; class_count += 1
                    elif re.match(r"^[a-z]", name):
                        if re.search(r"\d", name):  # func-like
                            mapping[name] = f"func{func_count}"; func_count += 1
                        else:
                            mapping[name] = f"var{var_count}"; var_count += 1

        # ----------------------------------------
        # Apply mapping and generate change log
        # ----------------------------------------
        def replace_identifier(match):
            word = match.group(0)
            new_word = mapping.get(word, word)
            if word != new_word:
                changes.append({
                    "original": word,
                    "cleaned": new_word,
                    "reason": f"Obfuscated identifier replaced ({word} → {new_word})"
                })
            return new_word

        cleaned_code = re.sub(r"\b[a-zA-Z_][a-zA-Z0-9_]*\b", replace_identifier, code)
        return changes, cleaned_code


# ----------------------------------------
# Language Detection Helper
# ----------------------------------------
def detect_language(filename: str) -> str:
    """Detect programming language from file extension."""
    ext = filename.split(".")[-1].lower()
    if ext == "py":
        return "python"
    elif ext in ("c", "h"):
        return "c"
    elif ext == "cpp":
        return "cpp"
    elif ext == "java":
        return "java"
    elif ext == "kt":
        return "kotlin"
    return "unknown" (parse_error: unmatched ')' (<unknown>, line 50))
input\opaque_predicate.py: # Opaque Predicate Complex Test Cases

# 1. Always true with redundant check inside loop

"""for i in range(2):
    if (2 + 2 == 4) and (3 > 1):
        print("Loop always true:", i)

# 2. Always false predicate (never executes)
for j in range(3):
    if (5 < 2) or (10 < 3):
        print("This will never print", j)

# 3. Constant comparison with while loop
k = 0
while k < 2:
    if (100 == 100):
        print("While loop always true", k)
    k += 1

# 4. Arithmetic inside comparison
if (2 * 3 == 6) and (4 - 1 == 3):
    print("Inline arithmetic always true")

# 5. Complex but always true condition in function
def check_predicate():
    if (50 - 25 == 25) and (4**2 == 16):
        return "Function always true"
    return "Unreachable"

print(check_predicate())

# 6. Complex but false inside loop
for i in range(2):
    if (9 % 2 == 0) or (7 < 3):
        print("Never executes")

# 7. Nested opaque predicates
if ((10/2) == 5):
    if ((3*3) == 9):
        print("Nested always true")

# 8. Redundant always true inside loop
for i in range(2):
    if (8 > 3) and (2 < 5):
        print("Redundant always true", i)

# 9. Impossible opaque condition
if (1 == 2) or (0 > 10):
    print("Impossible branch")

# 10. Hidden constant compare inside function + loop
def hidden_check(x):
    if (x * 2 == 8) and (16/4 == 4):
        return True
    return False

for val in "./":
    if hidden_check(val):
        print("Hidden opaque true for", val)"""


# analyzers/opaque_predicate.py
import ast
import re
from typing import List, Dict

# Reuse the same safe AST evaluator from inline_expansion; to avoid circular import, copy minimal evaluator:
_ALLOWED_BINOPS = (ast.Add, ast.Sub, ast.Mult, ast.Div, ast.Mod, ast.Pow,
                   ast.LShift, ast.RShift, ast.BitAnd, ast.BitOr, ast.BitXor, ast.FloorDiv)
_ALLOWED_UNARYOPS = (ast.UAdd, ast.USub, ast.Invert)

def _eval_constant_ast(node):
    if isinstance(node, ast.Constant):
        return node.value
    if isinstance(node, ast.UnaryOp) and isinstance(node.op, _ALLOWED_UNARYOPS):
        val = _eval_constant_ast(node.operand)
        if isinstance(node.op, ast.UAdd): return +val
        if isinstance(node.op, ast.USub): return -val
        if isinstance(node.op, ast.Invert): return ~val
    if isinstance(node, ast.BinOp) and isinstance(node.op, _ALLOWED_BINOPS):
        L = _eval_constant_ast(node.left)
        R = _eval_constant_ast(node.right)
        op = node.op
        if isinstance(op, ast.Add): return L + R
        if isinstance(op, ast.Sub): return L - R
        if isinstance(op, ast.Mult): return L * R
        if isinstance(op, ast.Div): return L / R
        if isinstance(op, ast.FloorDiv): return L // R
        if isinstance(op, ast.Mod): return L % R
        if isinstance(op, ast.Pow): return L ** R
        if isinstance(op, ast.LShift): return L << R
        if isinstance(op, ast.RShift): return L >> R
        if isinstance(op, ast.BitAnd): return L & R
        if isinstance(op, ast.BitOr): return L | R
        if isinstance(op, ast.BitXor): return L ^ R
    if isinstance(node, ast.Compare):
        left = _eval_constant_ast(node.left)
        # single comparator supported
        comp = node.comparators"*"
        right = _eval_constant_ast(comp)
        op = node.ops"*"
        if isinstance(op, ast.Eq): return left == right
        if isinstance(op, ast.NotEq): return left != right
        if isinstance(op, ast.Lt): return left < right
        if isinstance(op, ast.LtE): return left <= right
        if isinstance(op, ast.Gt): return left > right
        if isinstance(op, ast.GtE): return left >= right
    if isinstance(node, ast.BoolOp):
        # evaluate values if possible
        values = [_eval_constant_ast(v) for v in node.values]
        if isinstance(node.op, ast.And):
            return all(values)
        else:
            return any(values)
    raise ValueError("Not constant-evaluable")

# ---------------- Python detection/cleaning ----------------
def detect_opaque_predicate_python(code: str) -> List[Dict]:
    findings = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{"type": "parse_error", "reason": str(e)}]
    class V(ast.NodeVisitor):
        def visit_If(self, node):
            # try to evaluate the test
            try:
                val = _eval_constant_ast(node.test)
                findings.append({"type": "opaque_always", "lineno": node.lineno, "value": bool(val), "expr": ast.unparse(node.test)})
            except Exception:
                # check for Compare with constant operands inside BoolOp
                if isinstance(node.test, ast.BoolOp):
                    for v in node.test.values:
                        if isinstance(v, ast.Compare):
                            left = v.left
                            if isinstance(left, ast.BinOp) and isinstance(left.left, ast.Constant) and isinstance(left.right, ast.Constant):
                                findings.append({"type": "opaque_arith", "lineno": node.lineno, "expr": ast.unparse(v)})
            self.generic_visit(node)
    V().visit(tree)
    return findings

def clean_opaque_predicate_python(code: str) -> List[Dict]:
    """
    Replace opaque predicates that evaluate to True with their body,
    remove those that evaluate to False.
    """
    results = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{"original": code, "cleaned": code, "reason": f"parse_error: {e}"}]

    class Transformer(ast.NodeTransformer):
        def __init__(self):
            self.changes = []
        def visit_If(self, node):
            # try eval test
            try:
                val = _eval_constant_ast(node.test)
                orig = ast.unparse(node)
                if bool(val):
                    # keep body (inline)
                    cleaned = "\n".join([ast.unparse(n) for n in node.body])
                    self.changes.append({"original": orig, "cleaned": cleaned, "reason": "Opaque predicate evaluated True -> inlined body"})
                    return node.body
                else:
                    # remove if entirely or keep else if present
                    cleaned = ""
                    if node.orelse:
                        cleaned = "\n".join([ast.unparse(n) for n in node.orelse])
                    self.changes.append({"original": orig, "cleaned": cleaned, "reason": "Opaque predicate evaluated False -> removed or replaced with else"})
                    # replace with else-body if exists
                    return node.orelse or []
            except Exception:
                return self.generic_visit(node)

    t = Transformer()
    new_tree = t.visit(tree)
    try:
        new_code = ast.unparse(new_tree)
    except Exception:
        new_code = code
    results.extend(t.changes)
    results.append({"original": code, "cleaned": new_code, "reason": "Full cleaned file (Python opaque predicate simplification)"})
    return results

# ---------------- C-like detection/cleaning (regex) ----------------
_cmp_re = re.compile(r'\b(\d+(?:\s*[\+\-\*\/]\s*\d+)*)\s*(==|!=|>|<|>=|<=)\s*(\d+(?:\s*[\+\-\*\/]\s*\d+)*)')

def _safe_eval_num_expr(expr: str):
    # only digits, whitespace, and operators allowed
    if not re.fullmatch(r'[0-9\+\-\*\/%\s\(\)]+', expr):
        raise ValueError("unsafe expr")
    # evaluate using Python integer math (floor division)
    # replace / with // for integer division
    expr2 = expr.replace('/', '//')
    return eval(expr2)

def detect_opaque_predicate_clike(code: str, lang="C-like") -> List[Dict]:
    findings = []
    for i, line in enumerate(code.splitlines(), start=1):
        for m in _cmp_re.finditer(line):
            left, op, right = m.groups()
            try:
                lv = _safe_eval_num_expr(left)
                rv = _safe_eval_num_expr(right)
                # compare
                ok = False
                if op == '==': ok = (lv == rv)
                elif op == '!=': ok = (lv != rv)
                elif op == '<': ok = (lv < rv)
                elif op == '<=': ok = (lv <= rv)
                elif op == '>': ok = (lv > rv)
                elif op == '>=': ok = (lv >= rv)
                findings.append({"type": "opaque_cmp_const", "lineno": i, "expr": m.group(0), "value": ok, "lang": lang})
            except Exception:
                findings.append({"type": "opaque_cmp_unknown", "lineno": i, "expr": m.group(0), "lang": lang})
    return findings

def clean_opaque_predicate_clike(code: str) -> List[Dict]:
    """
    For identified constant comparisons, attempt to simplify:
      - if condition is always true: replace `if(cond){block}else{else}` -> keep block
      - if always false: remove block or keep else
    Very conservative textual approach: only handles simple one-line if statements and braced blocks.
    """
    changes = []
    s = code
    # find simple if (...) { ... } else { ... } patterns with constant numeric comparisons inside parentheses
    if_pattern = re.compile(r'if\s*\(\s*([^\)]+)\s*\)\s*(\{(?:[^{}]|\{[^}]*\})*\}|[^\n;]*;)\s*(else\s*(\{(?:[^{}]|\{[^}]*\})*\}|[^\n;]*;))?', re.DOTALL)
    pos = 0
    while True:
        m = if_pattern.search(s, pos)
        if not m:
            break
        cond = m.group(1)
        body = m.group(2)
        else_part = m.group(3) or ""
        try:
            # attempt to evaluate cond if it's a simple arithmetic comparison
            mm = _cmp_re.search(cond)
            if mm:
                left, op, right = mm.groups()
                lv = _safe_eval_num_expr(left)
                rv = _safe_eval_num_expr(right)
                if op == '==': val = (lv == rv)
                elif op == '!=': val = (lv != rv)
                elif op == '<': val = (lv < rv)
                elif op == '<=': val = (lv <= rv)
                elif op == '>': val = (lv > rv)
                elif op == '>=': val = (lv >= rv)
                if val:
                    # keep body, remove if(...) and else
                    cleaned = body
                    changes.append({"original": m.group(0), "cleaned": cleaned, "reason": "Opaque condition evaluated True — inlined body"})
                    s = s[:m.start()] + cleaned + s[m.end():]
                    pos = m.start() + len(cleaned)
                    continue
                else:
                    # remove body, keep else if present
                    cleaned = else_part if else_part else ""
                    changes.append({"original": m.group(0), "cleaned": cleaned, "reason": "Opaque condition evaluated False — removed body / kept else"})
                    s = s[:m.start()] + cleaned + s[m.end():]
                    pos = m.start() + len(cleaned)
                    continue
        except Exception:
            pass
        pos = m.end()
    if changes:
        changes.append({"original": code, "cleaned": s, "reason": "Applied simple opaque predicate simplification (C-like)"})
    return changes
 -> # Opaque Predicate Complex Test Cases

# 1. Always true with redundant check inside loop

"""for i in range(2):
    if (2 + 2 == 4) and (3 > 1):
        print("Loop always true:", i)

# 2. Always false predicate (never executes)
for j in range(3):
    if (5 < 2) or (10 < 3):
        print("This will never print", j)

# 3. Constant comparison with while loop
k = 0
while k < 2:
    if (100 == 100):
        print("While loop always true", k)
    k += 1

# 4. Arithmetic inside comparison
if (2 * 3 == 6) and (4 - 1 == 3):
    print("Inline arithmetic always true")

# 5. Complex but always true condition in function
def check_predicate():
    if (50 - 25 == 25) and (4**2 == 16):
        return "Function always true"
    return "Unreachable"

print(check_predicate())

# 6. Complex but false inside loop
for i in range(2):
    if (9 % 2 == 0) or (7 < 3):
        print("Never executes")

# 7. Nested opaque predicates
if ((10/2) == 5):
    if ((3*3) == 9):
        print("Nested always true")

# 8. Redundant always true inside loop
for i in range(2):
    if (8 > 3) and (2 < 5):
        print("Redundant always true", i)

# 9. Impossible opaque condition
if (1 == 2) or (0 > 10):
    print("Impossible branch")

# 10. Hidden constant compare inside function + loop
def hidden_check(x):
    if (x * 2 == 8) and (16/4 == 4):
        return True
    return False

for val in "./":
    if hidden_check(val):
        print("Hidden opaque true for", val)"""


# analyzers/opaque_predicate.py
import ast
import re
from typing import List, Dict

# Reuse the same safe AST evaluator from inline_expansion; to avoid circular import, copy minimal evaluator:
_ALLOWED_BINOPS = (ast.Add, ast.Sub, ast.Mult, ast.Div, ast.Mod, ast.Pow,
                   ast.LShift, ast.RShift, ast.BitAnd, ast.BitOr, ast.BitXor, ast.FloorDiv)
_ALLOWED_UNARYOPS = (ast.UAdd, ast.USub, ast.Invert)

def _eval_constant_ast(node):
    if isinstance(node, ast.Constant):
        return node.value
    if isinstance(node, ast.UnaryOp) and isinstance(node.op, _ALLOWED_UNARYOPS):
        val = _eval_constant_ast(node.operand)
        if isinstance(node.op, ast.UAdd): return +val
        if isinstance(node.op, ast.USub): return -val
        if isinstance(node.op, ast.Invert): return ~val
    if isinstance(node, ast.BinOp) and isinstance(node.op, _ALLOWED_BINOPS):
        L = _eval_constant_ast(node.left)
        R = _eval_constant_ast(node.right)
        op = node.op
        if isinstance(op, ast.Add): return L + R
        if isinstance(op, ast.Sub): return L - R
        if isinstance(op, ast.Mult): return L * R
        if isinstance(op, ast.Div): return L / R
        if isinstance(op, ast.FloorDiv): return L // R
        if isinstance(op, ast.Mod): return L % R
        if isinstance(op, ast.Pow): return L ** R
        if isinstance(op, ast.LShift): return L << R
        if isinstance(op, ast.RShift): return L >> R
        if isinstance(op, ast.BitAnd): return L & R
        if isinstance(op, ast.BitOr): return L | R
        if isinstance(op, ast.BitXor): return L ^ R
    if isinstance(node, ast.Compare):
        left = _eval_constant_ast(node.left)
        # single comparator supported
        comp = node.comparators"*"
        right = _eval_constant_ast(comp)
        op = node.ops"*"
        if isinstance(op, ast.Eq): return left == right
        if isinstance(op, ast.NotEq): return left != right
        if isinstance(op, ast.Lt): return left < right
        if isinstance(op, ast.LtE): return left <= right
        if isinstance(op, ast.Gt): return left > right
        if isinstance(op, ast.GtE): return left >= right
    if isinstance(node, ast.BoolOp):
        # evaluate values if possible
        values = [_eval_constant_ast(v) for v in node.values]
        if isinstance(node.op, ast.And):
            return all(values)
        else:
            return any(values)
    raise ValueError("Not constant-evaluable")

# ---------------- Python detection/cleaning ----------------
def detect_opaque_predicate_python(code: str) -> List[Dict]:
    findings = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{"type": "parse_error", "reason": str(e)}]
    class V(ast.NodeVisitor):
        def visit_If(self, node):
            # try to evaluate the test
            try:
                val = _eval_constant_ast(node.test)
                findings.append({"type": "opaque_always", "lineno": node.lineno, "value": bool(val), "expr": ast.unparse(node.test)})
            except Exception:
                # check for Compare with constant operands inside BoolOp
                if isinstance(node.test, ast.BoolOp):
                    for v in node.test.values:
                        if isinstance(v, ast.Compare):
                            left = v.left
                            if isinstance(left, ast.BinOp) and isinstance(left.left, ast.Constant) and isinstance(left.right, ast.Constant):
                                findings.append({"type": "opaque_arith", "lineno": node.lineno, "expr": ast.unparse(v)})
            self.generic_visit(node)
    V().visit(tree)
    return findings

def clean_opaque_predicate_python(code: str) -> List[Dict]:
    """
    Replace opaque predicates that evaluate to True with their body,
    remove those that evaluate to False.
    """
    results = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{"original": code, "cleaned": code, "reason": f"parse_error: {e}"}]

    class Transformer(ast.NodeTransformer):
        def __init__(self):
            self.changes = []
        def visit_If(self, node):
            # try eval test
            try:
                val = _eval_constant_ast(node.test)
                orig = ast.unparse(node)
                if bool(val):
                    # keep body (inline)
                    cleaned = "\n".join([ast.unparse(n) for n in node.body])
                    self.changes.append({"original": orig, "cleaned": cleaned, "reason": "Opaque predicate evaluated True -> inlined body"})
                    return node.body
                else:
                    # remove if entirely or keep else if present
                    cleaned = ""
                    if node.orelse:
                        cleaned = "\n".join([ast.unparse(n) for n in node.orelse])
                    self.changes.append({"original": orig, "cleaned": cleaned, "reason": "Opaque predicate evaluated False -> removed or replaced with else"})
                    # replace with else-body if exists
                    return node.orelse or []
            except Exception:
                return self.generic_visit(node)

    t = Transformer()
    new_tree = t.visit(tree)
    try:
        new_code = ast.unparse(new_tree)
    except Exception:
        new_code = code
    results.extend(t.changes)
    results.append({"original": code, "cleaned": new_code, "reason": "Full cleaned file (Python opaque predicate simplification)"})
    return results

# ---------------- C-like detection/cleaning (regex) ----------------
_cmp_re = re.compile(r'\b(\d+(?:\s*[\+\-\*\/]\s*\d+)*)\s*(==|!=|>|<|>=|<=)\s*(\d+(?:\s*[\+\-\*\/]\s*\d+)*)')

def _safe_eval_num_expr(expr: str):
    # only digits, whitespace, and operators allowed
    if not re.fullmatch(r'[0-9\+\-\*\/%\s\(\)]+', expr):
        raise ValueError("unsafe expr")
    # evaluate using Python integer math (floor division)
    # replace / with // for integer division
    expr2 = expr.replace('/', '//')
    return eval(expr2)

def detect_opaque_predicate_clike(code: str, lang="C-like") -> List[Dict]:
    findings = []
    for i, line in enumerate(code.splitlines(), start=1):
        for m in _cmp_re.finditer(line):
            left, op, right = m.groups()
            try:
                lv = _safe_eval_num_expr(left)
                rv = _safe_eval_num_expr(right)
                # compare
                ok = False
                if op == '==': ok = (lv == rv)
                elif op == '!=': ok = (lv != rv)
                elif op == '<': ok = (lv < rv)
                elif op == '<=': ok = (lv <= rv)
                elif op == '>': ok = (lv > rv)
                elif op == '>=': ok = (lv >= rv)
                findings.append({"type": "opaque_cmp_const", "lineno": i, "expr": m.group(0), "value": ok, "lang": lang})
            except Exception:
                findings.append({"type": "opaque_cmp_unknown", "lineno": i, "expr": m.group(0), "lang": lang})
    return findings

def clean_opaque_predicate_clike(code: str) -> List[Dict]:
    """
    For identified constant comparisons, attempt to simplify:
      - if condition is always true: replace `if(cond){block}else{else}` -> keep block
      - if always false: remove block or keep else
    Very conservative textual approach: only handles simple one-line if statements and braced blocks.
    """
    changes = []
    s = code
    # find simple if (...) { ... } else { ... } patterns with constant numeric comparisons inside parentheses
    if_pattern = re.compile(r'if\s*\(\s*([^\)]+)\s*\)\s*(\{(?:[^{}]|\{[^}]*\})*\}|[^\n;]*;)\s*(else\s*(\{(?:[^{}]|\{[^}]*\})*\}|[^\n;]*;))?', re.DOTALL)
    pos = 0
    while True:
        m = if_pattern.search(s, pos)
        if not m:
            break
        cond = m.group(1)
        body = m.group(2)
        else_part = m.group(3) or ""
        try:
            # attempt to evaluate cond if it's a simple arithmetic comparison
            mm = _cmp_re.search(cond)
            if mm:
                left, op, right = mm.groups()
                lv = _safe_eval_num_expr(left)
                rv = _safe_eval_num_expr(right)
                if op == '==': val = (lv == rv)
                elif op == '!=': val = (lv != rv)
                elif op == '<': val = (lv < rv)
                elif op == '<=': val = (lv <= rv)
                elif op == '>': val = (lv > rv)
                elif op == '>=': val = (lv >= rv)
                if val:
                    # keep body, remove if(...) and else
                    cleaned = body
                    changes.append({"original": m.group(0), "cleaned": cleaned, "reason": "Opaque condition evaluated True — inlined body"})
                    s = s[:m.start()] + cleaned + s[m.end():]
                    pos = m.start() + len(cleaned)
                    continue
                else:
                    # remove body, keep else if present
                    cleaned = else_part if else_part else ""
                    changes.append({"original": m.group(0), "cleaned": cleaned, "reason": "Opaque condition evaluated False — removed body / kept else"})
                    s = s[:m.start()] + cleaned + s[m.end():]
                    pos = m.start() + len(cleaned)
                    continue
        except Exception:
            pass
        pos = m.end()
    if changes:
        changes.append({"original": code, "cleaned": s, "reason": "Applied simple opaque predicate simplification (C-like)"})
    return changes
 (parse_error: invalid syntax (<unknown>, line 100))
input\stringEncryption.py: import re

def xor_decrypt(enc_list, key=42):
    """XOR decrypt a list of integers to a string."""
    try:
        return ''.join((chr(c ^ key) for c in enc_list))
    except Exception:
        return None

class StringDecryptor:
    """Detects and decrypts XOR-encrypted strings in code."""

    def __init__(self, key=42):
        self.key = key

    def detect_strings(self, code: str):
        """Detect candidate encrypted strings as list of integers."""
        pattern = re.compile('[\\[{]([0-9,\\s]+)[\\]}]')
        results = []
        for match in pattern.finditer(code):
            str_bytes = match.group(1)
            try:
                enc_list = [int(b.strip()) for b in str_bytes.split(',') if b.strip().isdigit()]
                decrypted = xor_decrypt(enc_list, self.key)
                if decrypted and all((32 <= ord(ch) <= 126 for ch in decrypted)):
                    results.append({'original': match.group(0), 'decrypted': decrypted, 'position': match.start(), 'reason': 'XOR-encrypted string detected and decrypted'})
            except Exception:
                continue
        return results

    def detect_and_clean(self, code: str):
        """Detect encrypted strings, replace them, and return changes and final code."""
        results = self.detect_strings(code)
        cleaned_code = code
        for res in reversed(results):
            start_idx = cleaned_code.find(res['original'])
            if start_idx != -1:
                cleaned_code = cleaned_code[:start_idx] + f'"{res['decrypted']}"' + cleaned_code[start_idx + len(res['original']):]
                res['cleaned'] = f'"{res['decrypted']}"'
        return (results, cleaned_code) -> import re

def xor_decrypt(enc_list, key=42):
    """XOR decrypt a list of integers to a string."""
    try:
        return ''.join((chr(c ^ key) for c in enc_list))
    except Exception:
        return None

class StringDecryptor:
    """Detects and decrypts XOR-encrypted strings in code."""

    def __init__(self, key=42):
        self.key = key

    def detect_strings(self, code: str):
        """Detect candidate encrypted strings as list of integers."""
        pattern = re.compile('[\\[{]([0-9,\\s]+)[\\]}]')
        results = []
        for match in pattern.finditer(code):
            str_bytes = match.group(1)
            try:
                enc_list = [int(b.strip()) for b in str_bytes.split(',') if b.strip().isdigit()]
                decrypted = xor_decrypt(enc_list, self.key)
                if decrypted and all((32 <= ord(ch) <= 126 for ch in decrypted)):
                    results.append({'original': match.group(0), 'decrypted': decrypted, 'position': match.start(), 'reason': 'XOR-encrypted string detected and decrypted'})
            except Exception:
                continue
        return results

    def detect_and_clean(self, code: str):
        """Detect encrypted strings, replace them, and return changes and final code."""
        results = self.detect_strings(code)
        cleaned_code = code
        for res in reversed(results):
            start_idx = cleaned_code.find(res['original'])
            if start_idx != -1:
                cleaned_code = cleaned_code[:start_idx] + f'"{res['decrypted']}"' + cleaned_code[start_idx + len(res['original']):]
                res['cleaned'] = f'"{res['decrypted']}"'
        return (results, cleaned_code) (Full cleaned file (Python inline folding))



===== Opaque Predicates =====

input\api_redirection.py: """
Detect API redirection/wrapper patterns:
  - tiny wrappers that call another function and do nothing else
  - multiple-level wrappers
Cleaning: inline trivial wrappers (calls) conservatively.
"""
import re
from typing import List, Dict

def detect_api_redirection_clike(code: str) -> List[Dict]:
    findings = []
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*\\((?:[^)]*)\\)\\s*\\{\\s*return\\s+([A-Za-z_]\\w*)\\s*\\(\\s*\\)\\s*;\\s*\\}', code):
        findings.append({'type': 'trivial_wrapper', 'lineno': code[:m.start()].count('\n') + 1, 'wrapper': m.group(1), 'target': m.group(2)})
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*\\(\\s*([^\\)]*)\\)\\s*\\{\\s*return\\s+([A-Za-z_]\\w*)\\s*\\(\\s*\\2\\s*\\)\\s*;\\s*\\}', code):
        findings.append({'type': 'arg_forwarding_wrapper', 'lineno': code[:m.start()].count('\n') + 1, 'wrapper': m.group(1), 'target': m.group(3)})
    return findings

def clean_api_redirection_clike(code: str) -> List[Dict]:
    changes = []
    s = code
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*\\((?:\\s*)\\)\\s*;\\s*', s):
        call_name = m.group(1)
        mm = re.search('\\b' + re.escape(call_name) + '\\s*\\([^)]*\\)\\s*\\{\\s*return\\s+([A-Za-z_]\\w*)\\s*\\(\\s*\\)\\s*;\\s*\\}', s)
        if mm:
            actual = mm.group(1)
            s_new = re.sub('\\b' + re.escape(call_name) + '\\s*\\(\\s*\\)', actual + '()', s)
            if s_new != s:
                changes.append({'original': call_name + '()', 'cleaned': actual + '()', 'reason': f'Inlined trivial wrapper {call_name} -> {actual}'})
                s = s_new
    if changes:
        changes.append({'original': code, 'cleaned': s, 'reason': 'Inlined trivial API wrappers (C-like)'})
    else:
        findings = detect_api_redirection_clike(code)
        if findings:
            changes.append({'original': '', 'cleaned': '', 'reason': f'Detected wrapper patterns but no safe automatic inlining performed: {findings}'})
    return changes

def detect_api_redirection_python(code: str) -> List[Dict]:
    findings = []
    for m in re.finditer('def\\s+([A-Za-z_]\\w*)\\s*\\([^)]*\\)\\s*:\\s*return\\s+([A-Za-z_]\\w*)\\s*\\(\\s*\\)\\s*', code):
        findings.append({'type': 'trivial_wrapper_py', 'lineno': code[:m.start()].count('\n') + 1, 'wrapper': m.group(1), 'target': m.group(2)})
    return findings

def clean_api_redirection_python(code: str) -> List[Dict]:
    s = code
    changes = []
    for m in re.finditer('def\\s+([A-Za-z_]\\w*)\\s*\\([^)]*\\)\\s*:\\s*return\\s+([A-Za-z_]\\w*)\\s*\\(\\s*\\)\\s*', s):
        wrapper = m.group(1)
        target = m.group(2)
        s_new = re.sub('\\b' + re.escape(wrapper) + '\\s*\\(\\s*\\)', target + '()', s)
        if s_new != s:
            changes.append({'original': wrapper + '() calls', 'cleaned': target + '()', 'reason': f'Inlined trivial wrapper {wrapper} -> {target}'})
            s = s_new
    if changes:
        changes.append({'original': code, 'cleaned': s, 'reason': 'Inlined trivial wrappers (Python)'})
    else:
        finds = detect_api_redirection_python(code)
        if finds:
            changes.append({'original': '', 'cleaned': '', 'reason': f'Detected wrappers: {finds}. No automatic inlining applied.'})
    return changes -> """
Detect API redirection/wrapper patterns:
  - tiny wrappers that call another function and do nothing else
  - multiple-level wrappers
Cleaning: inline trivial wrappers (calls) conservatively.
"""
import re
from typing import List, Dict

def detect_api_redirection_clike(code: str) -> List[Dict]:
    findings = []
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*\\((?:[^)]*)\\)\\s*\\{\\s*return\\s+([A-Za-z_]\\w*)\\s*\\(\\s*\\)\\s*;\\s*\\}', code):
        findings.append({'type': 'trivial_wrapper', 'lineno': code[:m.start()].count('\n') + 1, 'wrapper': m.group(1), 'target': m.group(2)})
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*\\(\\s*([^\\)]*)\\)\\s*\\{\\s*return\\s+([A-Za-z_]\\w*)\\s*\\(\\s*\\2\\s*\\)\\s*;\\s*\\}', code):
        findings.append({'type': 'arg_forwarding_wrapper', 'lineno': code[:m.start()].count('\n') + 1, 'wrapper': m.group(1), 'target': m.group(3)})
    return findings

def clean_api_redirection_clike(code: str) -> List[Dict]:
    changes = []
    s = code
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*\\((?:\\s*)\\)\\s*;\\s*', s):
        call_name = m.group(1)
        mm = re.search('\\b' + re.escape(call_name) + '\\s*\\([^)]*\\)\\s*\\{\\s*return\\s+([A-Za-z_]\\w*)\\s*\\(\\s*\\)\\s*;\\s*\\}', s)
        if mm:
            actual = mm.group(1)
            s_new = re.sub('\\b' + re.escape(call_name) + '\\s*\\(\\s*\\)', actual + '()', s)
            if s_new != s:
                changes.append({'original': call_name + '()', 'cleaned': actual + '()', 'reason': f'Inlined trivial wrapper {call_name} -> {actual}'})
                s = s_new
    if changes:
        changes.append({'original': code, 'cleaned': s, 'reason': 'Inlined trivial API wrappers (C-like)'})
    else:
        findings = detect_api_redirection_clike(code)
        if findings:
            changes.append({'original': '', 'cleaned': '', 'reason': f'Detected wrapper patterns but no safe automatic inlining performed: {findings}'})
    return changes

def detect_api_redirection_python(code: str) -> List[Dict]:
    findings = []
    for m in re.finditer('def\\s+([A-Za-z_]\\w*)\\s*\\([^)]*\\)\\s*:\\s*return\\s+([A-Za-z_]\\w*)\\s*\\(\\s*\\)\\s*', code):
        findings.append({'type': 'trivial_wrapper_py', 'lineno': code[:m.start()].count('\n') + 1, 'wrapper': m.group(1), 'target': m.group(2)})
    return findings

def clean_api_redirection_python(code: str) -> List[Dict]:
    s = code
    changes = []
    for m in re.finditer('def\\s+([A-Za-z_]\\w*)\\s*\\([^)]*\\)\\s*:\\s*return\\s+([A-Za-z_]\\w*)\\s*\\(\\s*\\)\\s*', s):
        wrapper = m.group(1)
        target = m.group(2)
        s_new = re.sub('\\b' + re.escape(wrapper) + '\\s*\\(\\s*\\)', target + '()', s)
        if s_new != s:
            changes.append({'original': wrapper + '() calls', 'cleaned': target + '()', 'reason': f'Inlined trivial wrapper {wrapper} -> {target}'})
            s = s_new
    if changes:
        changes.append({'original': code, 'cleaned': s, 'reason': 'Inlined trivial wrappers (Python)'})
    else:
        finds = detect_api_redirection_python(code)
        if finds:
            changes.append({'original': '', 'cleaned': '', 'reason': f'Detected wrappers: {finds}. No automatic inlining applied.'})
    return changes (Full cleaned file (Python opaque predicate simplification))
input\controlFlow.py: # -------------------- controlflow.py --------------------
import re
from typing import List, Dict, Tuple

class FakeConditionCleaner:
    """
    Detect and clean fake/unreachable conditions from source code.
    Reports detailed mapping of:
        - original (obfuscated) code snippet
        - cleaned (deobfuscated) snippet
        - reason for change
    """

    def __init__(self):
        # Patterns for fake conditions
        self.python_patterns = [
            (re.compile(r'if\s+False\s*:\s*', re.IGNORECASE), "Unreachable branch (condition always False)"),
            (re.compile(r'if\s+True\s*:\s*', re.IGNORECASE), "Always-true condition simplified (kept body, removed if header)"),
            (re.compile(r'if\s+[^\n]*>\s*\d+\s+and\s+[^\n]*<\s*\d+\s*:\s*', re.IGNORECASE),
             "Contradictory numeric range in condition (impossible)")
        ]

        self.c_like_patterns = [
            (re.compile(r'if\s*\(\s*(false|0)\s*\)', re.IGNORECASE), "Unreachable branch (condition always false)"),
            (re.compile(r'if\s*\(\s*(true|1)\s*\)', re.IGNORECASE), "Always-true condition simplified (kept statement/block, removed condition header)"),
            (re.compile(r'if\s*\([^)]*>\s*\d+\s*&&\s*[^)]*<\s*\d+\)', re.IGNORECASE),
             "Contradictory numeric range in condition (impossible)")
        ]

    # ---------- Python helper ----------
    def _extract_python_if_block(self, code: str, match_start: int) -> Tuple[str, str]:
        header_end = code.find('\n', match_start)
        if header_end == -1:
            return code[match_start:], code[:match_start]

        header = code[match_start:header_end+1]
        body_start = header_end + 1
        end = body_start
        while True:
            if end >= len(code):
                break
            nl = code.find('\n', end)
            if nl == -1:
                nl = len(code)
            line = code[end:nl]
            if not line or not (line"*" == ' ' or line"*" == '\t'):
                break
            end = nl + 1
        removed = code[match_start:end]
        new_code = code[:match_start] + code[end:]
        return removed, new_code

    def _dedent_python_body(self, body_text: str) -> str:
        lines = body_text.splitlines()
        indents = [len(re.match(r'^[ \t]+', ln).group(0)) for ln in lines if ln.strip() and re.match(r'^[ \t]+', ln)]
        if not indents:
            return "\n".join(lines) + ("\n" if body_text.endswith("\n") else "")
        min_indent = min(indents)
        dedented_lines = [ln[min_indent:] if len(ln) >= min_indent else ln for ln in lines]
        return "\n".join(dedented_lines) + ("\n" if body_text.endswith("\n") else "")

    # ---------- C-like helper ----------
    def _extract_c_like_block_or_line(self, code: str, start_idx: int) -> Tuple[str, str]:
        i = start_idx
        while i < len(code) and code[i].isspace():
            i += 1
        if i < len(code) and code[i] == '{':
            stack = ['{']
            end = i + 1
            while stack and end < len(code):
                if code[end] == '{': stack.append('{')
                elif code[end] == '}': stack.pop()
                end += 1
            removed = code[start_idx:end]
            return removed, code[:start_idx] + code[end:]
        else:
            end = i
            while end < len(code) and code[end] not in (';', '\n'):
                end += 1
            if end < len(code) and code[end] == ';': end += 1
            removed = code[start_idx:end]
            return removed, code[:start_idx] + code[end:]

    # ---------- Detection ----------
    def detect_fake_conditions(self, code: str) -> List[Dict]:
        findings = []

        # Python
        for pat, reason in self.python_patterns:
            for m in pat.finditer(code):
                findings.append({"condition": m.group(0), "position": m.start(), "reason": reason})

        # C-like
        for pat, reason in self.c_like_patterns:
            for m in pat.finditer(code):
                findings.append({"condition": m.group(0), "position": m.start(), "reason": reason})

        return findings

    # ---------- Cleaning ----------
    def clean_code(self, code: str) -> List[Dict]:
        """
        Returns a list of changes:
        [
            {"original": ..., "cleaned": ..., "reason": ...},
            ...
        ]
        """
        changes = []
        cleaned_code = code

        # Python patterns
        for pat, reason in self.python_patterns:
            while True:
                m = pat.search(cleaned_code)
                if not m: break
                start = m.start()
                removed, cleaned_code = self._extract_python_if_block(cleaned_code, start)
                if "True" in m.group(0):
                    header_end = removed.find('\n')
                    body = removed[header_end+1:] if header_end != -1 else ""
                    dedented_body = self._dedent_python_body(body)
                    cleaned_code = cleaned_code[:start] + dedented_body + cleaned_code[start:]
                    changes.append({"original": removed, "cleaned": dedented_body, "reason": reason})
                else:
                    changes.append({"original": removed, "cleaned": "", "reason": reason})

        # C-like patterns
        for pat, reason in self.c_like_patterns:
            while True:
                m = pat.search(cleaned_code)
                if not m: break
                start = m.start()
                removed, cleaned_code = self._extract_c_like_block_or_line(cleaned_code, start)
                if "true" in m.group(0).lower() or "1" in m.group(0):
                    # Keep block/statement only
                    if '{' in removed:
                        block_start = removed.find('{')
                        block = removed[block_start:]
                        cleaned_code = cleaned_code[:start] + block + cleaned_code[start:]
                        changes.append({"original": removed, "cleaned": block, "reason": reason})
                    else:
                        # single statement
                        stmt = removed[m.end()-start:]
                        cleaned_code = cleaned_code[:start] + stmt + cleaned_code[start:]
                        changes.append({"original": removed, "cleaned": stmt, "reason": reason})
                else:
                    changes.append({"original": removed, "cleaned": "", "reason": reason})

        return changes -> # -------------------- controlflow.py --------------------
import re
from typing import List, Dict, Tuple

class FakeConditionCleaner:
    """
    Detect and clean fake/unreachable conditions from source code.
    Reports detailed mapping of:
        - original (obfuscated) code snippet
        - cleaned (deobfuscated) snippet
        - reason for change
    """

    def __init__(self):
        # Patterns for fake conditions
        self.python_patterns = [
            (re.compile(r'if\s+False\s*:\s*', re.IGNORECASE), "Unreachable branch (condition always False)"),
            (re.compile(r'if\s+True\s*:\s*', re.IGNORECASE), "Always-true condition simplified (kept body, removed if header)"),
            (re.compile(r'if\s+[^\n]*>\s*\d+\s+and\s+[^\n]*<\s*\d+\s*:\s*', re.IGNORECASE),
             "Contradictory numeric range in condition (impossible)")
        ]

        self.c_like_patterns = [
            (re.compile(r'if\s*\(\s*(false|0)\s*\)', re.IGNORECASE), "Unreachable branch (condition always false)"),
            (re.compile(r'if\s*\(\s*(true|1)\s*\)', re.IGNORECASE), "Always-true condition simplified (kept statement/block, removed condition header)"),
            (re.compile(r'if\s*\([^)]*>\s*\d+\s*&&\s*[^)]*<\s*\d+\)', re.IGNORECASE),
             "Contradictory numeric range in condition (impossible)")
        ]

    # ---------- Python helper ----------
    def _extract_python_if_block(self, code: str, match_start: int) -> Tuple[str, str]:
        header_end = code.find('\n', match_start)
        if header_end == -1:
            return code[match_start:], code[:match_start]

        header = code[match_start:header_end+1]
        body_start = header_end + 1
        end = body_start
        while True:
            if end >= len(code):
                break
            nl = code.find('\n', end)
            if nl == -1:
                nl = len(code)
            line = code[end:nl]
            if not line or not (line"*" == ' ' or line"*" == '\t'):
                break
            end = nl + 1
        removed = code[match_start:end]
        new_code = code[:match_start] + code[end:]
        return removed, new_code

    def _dedent_python_body(self, body_text: str) -> str:
        lines = body_text.splitlines()
        indents = [len(re.match(r'^[ \t]+', ln).group(0)) for ln in lines if ln.strip() and re.match(r'^[ \t]+', ln)]
        if not indents:
            return "\n".join(lines) + ("\n" if body_text.endswith("\n") else "")
        min_indent = min(indents)
        dedented_lines = [ln[min_indent:] if len(ln) >= min_indent else ln for ln in lines]
        return "\n".join(dedented_lines) + ("\n" if body_text.endswith("\n") else "")

    # ---------- C-like helper ----------
    def _extract_c_like_block_or_line(self, code: str, start_idx: int) -> Tuple[str, str]:
        i = start_idx
        while i < len(code) and code[i].isspace():
            i += 1
        if i < len(code) and code[i] == '{':
            stack = ['{']
            end = i + 1
            while stack and end < len(code):
                if code[end] == '{': stack.append('{')
                elif code[end] == '}': stack.pop()
                end += 1
            removed = code[start_idx:end]
            return removed, code[:start_idx] + code[end:]
        else:
            end = i
            while end < len(code) and code[end] not in (';', '\n'):
                end += 1
            if end < len(code) and code[end] == ';': end += 1
            removed = code[start_idx:end]
            return removed, code[:start_idx] + code[end:]

    # ---------- Detection ----------
    def detect_fake_conditions(self, code: str) -> List[Dict]:
        findings = []

        # Python
        for pat, reason in self.python_patterns:
            for m in pat.finditer(code):
                findings.append({"condition": m.group(0), "position": m.start(), "reason": reason})

        # C-like
        for pat, reason in self.c_like_patterns:
            for m in pat.finditer(code):
                findings.append({"condition": m.group(0), "position": m.start(), "reason": reason})

        return findings

    # ---------- Cleaning ----------
    def clean_code(self, code: str) -> List[Dict]:
        """
        Returns a list of changes:
        [
            {"original": ..., "cleaned": ..., "reason": ...},
            ...
        ]
        """
        changes = []
        cleaned_code = code

        # Python patterns
        for pat, reason in self.python_patterns:
            while True:
                m = pat.search(cleaned_code)
                if not m: break
                start = m.start()
                removed, cleaned_code = self._extract_python_if_block(cleaned_code, start)
                if "True" in m.group(0):
                    header_end = removed.find('\n')
                    body = removed[header_end+1:] if header_end != -1 else ""
                    dedented_body = self._dedent_python_body(body)
                    cleaned_code = cleaned_code[:start] + dedented_body + cleaned_code[start:]
                    changes.append({"original": removed, "cleaned": dedented_body, "reason": reason})
                else:
                    changes.append({"original": removed, "cleaned": "", "reason": reason})

        # C-like patterns
        for pat, reason in self.c_like_patterns:
            while True:
                m = pat.search(cleaned_code)
                if not m: break
                start = m.start()
                removed, cleaned_code = self._extract_c_like_block_or_line(cleaned_code, start)
                if "true" in m.group(0).lower() or "1" in m.group(0):
                    # Keep block/statement only
                    if '{' in removed:
                        block_start = removed.find('{')
                        block = removed[block_start:]
                        cleaned_code = cleaned_code[:start] + block + cleaned_code[start:]
                        changes.append({"original": removed, "cleaned": block, "reason": reason})
                    else:
                        # single statement
                        stmt = removed[m.end()-start:]
                        cleaned_code = cleaned_code[:start] + stmt + cleaned_code[start:]
                        changes.append({"original": removed, "cleaned": stmt, "reason": reason})
                else:
                    changes.append({"original": removed, "cleaned": "", "reason": reason})

        return changes (parse_error: invalid syntax. Perhaps you forgot a comma? (<unknown>, line 46))
input\controlflow_flattening.py: """
Detect/control-flow flattening patterns (dispatcher loops, state-machine switch inside loop).
Conservative detection + optional simple unflatten attempt (only for tiny patterns).
"""
import re
import ast
from typing import List, Dict

def detect_controlflow_flattening_clike(code: str) -> List[Dict]:
    findings = []
    pattern = re.compile('\\bwhile\\s*\\(\\s*(?:1|true)\\s*\\)\\s*\\{.*?\\b(switch|if)\\s*\\s*\\([^)]*\\)\\s*\\{', re.IGNORECASE | re.DOTALL)
    if pattern.search(code):
        findings.append({'type': 'dispatcher_loop', 'reason': 'while(true)/switch dispatcher pattern', 'hint': 'control-flow flattening (C-like)'})
    if re.search('\\bstate\\s*=\\s*\\d+\\s*;', code):
        findings.append({'type': 'state_var', 'reason': 'state variable updated inside loop', 'hint': 'possible flattened flow'})
    return findings

def clean_controlflow_flattening_clike(code: str) -> List[Dict]:
    """
    Conservative: we will not attempt full de-flattening.
    Instead, we:
      - detect small dispatcher with 2-3 cases and produce a suggested straight-line replacement as text,
        but do not modify code automatically unless pattern exactly matches a simple form.
    Returns list of change dicts; last item contains full cleaned placeholder if applied.
    """
    changes = []
    m = re.search('while\\s*\\(\\s*(?:1|true)\\s*\\)\\s*\\{\\s*switch\\s*\\(\\s*state\\s*\\)\\s*\\{\\s*(case\\s*1\\s*:\\s*([^}]*)break\\s*;)\\s*(case\\s*2\\s*:\\s*([^}]*)break\\s*;)\\s*\\}\\s*\\}', code, re.DOTALL | re.IGNORECASE)
    if m:
        case1 = m.group(2).strip()
        case2 = m.group(4).strip()
        suggested = '// Suggested deobfuscated sequence\n/* case1 */\n' + case1 + '\n/* case2 */\n' + case2 + '\n'
        changes.append({'original': m.group(0), 'cleaned': suggested, 'reason': 'Simple dispatcher unflattened into sequential suggestions'})
        cleaned = code[:m.start()] + suggested + code[m.end():]
        changes.append({'original': code, 'cleaned': cleaned, 'reason': 'Applied small-scope unflatten (C-like) - manual review required'})
    elif detect_controlflow_flattening_clike(code):
        changes.append({'original': '', 'cleaned': '', 'reason': 'Detected control-flow flattening patterns, no automatic rewrite performed (too risky).'})
    return changes

def detect_controlflow_flattening_python(code: str) -> List[Dict]:
    findings = []
    if re.search('while\\s+True\\s*:\\s*', code):
        if re.search('\\b(state|mode)\\b', code) and re.search('\\bif\\b.*\\belse\\b', code, re.DOTALL):
            findings.append({'type': 'dispatcher_loop_py', 'reason': 'while True with state/if-dispatch found'})
    if re.search('\\{.*lambda.*:.*\\}', code, re.DOTALL):
        findings.append({'type': 'dict_dispatch', 'reason': 'dictionary-based dispatcher (python)'})
    return findings

def clean_controlflow_flattening_python(code: str) -> List[Dict]:
    findings = detect_controlflow_flattening_python(code)
    if findings:
        return [{'original': '', 'cleaned': '', 'reason': 'Detected Python flattened control-flow patterns. Manual reconstruction recommended.'}]
    return [] -> """
Detect/control-flow flattening patterns (dispatcher loops, state-machine switch inside loop).
Conservative detection + optional simple unflatten attempt (only for tiny patterns).
"""
import re
import ast
from typing import List, Dict

def detect_controlflow_flattening_clike(code: str) -> List[Dict]:
    findings = []
    pattern = re.compile('\\bwhile\\s*\\(\\s*(?:1|true)\\s*\\)\\s*\\{.*?\\b(switch|if)\\s*\\s*\\([^)]*\\)\\s*\\{', re.IGNORECASE | re.DOTALL)
    if pattern.search(code):
        findings.append({'type': 'dispatcher_loop', 'reason': 'while(true)/switch dispatcher pattern', 'hint': 'control-flow flattening (C-like)'})
    if re.search('\\bstate\\s*=\\s*\\d+\\s*;', code):
        findings.append({'type': 'state_var', 'reason': 'state variable updated inside loop', 'hint': 'possible flattened flow'})
    return findings

def clean_controlflow_flattening_clike(code: str) -> List[Dict]:
    """
    Conservative: we will not attempt full de-flattening.
    Instead, we:
      - detect small dispatcher with 2-3 cases and produce a suggested straight-line replacement as text,
        but do not modify code automatically unless pattern exactly matches a simple form.
    Returns list of change dicts; last item contains full cleaned placeholder if applied.
    """
    changes = []
    m = re.search('while\\s*\\(\\s*(?:1|true)\\s*\\)\\s*\\{\\s*switch\\s*\\(\\s*state\\s*\\)\\s*\\{\\s*(case\\s*1\\s*:\\s*([^}]*)break\\s*;)\\s*(case\\s*2\\s*:\\s*([^}]*)break\\s*;)\\s*\\}\\s*\\}', code, re.DOTALL | re.IGNORECASE)
    if m:
        case1 = m.group(2).strip()
        case2 = m.group(4).strip()
        suggested = '// Suggested deobfuscated sequence\n/* case1 */\n' + case1 + '\n/* case2 */\n' + case2 + '\n'
        changes.append({'original': m.group(0), 'cleaned': suggested, 'reason': 'Simple dispatcher unflattened into sequential suggestions'})
        cleaned = code[:m.start()] + suggested + code[m.end():]
        changes.append({'original': code, 'cleaned': cleaned, 'reason': 'Applied small-scope unflatten (C-like) - manual review required'})
    elif detect_controlflow_flattening_clike(code):
        changes.append({'original': '', 'cleaned': '', 'reason': 'Detected control-flow flattening patterns, no automatic rewrite performed (too risky).'})
    return changes

def detect_controlflow_flattening_python(code: str) -> List[Dict]:
    findings = []
    if re.search('while\\s+True\\s*:\\s*', code):
        if re.search('\\b(state|mode)\\b', code) and re.search('\\bif\\b.*\\belse\\b', code, re.DOTALL):
            findings.append({'type': 'dispatcher_loop_py', 'reason': 'while True with state/if-dispatch found'})
    if re.search('\\{.*lambda.*:.*\\}', code, re.DOTALL):
        findings.append({'type': 'dict_dispatch', 'reason': 'dictionary-based dispatcher (python)'})
    return findings

def clean_controlflow_flattening_python(code: str) -> List[Dict]:
    findings = detect_controlflow_flattening_python(code)
    if findings:
        return [{'original': '', 'cleaned': '', 'reason': 'Detected Python flattened control-flow patterns. Manual reconstruction recommended.'}]
    return [] (Full cleaned file (Python opaque predicate simplification))
input\deadCode.py: """# Dead Code Test Cases

# 1. Unused variable
x = 10   # dead
y = 20
print(y)

# 2. If condition always True
print("Always runs")
else:
    print("Dead branch")

# 3. If condition always False
else:
    print("Always runs")

# 4. Code after return
def f1():
    return 5
    print("Dead")  # dead

# 5. Code after break
for i in range(3):
    break
    print("Dead")  # dead

# 6. Unreachable else
print("Run")
else:
    print("Dead")

# 7. While False loop
while False:
    print("Never runs")  # dead

# 8. Constant condition (0 is False)
if 0:
    print("Dead")
else:
    print("Runs")

# 9. Constant condition (non-zero is True)
if 1:
    print("Runs")
else:
    print("Dead")

# 10. Multiple returns
def f2(x):
    if x > 0:
        return 1
        print("Dead")  # dead
    else:
        return -1
"""

# analyzers/deadcode.py
import ast
import re
from typing import List, Dict, Tuple

# --------------------------
# Python (AST) helpers
# --------------------------
class _DeadCodeRemover(ast.NodeTransformer):
    """
    Transformations:
      - remove `
    def visit_If(self, node: ast.If):
        # evaluate constant tests only
        try:
            if isinstance(node.test, ast.Constant):
                val = node.test.value
                if val is False:
                    original = ast.get_source_segment(self.source_text, node) if hasattr(self, "source_text") else ast.unparse(node)
                    # remove the entire if-block
                    self.changes.append((original, "", "If condition is constant False (dead code)"))
                    return None  # remove node
                elif val is True:
                    # keep body in place of if
                    body_nodes = [self.visit(b) for b in node.body]
                    original = ast.get_source_segment(self.source_text, node) if hasattr(self, "source_text") else ast.unparse(node)
                    cleaned = "\n".join([ast.unparse(b) for b in body_nodes if b is not None])
                    self.changes.append((original, cleaned, "If condition is constant True (inlined body)"))
                    return body_nodes  # splice body
        except Exception:
            pass
        self.generic_visit(node)
        return node

    def run(self, tree: ast.AST, source_text: str):
        self.source_text = source_text
        new_tree = self.visit(tree)
        return new_tree, self.changes


def detect_deadcode_python(code: str) -> List[Dict]:
    """
    Detect dead-code patterns in Python source using AST scanning.
    Returns list of findings (simple descriptions and line numbers).
    """
    findings = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        findings.append({"type": "parse_error", "reason": str(e)})
        return findings

    # If/While constant tests
    class V(ast.NodeVisitor):
        def visit_If(self, node):
            if isinstance(node.test, ast.Constant):
                if node.test.value is False:
                    findings.append({"type": "dead_if_false", "lineno": node.lineno, "snippet": ast.unparse(node.test)})
                elif node.test.value is True:
                    findings.append({"type": "dead_else", "lineno": node.lineno, "snippet": ast.unparse(node.test)})
            self.generic_visit(node)

        def visit_While(self, node):
            if isinstance(node.test, ast.Constant) and node.test.value is False:
                findings.append({"type": "dead_while_false", "lineno": node.lineno})
            self.generic_visit(node)

        def visit_FunctionDef(self, node):
            # detect code after return in function body
            for i, stmt in enumerate(node.body):
                if isinstance(stmt, ast.Return):
                    for later in node.body[i+1:]:
                        findings.append({"type": "dead_after_return", "lineno": getattr(later, "lineno", None), "func": node.name})
            self.generic_visit(node)

        def visit_Assign(self, node):
            # naive assigned variable capture (we'll refine in unused)
            self.generic_visit(node)

    V().visit(tree)

    # Unused variables: track simple assignments and loads
    assigned = {}
    used = set()
    class U(ast.NodeVisitor):
        def visit_Assign(self, node):
            if len(node.targets) == 1 and isinstance(node.targets"*", ast.Name):
                assigned[node.targets"*".id] = getattr(node, "lineno", None)
            self.generic_visit(node)
        def visit_Name(self, node):
            if isinstance(node.ctx, ast.Load):
                used.add(node.id)
    U().visit(tree)
    for var, lineno in assigned.items():
        if var not in used:
            findings.append({"type": "unused_var", "var": var, "lineno": lineno})

    return findings


def clean_deadcode_python(code: str) -> List[Dict]:
    """
    Attempt to remove dead code in Python source.
    Returns list of changes: {"original":..., "cleaned":..., "reason":...}
    """
    results = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{"original": code, "cleaned": code, "reason": f"parse_error: {e}"}]

    remover = _DeadCodeRemover()
    new_tree, changes = remover.run(tree, code)
    # unparse new_tree (may be list when splicing body — handle carefully)
    try:
        cleaned_code = ast.unparse(new_tree) if not isinstance(new_tree, list) else "\n".join(ast.unparse(n) for n in new_tree)
    except Exception:
        # fallback: do not change
        cleaned_code = code

    for orig, cleaned, reason in changes:
        results.append({"original": orig, "cleaned": cleaned, "reason": reason})

    # Also remove simple unused assignments by regex (safe: only single-name assigns to literal)
    # e.g., `x = 4` where x not used — remove those lines if they exist exactly.
    # We already reported unused vars above; here perform textual removal for simple case.
    facts = detect_deadcode_python(code)
    for f in facts:
        if f.get("type") == "unused_var" and isinstance(f.get("lineno"), int):
            lines = cleaned_code.splitlines()
            idx = f["lineno"] - 1
            if 0 <= idx < len(lines):
                orig_line = lines[idx]
                # verify assignment pattern
                if re.match(r'^\s*' + re.escape(f["var"]) + r'\s*=\s*[^#\n]+', orig_line):
                    lines[idx] = ""  # remove
                    results.append({"original": orig_line + "\n", "cleaned": "", "reason": f"Removed unused assignment '{f['var']}'"})
                    cleaned_code = "\n".join(lines)
    # Return changes and cleaned code appended as last item
    results.append({"original": code, "cleaned": cleaned_code, "reason": "Full cleaned file (Python deadcode removal)"})
    return results


# --------------------------
# C-like regex helpers
# --------------------------
def detect_deadcode_clike(code: str, ext_tag: str = "C-like") -> List[Dict]:
    findings = []
    lines = code.splitlines()
    for i, line in enumerate(lines, start=1):
        if re.search(r'\bif\s*\(\s*(false|0)\s*\)', line, re.IGNORECASE):
            findings.append({"type": "dead_if_false", "lineno": i, "snippet": line.strip(), "lang": ext_tag})
        if re.search(r'\bwhile\s*\(\s*(false|0)\s*\)', line, re.IGNORECASE):
            findings.append({"type": "dead_while_false", "lineno": i, "snippet": line.strip(), "lang": ext_tag})
        if re.search(r'\breturn\b.*;', line) and i < len(lines) and lines[i].strip():
            findings.append({"type": "after_return", "lineno": i+1, "snippet": lines[i].strip(), "lang": ext_tag})
    return findings


def clean_deadcode_clike(code: str) -> List[Dict]:
    """
    Clean simple C-like dead code:
      - remove `
      - replace `{ ... }` with block contents (strip braces)
      - remove single-line unused var assignments that are literal and not used elsewhere (conservative)
    Returns list of changes
    """
    changes = []
    s = code

    # remove 
    pattern_false_block = re.compile(r'\bif\s*\(\s*(?:false|0)\s*\)\s*(\{(?:[^{}]*|\{[^}]*\})*\}|[^;]*;)', re.IGNORECASE | re.DOTALL)
    while True:
        m = pattern_false_block.search(s)
        if not m: break
        orig = m.group(0)
        s = s[:m.start()] + s[m.end():]
        changes.append({"original": orig, "cleaned": "", "reason": "

    # inline { block } => replace with block contents
    pattern_true_block = re.compile(r'\bif\s*\(\s*(?:true|1)\s*\)\s*(\{(?:[^{}]*|\{[^}]*\})*\}|[^;]*;)', re.IGNORECASE | re.DOTALL)
    while True:
        m = pattern_true_block.search(s)
        if not m: break
        orig = m.group(0)
        blk = m.group(1)
        # strip outer braces if present
        if blk.strip().startswith("{") and blk.strip().endswith("}"):
            inner = blk.strip()[1:-1]
        else:
            inner = blk
        s = s[:m.start()] + inner + s[m.end():]
        changes.append({"original": orig, "cleaned": inner, "reason": " inlined (kept body)"})

    # conservative removal of simple unused assignments: pattern `int x = 4;` only if var name does not appear elsewhere
    assign_pattern = re.compile(r'\b(?:int|long|char|float|double)\s+([A-Za-z_]\w*)\s*=\s*[^;]+;')
    for m in assign_pattern.finditer(s):
        var = m.group(1)
        # if var occurs only once (the definition), remove it
        if len(re.findall(r'\b' + re.escape(var) + r'\b', s)) == 1:
            orig = m.group(0)
            s = s[:m.start()] + s[m.end():]
            changes.append({"original": orig, "cleaned": "", "reason": f"Removed likely-unused declaration '{var}'"})

    changes.append({"original": code, "cleaned": s, "reason": "Full cleaned file (C-like deadcode removal)"})
    return changes
 -> """# Dead Code Test Cases

# 1. Unused variable
x = 10   # dead
y = 20
print(y)

# 2. If condition always True
print("Always runs")
else:
    print("Dead branch")

# 3. If condition always False
else:
    print("Always runs")

# 4. Code after return
def f1():
    return 5
    print("Dead")  # dead

# 5. Code after break
for i in range(3):
    break
    print("Dead")  # dead

# 6. Unreachable else
print("Run")
else:
    print("Dead")

# 7. While False loop
while False:
    print("Never runs")  # dead

# 8. Constant condition (0 is False)
if 0:
    print("Dead")
else:
    print("Runs")

# 9. Constant condition (non-zero is True)
if 1:
    print("Runs")
else:
    print("Dead")

# 10. Multiple returns
def f2(x):
    if x > 0:
        return 1
        print("Dead")  # dead
    else:
        return -1
"""

# analyzers/deadcode.py
import ast
import re
from typing import List, Dict, Tuple

# --------------------------
# Python (AST) helpers
# --------------------------
class _DeadCodeRemover(ast.NodeTransformer):
    """
    Transformations:
      - remove `
    def visit_If(self, node: ast.If):
        # evaluate constant tests only
        try:
            if isinstance(node.test, ast.Constant):
                val = node.test.value
                if val is False:
                    original = ast.get_source_segment(self.source_text, node) if hasattr(self, "source_text") else ast.unparse(node)
                    # remove the entire if-block
                    self.changes.append((original, "", "If condition is constant False (dead code)"))
                    return None  # remove node
                elif val is True:
                    # keep body in place of if
                    body_nodes = [self.visit(b) for b in node.body]
                    original = ast.get_source_segment(self.source_text, node) if hasattr(self, "source_text") else ast.unparse(node)
                    cleaned = "\n".join([ast.unparse(b) for b in body_nodes if b is not None])
                    self.changes.append((original, cleaned, "If condition is constant True (inlined body)"))
                    return body_nodes  # splice body
        except Exception:
            pass
        self.generic_visit(node)
        return node

    def run(self, tree: ast.AST, source_text: str):
        self.source_text = source_text
        new_tree = self.visit(tree)
        return new_tree, self.changes


def detect_deadcode_python(code: str) -> List[Dict]:
    """
    Detect dead-code patterns in Python source using AST scanning.
    Returns list of findings (simple descriptions and line numbers).
    """
    findings = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        findings.append({"type": "parse_error", "reason": str(e)})
        return findings

    # If/While constant tests
    class V(ast.NodeVisitor):
        def visit_If(self, node):
            if isinstance(node.test, ast.Constant):
                if node.test.value is False:
                    findings.append({"type": "dead_if_false", "lineno": node.lineno, "snippet": ast.unparse(node.test)})
                elif node.test.value is True:
                    findings.append({"type": "dead_else", "lineno": node.lineno, "snippet": ast.unparse(node.test)})
            self.generic_visit(node)

        def visit_While(self, node):
            if isinstance(node.test, ast.Constant) and node.test.value is False:
                findings.append({"type": "dead_while_false", "lineno": node.lineno})
            self.generic_visit(node)

        def visit_FunctionDef(self, node):
            # detect code after return in function body
            for i, stmt in enumerate(node.body):
                if isinstance(stmt, ast.Return):
                    for later in node.body[i+1:]:
                        findings.append({"type": "dead_after_return", "lineno": getattr(later, "lineno", None), "func": node.name})
            self.generic_visit(node)

        def visit_Assign(self, node):
            # naive assigned variable capture (we'll refine in unused)
            self.generic_visit(node)

    V().visit(tree)

    # Unused variables: track simple assignments and loads
    assigned = {}
    used = set()
    class U(ast.NodeVisitor):
        def visit_Assign(self, node):
            if len(node.targets) == 1 and isinstance(node.targets"*", ast.Name):
                assigned[node.targets"*".id] = getattr(node, "lineno", None)
            self.generic_visit(node)
        def visit_Name(self, node):
            if isinstance(node.ctx, ast.Load):
                used.add(node.id)
    U().visit(tree)
    for var, lineno in assigned.items():
        if var not in used:
            findings.append({"type": "unused_var", "var": var, "lineno": lineno})

    return findings


def clean_deadcode_python(code: str) -> List[Dict]:
    """
    Attempt to remove dead code in Python source.
    Returns list of changes: {"original":..., "cleaned":..., "reason":...}
    """
    results = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{"original": code, "cleaned": code, "reason": f"parse_error: {e}"}]

    remover = _DeadCodeRemover()
    new_tree, changes = remover.run(tree, code)
    # unparse new_tree (may be list when splicing body — handle carefully)
    try:
        cleaned_code = ast.unparse(new_tree) if not isinstance(new_tree, list) else "\n".join(ast.unparse(n) for n in new_tree)
    except Exception:
        # fallback: do not change
        cleaned_code = code

    for orig, cleaned, reason in changes:
        results.append({"original": orig, "cleaned": cleaned, "reason": reason})

    # Also remove simple unused assignments by regex (safe: only single-name assigns to literal)
    # e.g., `x = 4` where x not used — remove those lines if they exist exactly.
    # We already reported unused vars above; here perform textual removal for simple case.
    facts = detect_deadcode_python(code)
    for f in facts:
        if f.get("type") == "unused_var" and isinstance(f.get("lineno"), int):
            lines = cleaned_code.splitlines()
            idx = f["lineno"] - 1
            if 0 <= idx < len(lines):
                orig_line = lines[idx]
                # verify assignment pattern
                if re.match(r'^\s*' + re.escape(f["var"]) + r'\s*=\s*[^#\n]+', orig_line):
                    lines[idx] = ""  # remove
                    results.append({"original": orig_line + "\n", "cleaned": "", "reason": f"Removed unused assignment '{f['var']}'"})
                    cleaned_code = "\n".join(lines)
    # Return changes and cleaned code appended as last item
    results.append({"original": code, "cleaned": cleaned_code, "reason": "Full cleaned file (Python deadcode removal)"})
    return results


# --------------------------
# C-like regex helpers
# --------------------------
def detect_deadcode_clike(code: str, ext_tag: str = "C-like") -> List[Dict]:
    findings = []
    lines = code.splitlines()
    for i, line in enumerate(lines, start=1):
        if re.search(r'\bif\s*\(\s*(false|0)\s*\)', line, re.IGNORECASE):
            findings.append({"type": "dead_if_false", "lineno": i, "snippet": line.strip(), "lang": ext_tag})
        if re.search(r'\bwhile\s*\(\s*(false|0)\s*\)', line, re.IGNORECASE):
            findings.append({"type": "dead_while_false", "lineno": i, "snippet": line.strip(), "lang": ext_tag})
        if re.search(r'\breturn\b.*;', line) and i < len(lines) and lines[i].strip():
            findings.append({"type": "after_return", "lineno": i+1, "snippet": lines[i].strip(), "lang": ext_tag})
    return findings


def clean_deadcode_clike(code: str) -> List[Dict]:
    """
    Clean simple C-like dead code:
      - remove `
      - replace `{ ... }` with block contents (strip braces)
      - remove single-line unused var assignments that are literal and not used elsewhere (conservative)
    Returns list of changes
    """
    changes = []
    s = code

    # remove 
    pattern_false_block = re.compile(r'\bif\s*\(\s*(?:false|0)\s*\)\s*(\{(?:[^{}]*|\{[^}]*\})*\}|[^;]*;)', re.IGNORECASE | re.DOTALL)
    while True:
        m = pattern_false_block.search(s)
        if not m: break
        orig = m.group(0)
        s = s[:m.start()] + s[m.end():]
        changes.append({"original": orig, "cleaned": "", "reason": "

    # inline { block } => replace with block contents
    pattern_true_block = re.compile(r'\bif\s*\(\s*(?:true|1)\s*\)\s*(\{(?:[^{}]*|\{[^}]*\})*\}|[^;]*;)', re.IGNORECASE | re.DOTALL)
    while True:
        m = pattern_true_block.search(s)
        if not m: break
        orig = m.group(0)
        blk = m.group(1)
        # strip outer braces if present
        if blk.strip().startswith("{") and blk.strip().endswith("}"):
            inner = blk.strip()[1:-1]
        else:
            inner = blk
        s = s[:m.start()] + inner + s[m.end():]
        changes.append({"original": orig, "cleaned": inner, "reason": " inlined (kept body)"})

    # conservative removal of simple unused assignments: pattern `int x = 4;` only if var name does not appear elsewhere
    assign_pattern = re.compile(r'\b(?:int|long|char|float|double)\s+([A-Za-z_]\w*)\s*=\s*[^;]+;')
    for m in assign_pattern.finditer(s):
        var = m.group(1)
        # if var occurs only once (the definition), remove it
        if len(re.findall(r'\b' + re.escape(var) + r'\b', s)) == 1:
            orig = m.group(0)
            s = s[:m.start()] + s[m.end():]
            changes.append({"original": orig, "cleaned": "", "reason": f"Removed likely-unused declaration '{var}'"})

    changes.append({"original": code, "cleaned": s, "reason": "Full cleaned file (C-like deadcode removal)"})
    return changes
 (parse_error: unterminated triple-quoted string literal (detected at line 262) (<unknown>, line 223))
input\dynamic_loading.py: """
Detect dynamic code loading/reflection/indirect calls:
 - Python: eval, exec, compile, importlib, getattr/locals tricks
 - C/C++: function pointers, dlsym, system/exec calls
 - Java/Kotlin: reflection usage (Class.forName, Method.invoke)
Cleaning is conservative: we only report and, for trivial indirect calls (wrapper->function pointer),
we can sometimes inline wrapper.
"""
import re
from typing import List, Dict
_PY_DYN = [re.compile('\\beval\\s*\\('), re.compile('\\bexec\\s*\\('), re.compile('\\bcompile\\s*\\('), re.compile('\\bimportlib\\.'), re.compile('\\b__import__\\s*\\('), re.compile('getattr\\s*\\(')]

def detect_dynamic_code_loading_python(code: str) -> List[Dict]:
    findings = []
    for pat in _PY_DYN:
        for m in pat.finditer(code):
            findings.append({'type': 'dynamic_py', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0), 'reason': 'dynamic execution/reflection'})
    return findings

def detect_dynamic_code_loading_clike(code: str) -> List[Dict]:
    findings = []
    if re.search('\\(\\s*\\*\\s*[A-Za-z_]\\w*\\s*\\)\\s*\\(', code):
        findings.append({'type': 'func_ptr', 'reason': 'Function pointer usage detected (C/C++)'})
    if re.search('\\bdlsym\\s*\\(|\\bGetProcAddress\\s*\\(', code):
        findings.append({'type': 'dynamic_link', 'reason': 'dynamic symbol loading (dlsym/GetProcAddress)'})
    if re.search('\\bsystem\\s*\\(|\\bexecve?\\s*\\(', code):
        findings.append({'type': 'exec_call', 'reason': 'dynamic process creation or exec'})
    if re.search('\\bClass\\.forName\\s*\\(|\\bgetMethod\\s*\\(|\\binvoke\\s*\\(', code):
        findings.append({'type': 'java_reflection', 'reason': 'Java reflection API usage'})
    return findings

def clean_dynamic_code_loading_clike(code: str) -> List[Dict]:
    changes = []
    m = re.search('\\b([A-Za-z_]\\w*)\\s*\\([^)]*\\)\\s*\\{\\s*return\\s+([A-Za-z_]\\w*)\\s*\\(\\s*\\)\\s*;\\s*\\}', code)
    if m:
        wrapper_name = m.group(1)
        real = m.group(2)
        orig_wrapper = m.group(0)
        new_code = re.sub('\\b' + re.escape(wrapper_name) + '\\s*\\(\\s*\\)', real + '()', code)
        changes.append({'original': orig_wrapper, 'cleaned': '', 'reason': f'Removed trivial wrapper {wrapper_name} -> inlined calls to {real}()'})
        changes.append({'original': code, 'cleaned': new_code, 'reason': 'Inlined trivial wrapper (C-like)'})
    else:
        dyn = detect_dynamic_code_loading_clike(code)
        if dyn:
            changes.append({'original': '', 'cleaned': '', 'reason': f'Detected dynamic loading/reflection: {dyn}. No automatic rewrite.'})
    return changes

def clean_dynamic_code_loading_python(code: str) -> List[Dict]:
    findings = detect_dynamic_code_loading_python(code)
    if findings:
        return [{'original': '', 'cleaned': '', 'reason': f'Detected dynamic constructs (eval/exec/compile/reflection). Manual review required: {findings}'}]
    return [] -> """
Detect dynamic code loading/reflection/indirect calls:
 - Python: eval, exec, compile, importlib, getattr/locals tricks
 - C/C++: function pointers, dlsym, system/exec calls
 - Java/Kotlin: reflection usage (Class.forName, Method.invoke)
Cleaning is conservative: we only report and, for trivial indirect calls (wrapper->function pointer),
we can sometimes inline wrapper.
"""
import re
from typing import List, Dict
_PY_DYN = [re.compile('\\beval\\s*\\('), re.compile('\\bexec\\s*\\('), re.compile('\\bcompile\\s*\\('), re.compile('\\bimportlib\\.'), re.compile('\\b__import__\\s*\\('), re.compile('getattr\\s*\\(')]

def detect_dynamic_code_loading_python(code: str) -> List[Dict]:
    findings = []
    for pat in _PY_DYN:
        for m in pat.finditer(code):
            findings.append({'type': 'dynamic_py', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0), 'reason': 'dynamic execution/reflection'})
    return findings

def detect_dynamic_code_loading_clike(code: str) -> List[Dict]:
    findings = []
    if re.search('\\(\\s*\\*\\s*[A-Za-z_]\\w*\\s*\\)\\s*\\(', code):
        findings.append({'type': 'func_ptr', 'reason': 'Function pointer usage detected (C/C++)'})
    if re.search('\\bdlsym\\s*\\(|\\bGetProcAddress\\s*\\(', code):
        findings.append({'type': 'dynamic_link', 'reason': 'dynamic symbol loading (dlsym/GetProcAddress)'})
    if re.search('\\bsystem\\s*\\(|\\bexecve?\\s*\\(', code):
        findings.append({'type': 'exec_call', 'reason': 'dynamic process creation or exec'})
    if re.search('\\bClass\\.forName\\s*\\(|\\bgetMethod\\s*\\(|\\binvoke\\s*\\(', code):
        findings.append({'type': 'java_reflection', 'reason': 'Java reflection API usage'})
    return findings

def clean_dynamic_code_loading_clike(code: str) -> List[Dict]:
    changes = []
    m = re.search('\\b([A-Za-z_]\\w*)\\s*\\([^)]*\\)\\s*\\{\\s*return\\s+([A-Za-z_]\\w*)\\s*\\(\\s*\\)\\s*;\\s*\\}', code)
    if m:
        wrapper_name = m.group(1)
        real = m.group(2)
        orig_wrapper = m.group(0)
        new_code = re.sub('\\b' + re.escape(wrapper_name) + '\\s*\\(\\s*\\)', real + '()', code)
        changes.append({'original': orig_wrapper, 'cleaned': '', 'reason': f'Removed trivial wrapper {wrapper_name} -> inlined calls to {real}()'})
        changes.append({'original': code, 'cleaned': new_code, 'reason': 'Inlined trivial wrapper (C-like)'})
    else:
        dyn = detect_dynamic_code_loading_clike(code)
        if dyn:
            changes.append({'original': '', 'cleaned': '', 'reason': f'Detected dynamic loading/reflection: {dyn}. No automatic rewrite.'})
    return changes

def clean_dynamic_code_loading_python(code: str) -> List[Dict]:
    findings = detect_dynamic_code_loading_python(code)
    if findings:
        return [{'original': '', 'cleaned': '', 'reason': f'Detected dynamic constructs (eval/exec/compile/reflection). Manual review required: {findings}'}]
    return [] (Full cleaned file (Python opaque predicate simplification))
input\inlineExpansion.py: """# Inline Expansion Complex Test Cases with Loops

# 1. Constant multiplication inside assignment
a = 12 * 4

# 2. Constant addition inside parentheses
b = (50 + 25)

# 3. Constant exponentiation (square)
c = 9 ** 2

# 4. Function returning inline multiplication
def f1():
    return (2 * 5) + 3

# 5. Inline addition inside an expression
x = (1 + 2) * (3 + 4)

# 6. Inline squaring inside variable assignment
y = (7 ** 2) + (2 ** 2)

# 7. Mixed variable + constant inline addition
z = 10 + (5 + 5)

# 8. Nested multiplications with loop
val = 1
for i in range(2):
    val *= (2 * 3) + (4 * 5)

# 9. Inline expansion inside if-condition inside loop
for i in range(3):
    if (2 + 3) > i:
        print("Inline addition in loop condition", i)

# 10. Inline exponentiation inside nested loop
for i in range(2):
    for j in range(2):
        p = (i + j) * (2 ** 2)
        print("Loop square:", p)

# 11. Inline expansion in while loop
k = 0
while k < (2 + 2):
    k += (3 * 3)
    print("While loop step:", k)

# 12. Inline in function argument (looped calls)
def square_and_add(n):
    return n + (4 ** 2)

for i in range(3):
    print("Function call:", square_and_add(i))"""
import ast
import re
from typing import List, Dict
_ALLOWED_BINOPS = (ast.Add, ast.Sub, ast.Mult, ast.Div, ast.Mod, ast.Pow, ast.LShift, ast.RShift, ast.BitAnd, ast.BitOr, ast.BitXor, ast.FloorDiv)
_ALLOWED_UNARYOPS = (ast.UAdd, ast.USub, ast.Invert)

def _eval_constant_ast(node):
    if isinstance(node, ast.Constant):
        return node.value
    if isinstance(node, ast.UnaryOp) and isinstance(node.op, _ALLOWED_UNARYOPS):
        val = _eval_constant_ast(node.operand)
        if isinstance(node.op, ast.UAdd):
            return +val
        if isinstance(node.op, ast.USub):
            return -val
        if isinstance(node.op, ast.Invert):
            return ~val
    if isinstance(node, ast.BinOp) and isinstance(node.op, _ALLOWED_BINOPS):
        L = _eval_constant_ast(node.left)
        R = _eval_constant_ast(node.right)
        op = node.op
        if isinstance(op, ast.Add):
            return L + R
        if isinstance(op, ast.Sub):
            return L - R
        if isinstance(op, ast.Mult):
            return L * R
        if isinstance(op, ast.Div):
            return L / R
        if isinstance(op, ast.FloorDiv):
            return L // R
        if isinstance(op, ast.Mod):
            return L % R
        if isinstance(op, ast.Pow):
            return L ** R
        if isinstance(op, ast.LShift):
            return L << R
        if isinstance(op, ast.RShift):
            return L >> R
        if isinstance(op, ast.BitAnd):
            return L & R
        if isinstance(op, ast.BitOr):
            return L | R
        if isinstance(op, ast.BitXor):
            return L ^ R
    raise ValueError('Not a constant-evaluable expression')

class _ConstantFolder(ast.NodeTransformer):

    def __init__(self):
        self.changes = []

    def visit_BinOp(self, node):
        self.generic_visit(node)
        try:
            val = _eval_constant_ast(node)
            orig = ast.unparse(node)
            new = ast.copy_location(ast.Constant(value=val), node)
            self.changes.append((orig, repr(val), node.lineno))
            return new
        except Exception:
            return node

def detect_inline_expansion_python(code: str) -> List[Dict]:
    findings = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{'type': 'parse_error', 'reason': str(e)}]

    class V(ast.NodeVisitor):

        def visit_BinOp(self, node):
            try:
                val = _eval_constant_ast(node)
                findings.append({'type': 'constant_fold', 'lineno': node.lineno, 'expr': ast.unparse(node), 'value': val})
            except Exception:
                if isinstance(node.op, ast.Mult) and isinstance(node.left, ast.Name) and isinstance(node.right, ast.Name) and (node.left.id == node.right.id):
                    findings.append({'type': 'variable_square', 'lineno': node.lineno, 'var': node.left.id})
            self.generic_visit(node)
    V().visit(tree)
    return findings

def clean_inline_expansion_python(code: str) -> List[Dict]:
    results = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{'original': code, 'cleaned': code, 'reason': f'parse_error: {e}'}]
    folder = _ConstantFolder()
    new_tree = folder.visit(tree)
    cleaned_code = None
    try:
        cleaned_code = ast.unparse(new_tree)
    except Exception:
        cleaned_code = code
    for orig, valrepr, lineno in folder.changes:
        results.append({'original': orig, 'cleaned': str(valrepr), 'lineno': lineno, 'reason': 'Constant folded'})
    results.append({'original': code, 'cleaned': cleaned_code, 'reason': 'Full cleaned file (Python inline folding)'})
    return results
_numop_re = re.compile('\\b(\\d+)\\s*([\\+\\-\\*\\/%])\\s*(\\d+)\\b')

def detect_inline_expansion_clike(code: str, ext_tag='C-like') -> List[Dict]:
    findings = []
    for i, line in enumerate(code.splitlines(), start=1):
        for m in _numop_re.finditer(line):
            a, op, b = m.groups()
            findings.append({'type': 'const_expr', 'lineno': i, 'expr': m.group(0), 'lang': ext_tag})
        if re.search('\\b(\\w+)\\s*\\*\\s*\\1\\b', line):
            findings.append({'type': 'square_pattern', 'lineno': i, 'expr': line.strip(), 'lang': ext_tag})
    return findings

def clean_inline_expansion_clike(code: str) -> List[Dict]:
    s = code
    changes = []

    def _eval_match(m):
        a, op, b = m.groups()
        a_i = int(a)
        b_i = int(b)
        if op == '+':
            r = a_i + b_i
        elif op == '-':
            r = a_i - b_i
        elif op == '*':
            r = a_i * b_i
        elif op == '/':
            if b_i == 0:
                raise ZeroDivisionError
            r = a_i // b_i
        elif op == '%':
            r = a_i % b_i
        else:
            raise ValueError
        changes.append({'original': m.group(0), 'cleaned': str(r), 'reason': 'Constant arithmetic folded'})
        return str(r)
    while True:
        new, n = _numop_re.subn(lambda m: _eval_match(m), s, count=1)
        if n == 0:
            break
        s = new
    if changes:
        changes.append({'original': code, 'cleaned': s, 'reason': 'Applied simple constant folding (C-like)'})
    return changes -> """# Inline Expansion Complex Test Cases with Loops

# 1. Constant multiplication inside assignment
a = 12 * 4

# 2. Constant addition inside parentheses
b = (50 + 25)

# 3. Constant exponentiation (square)
c = 9 ** 2

# 4. Function returning inline multiplication
def f1():
    return (2 * 5) + 3

# 5. Inline addition inside an expression
x = (1 + 2) * (3 + 4)

# 6. Inline squaring inside variable assignment
y = (7 ** 2) + (2 ** 2)

# 7. Mixed variable + constant inline addition
z = 10 + (5 + 5)

# 8. Nested multiplications with loop
val = 1
for i in range(2):
    val *= (2 * 3) + (4 * 5)

# 9. Inline expansion inside if-condition inside loop
for i in range(3):
    if (2 + 3) > i:
        print("Inline addition in loop condition", i)

# 10. Inline exponentiation inside nested loop
for i in range(2):
    for j in range(2):
        p = (i + j) * (2 ** 2)
        print("Loop square:", p)

# 11. Inline expansion in while loop
k = 0
while k < (2 + 2):
    k += (3 * 3)
    print("While loop step:", k)

# 12. Inline in function argument (looped calls)
def square_and_add(n):
    return n + (4 ** 2)

for i in range(3):
    print("Function call:", square_and_add(i))"""
import ast
import re
from typing import List, Dict
_ALLOWED_BINOPS = (ast.Add, ast.Sub, ast.Mult, ast.Div, ast.Mod, ast.Pow, ast.LShift, ast.RShift, ast.BitAnd, ast.BitOr, ast.BitXor, ast.FloorDiv)
_ALLOWED_UNARYOPS = (ast.UAdd, ast.USub, ast.Invert)

def _eval_constant_ast(node):
    if isinstance(node, ast.Constant):
        return node.value
    if isinstance(node, ast.UnaryOp) and isinstance(node.op, _ALLOWED_UNARYOPS):
        val = _eval_constant_ast(node.operand)
        if isinstance(node.op, ast.UAdd):
            return +val
        if isinstance(node.op, ast.USub):
            return -val
        if isinstance(node.op, ast.Invert):
            return ~val
    if isinstance(node, ast.BinOp) and isinstance(node.op, _ALLOWED_BINOPS):
        L = _eval_constant_ast(node.left)
        R = _eval_constant_ast(node.right)
        op = node.op
        if isinstance(op, ast.Add):
            return L + R
        if isinstance(op, ast.Sub):
            return L - R
        if isinstance(op, ast.Mult):
            return L * R
        if isinstance(op, ast.Div):
            return L / R
        if isinstance(op, ast.FloorDiv):
            return L // R
        if isinstance(op, ast.Mod):
            return L % R
        if isinstance(op, ast.Pow):
            return L ** R
        if isinstance(op, ast.LShift):
            return L << R
        if isinstance(op, ast.RShift):
            return L >> R
        if isinstance(op, ast.BitAnd):
            return L & R
        if isinstance(op, ast.BitOr):
            return L | R
        if isinstance(op, ast.BitXor):
            return L ^ R
    raise ValueError('Not a constant-evaluable expression')

class _ConstantFolder(ast.NodeTransformer):

    def __init__(self):
        self.changes = []

    def visit_BinOp(self, node):
        self.generic_visit(node)
        try:
            val = _eval_constant_ast(node)
            orig = ast.unparse(node)
            new = ast.copy_location(ast.Constant(value=val), node)
            self.changes.append((orig, repr(val), node.lineno))
            return new
        except Exception:
            return node

def detect_inline_expansion_python(code: str) -> List[Dict]:
    findings = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{'type': 'parse_error', 'reason': str(e)}]

    class V(ast.NodeVisitor):

        def visit_BinOp(self, node):
            try:
                val = _eval_constant_ast(node)
                findings.append({'type': 'constant_fold', 'lineno': node.lineno, 'expr': ast.unparse(node), 'value': val})
            except Exception:
                if isinstance(node.op, ast.Mult) and isinstance(node.left, ast.Name) and isinstance(node.right, ast.Name) and (node.left.id == node.right.id):
                    findings.append({'type': 'variable_square', 'lineno': node.lineno, 'var': node.left.id})
            self.generic_visit(node)
    V().visit(tree)
    return findings

def clean_inline_expansion_python(code: str) -> List[Dict]:
    results = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{'original': code, 'cleaned': code, 'reason': f'parse_error: {e}'}]
    folder = _ConstantFolder()
    new_tree = folder.visit(tree)
    cleaned_code = None
    try:
        cleaned_code = ast.unparse(new_tree)
    except Exception:
        cleaned_code = code
    for orig, valrepr, lineno in folder.changes:
        results.append({'original': orig, 'cleaned': str(valrepr), 'lineno': lineno, 'reason': 'Constant folded'})
    results.append({'original': code, 'cleaned': cleaned_code, 'reason': 'Full cleaned file (Python inline folding)'})
    return results
_numop_re = re.compile('\\b(\\d+)\\s*([\\+\\-\\*\\/%])\\s*(\\d+)\\b')

def detect_inline_expansion_clike(code: str, ext_tag='C-like') -> List[Dict]:
    findings = []
    for i, line in enumerate(code.splitlines(), start=1):
        for m in _numop_re.finditer(line):
            a, op, b = m.groups()
            findings.append({'type': 'const_expr', 'lineno': i, 'expr': m.group(0), 'lang': ext_tag})
        if re.search('\\b(\\w+)\\s*\\*\\s*\\1\\b', line):
            findings.append({'type': 'square_pattern', 'lineno': i, 'expr': line.strip(), 'lang': ext_tag})
    return findings

def clean_inline_expansion_clike(code: str) -> List[Dict]:
    s = code
    changes = []

    def _eval_match(m):
        a, op, b = m.groups()
        a_i = int(a)
        b_i = int(b)
        if op == '+':
            r = a_i + b_i
        elif op == '-':
            r = a_i - b_i
        elif op == '*':
            r = a_i * b_i
        elif op == '/':
            if b_i == 0:
                raise ZeroDivisionError
            r = a_i // b_i
        elif op == '%':
            r = a_i % b_i
        else:
            raise ValueError
        changes.append({'original': m.group(0), 'cleaned': str(r), 'reason': 'Constant arithmetic folded'})
        return str(r)
    while True:
        new, n = _numop_re.subn(lambda m: _eval_match(m), s, count=1)
        if n == 0:
            break
        s = new
    if changes:
        changes.append({'original': code, 'cleaned': s, 'reason': 'Applied simple constant folding (C-like)'})
    return changes (Full cleaned file (Python opaque predicate simplification))
input\instruction_substitution.py: """
Detect instruction substitution like:
  - x - (-1)  -> x + 1
  - x << 1    -> x * 2
  - x + x     -> 2 * x  (or x * 2)
  - bitwise tricks (x ^ -1) etc.
We'll canonicalize a few safe patterns.
"""
import re
from typing import List, Dict
_CLIKE_PATTERNS = [(re.compile('([A-Za-z_]\\w*)\\s*-\\s*\\(\\s*-\\s*1\\s*\\)'), '\\1 + 1', 'neg-neg to plus'), (re.compile('([A-Za-z_]\\w*)\\s*<<\\s*1\\b'), '\\1 * 2', 'shift-left to multiply'), (re.compile('\\b([A-Za-z_]\\w*)\\s*\\+\\s*\\1\\b'), '2 * \\1', 'x+x to 2*x'), (re.compile('--([A-Za-z_]\\w*)'), '\\1', 'double-neg')]

def detect_instruction_substitution_clike(code: str) -> List[Dict]:
    findings = []
    for pat, repl, reason in _CLIKE_PATTERNS:
        for m in pat.finditer(code):
            findings.append({'type': 'instr_sub', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0), 'suggest': repl, 'reason': reason})
    return findings

def clean_instruction_substitution_clike(code: str) -> List[Dict]:
    changes = []
    s = code
    for pat, repl, reason in _CLIKE_PATTERNS:
        for m in pat.finditer(s):
            orig = m.group(0)
            new = pat.sub(repl, orig)
            changes.append({'original': orig, 'cleaned': new, 'reason': f'Canonicalized: {reason}'})
        s = pat.sub(repl, s)
    if changes:
        changes.append({'original': code, 'cleaned': s, 'reason': 'Applied instruction substitution canonicalization (C-like)'})
    return changes
_PY_PATTERNS = [(re.compile('([A-Za-z_]\\w*)\\s*-\\s*\\(\\s*-\\s*1\\s*\\)'), '\\1 + 1', 'neg-neg to plus'), (re.compile('\\b([A-Za-z_]\\w*)\\s*\\+\\s*\\1\\b'), '2 * \\1', 'x+x to 2*x')]

def detect_instruction_substitution_python(code: str) -> List[Dict]:
    findings = []
    for pat, repl, reason in _PY_PATTERNS:
        for m in pat.finditer(code):
            findings.append({'type': 'instr_sub_py', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0), 'suggest': repl, 'reason': reason})
    return findings

def clean_instruction_substitution_python(code: str) -> List[Dict]:
    s = code
    changes = []
    for pat, repl, reason in _PY_PATTERNS:
        for m in pat.finditer(s):
            orig = m.group(0)
            new = pat.sub(repl, orig)
            changes.append({'original': orig, 'cleaned': new, 'reason': f'Canonicalized: {reason}'})
        s = pat.sub(repl, s)
    if changes:
        changes.append({'original': code, 'cleaned': s, 'reason': 'Applied instruction substitution canonicalization (Python)'})
    return changes -> """
Detect instruction substitution like:
  - x - (-1)  -> x + 1
  - x << 1    -> x * 2
  - x + x     -> 2 * x  (or x * 2)
  - bitwise tricks (x ^ -1) etc.
We'll canonicalize a few safe patterns.
"""
import re
from typing import List, Dict
_CLIKE_PATTERNS = [(re.compile('([A-Za-z_]\\w*)\\s*-\\s*\\(\\s*-\\s*1\\s*\\)'), '\\1 + 1', 'neg-neg to plus'), (re.compile('([A-Za-z_]\\w*)\\s*<<\\s*1\\b'), '\\1 * 2', 'shift-left to multiply'), (re.compile('\\b([A-Za-z_]\\w*)\\s*\\+\\s*\\1\\b'), '2 * \\1', 'x+x to 2*x'), (re.compile('--([A-Za-z_]\\w*)'), '\\1', 'double-neg')]

def detect_instruction_substitution_clike(code: str) -> List[Dict]:
    findings = []
    for pat, repl, reason in _CLIKE_PATTERNS:
        for m in pat.finditer(code):
            findings.append({'type': 'instr_sub', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0), 'suggest': repl, 'reason': reason})
    return findings

def clean_instruction_substitution_clike(code: str) -> List[Dict]:
    changes = []
    s = code
    for pat, repl, reason in _CLIKE_PATTERNS:
        for m in pat.finditer(s):
            orig = m.group(0)
            new = pat.sub(repl, orig)
            changes.append({'original': orig, 'cleaned': new, 'reason': f'Canonicalized: {reason}'})
        s = pat.sub(repl, s)
    if changes:
        changes.append({'original': code, 'cleaned': s, 'reason': 'Applied instruction substitution canonicalization (C-like)'})
    return changes
_PY_PATTERNS = [(re.compile('([A-Za-z_]\\w*)\\s*-\\s*\\(\\s*-\\s*1\\s*\\)'), '\\1 + 1', 'neg-neg to plus'), (re.compile('\\b([A-Za-z_]\\w*)\\s*\\+\\s*\\1\\b'), '2 * \\1', 'x+x to 2*x')]

def detect_instruction_substitution_python(code: str) -> List[Dict]:
    findings = []
    for pat, repl, reason in _PY_PATTERNS:
        for m in pat.finditer(code):
            findings.append({'type': 'instr_sub_py', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0), 'suggest': repl, 'reason': reason})
    return findings

def clean_instruction_substitution_python(code: str) -> List[Dict]:
    s = code
    changes = []
    for pat, repl, reason in _PY_PATTERNS:
        for m in pat.finditer(s):
            orig = m.group(0)
            new = pat.sub(repl, orig)
            changes.append({'original': orig, 'cleaned': new, 'reason': f'Canonicalized: {reason}'})
        s = pat.sub(repl, s)
    if changes:
        changes.append({'original': code, 'cleaned': s, 'reason': 'Applied instruction substitution canonicalization (Python)'})
    return changes (Full cleaned file (Python opaque predicate simplification))
input\junkcode.py: """
Detect/remove junk code: NOPs, identity operations, redundant arithmetic, dead stores used only for obfuscation.
Conservative cleaning: only remove clear NOP-like constructs and no-op arithmetic on local vars not used in observable way.
"""
import re
from typing import List, Dict

def detect_junk_code_clike(code: str) -> List[Dict]:
    findings = []
    for m in re.finditer('\\basm\\s*\\(\\s*".*?nop.*?"\\s*\\)\\s*;', code, re.IGNORECASE | re.DOTALL):
        findings.append({'type': 'asm_nop', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*([+\\-\\*\\/])\\s*0\\b', code):
        findings.append({'type': 'identity_add_zero', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\*\\s*1\\b', code):
        findings.append({'type': 'identity_mul_one', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    lines = code.splitlines()
    for i in range(len(lines) - 1):
        a = lines[i].strip()
        b = lines[i + 1].strip()
        var1 = re.match('([A-Za-z_]\\w*)\\s*=\\s*[^;]+;', a)
        var2 = re.match('([A-Za-z_]\\w*)\\s*=\\s*[^;]+;', b)
        if var1 and var2 and (var1.group(1) == var2.group(1)):
            findings.append({'type': 'dead_store_sequence', 'lineno': i + 1, 'snippet': a + ' ' + b})
    return findings

def clean_junk_code_clike(code: str) -> List[Dict]:
    s = code
    changes = []
    s_new = re.sub('\\basm\\s*\\(\\s*".*?nop.*?"\\s*\\)\\s*;', '', s, flags=re.IGNORECASE | re.DOTALL)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed inline asm NOPs (C-like)'})
        s = s_new
    s_new = re.sub('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\+\\s*0\\s*;', '', s)
    s_new = re.sub('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\*\\s*1\\s*;', s_new)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed identity arithmetic (x = x + 0 / x = x * 1)'})
        s = s_new
    lines = s.splitlines()
    out_lines = []
    i = 0
    while i < len(lines):
        if i < len(lines) - 1:
            a = lines[i].strip()
            b = lines[i + 1].strip()
            var1 = re.match('([A-Za-z_]\\w*)\\s*=\\s*[^;]+;', a)
            var2 = re.match('([A-Za-z_]\\w*)\\s*=\\s*[^;]+;', b)
            if var1 and var2 and (var1.group(1) == var2.group(1)):
                changes.append({'original': a + '\n' + b + '\n', 'cleaned': b + '\n', 'reason': 'Removed redundant earlier store (dead store)'})
                out_lines.append(b)
                i += 2
                continue
        out_lines.append(lines[i])
        i += 1
    cleaned = '\n'.join(out_lines)
    if cleaned != code and (not changes):
        changes.append({'original': code, 'cleaned': cleaned, 'reason': 'Junk cleaning applied (C-like)'})
    elif cleaned != code:
        changes.append({'original': code, 'cleaned': cleaned, 'reason': 'Junk cleaning applied (C-like)'})
    return changes

def detect_junk_code_python(code: str) -> List[Dict]:
    findings = []
    for m in re.finditer('^\\s*pass\\s*$', code, re.MULTILINE):
        findings.append({'type': 'pass_stmt', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\+\\s*0\\b', code):
        findings.append({'type': 'identity_add_zero', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    return findings

def clean_junk_code_python(code: str) -> List[Dict]:
    s = code
    changes = []
    s_new = re.sub('^\\s*pass\\s*$(?:\\n)?', '', s, flags=re.MULTILINE)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed redundant pass statements'})
        s = s_new
    s_new = re.sub('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\+\\s*0\\b', '\\1 = \\1', s)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed identity addition (x = x + 0).'})
        s = s_new
    return changes -> """
Detect/remove junk code: NOPs, identity operations, redundant arithmetic, dead stores used only for obfuscation.
Conservative cleaning: only remove clear NOP-like constructs and no-op arithmetic on local vars not used in observable way.
"""
import re
from typing import List, Dict

def detect_junk_code_clike(code: str) -> List[Dict]:
    findings = []
    for m in re.finditer('\\basm\\s*\\(\\s*".*?nop.*?"\\s*\\)\\s*;', code, re.IGNORECASE | re.DOTALL):
        findings.append({'type': 'asm_nop', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*([+\\-\\*\\/])\\s*0\\b', code):
        findings.append({'type': 'identity_add_zero', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\*\\s*1\\b', code):
        findings.append({'type': 'identity_mul_one', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    lines = code.splitlines()
    for i in range(len(lines) - 1):
        a = lines[i].strip()
        b = lines[i + 1].strip()
        var1 = re.match('([A-Za-z_]\\w*)\\s*=\\s*[^;]+;', a)
        var2 = re.match('([A-Za-z_]\\w*)\\s*=\\s*[^;]+;', b)
        if var1 and var2 and (var1.group(1) == var2.group(1)):
            findings.append({'type': 'dead_store_sequence', 'lineno': i + 1, 'snippet': a + ' ' + b})
    return findings

def clean_junk_code_clike(code: str) -> List[Dict]:
    s = code
    changes = []
    s_new = re.sub('\\basm\\s*\\(\\s*".*?nop.*?"\\s*\\)\\s*;', '', s, flags=re.IGNORECASE | re.DOTALL)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed inline asm NOPs (C-like)'})
        s = s_new
    s_new = re.sub('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\+\\s*0\\s*;', '', s)
    s_new = re.sub('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\*\\s*1\\s*;', s_new)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed identity arithmetic (x = x + 0 / x = x * 1)'})
        s = s_new
    lines = s.splitlines()
    out_lines = []
    i = 0
    while i < len(lines):
        if i < len(lines) - 1:
            a = lines[i].strip()
            b = lines[i + 1].strip()
            var1 = re.match('([A-Za-z_]\\w*)\\s*=\\s*[^;]+;', a)
            var2 = re.match('([A-Za-z_]\\w*)\\s*=\\s*[^;]+;', b)
            if var1 and var2 and (var1.group(1) == var2.group(1)):
                changes.append({'original': a + '\n' + b + '\n', 'cleaned': b + '\n', 'reason': 'Removed redundant earlier store (dead store)'})
                out_lines.append(b)
                i += 2
                continue
        out_lines.append(lines[i])
        i += 1
    cleaned = '\n'.join(out_lines)
    if cleaned != code and (not changes):
        changes.append({'original': code, 'cleaned': cleaned, 'reason': 'Junk cleaning applied (C-like)'})
    elif cleaned != code:
        changes.append({'original': code, 'cleaned': cleaned, 'reason': 'Junk cleaning applied (C-like)'})
    return changes

def detect_junk_code_python(code: str) -> List[Dict]:
    findings = []
    for m in re.finditer('^\\s*pass\\s*$', code, re.MULTILINE):
        findings.append({'type': 'pass_stmt', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\+\\s*0\\b', code):
        findings.append({'type': 'identity_add_zero', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    return findings

def clean_junk_code_python(code: str) -> List[Dict]:
    s = code
    changes = []
    s_new = re.sub('^\\s*pass\\s*$(?:\\n)?', '', s, flags=re.MULTILINE)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed redundant pass statements'})
        s = s_new
    s_new = re.sub('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\+\\s*0\\b', '\\1 = \\1', s)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed identity addition (x = x + 0).'})
        s = s_new
    return changes (Full cleaned file (Python opaque predicate simplification))
input\mixed_language.py: """
Detect mixed-language obfuscation signals, such as:
 - inline assembly or ASM blocks inside C/C++  
 - presence of JNI-like bridging code (native method definitions)  
 - generated code markers or embedded Java/Kotlin code segments in C comments
Cleaning: only report and optionally remove pure ASM nop sections or trivial inline assembler used as junk.
"""
import re
from typing import List, Dict

def detect_mixed_language(code: str) -> List[Dict]:
    findings = []
    if re.search('\\b(__asm__|asm)\\s*\\(', code):
        findings.append({'type': 'inline_asm', 'reason': 'Inline assembler block detected'})
    if re.search('#\\s*include\\s*<jni.h>', code) or re.search('System\\.loadLibrary', code):
        findings.append({'type': 'jni_bridge', 'reason': 'JNI/native bridge detected'})
    if re.search('class\\s+[A-Z]\\w+\\s*\\{', code) and re.search('#include', code):
        findings.append({'type': 'mixed_java_c', 'reason': 'Mixed Java/C code smells (both class and #include present)'})
    return findings

def clean_mixed_language_python(code: str) -> List[Dict]:
    changes = []
    findings = detect_mixed_language(code)
    if findings:
        changes.append({'original': '', 'cleaned': '', 'reason': f'Detected mixed-language constructs: {findings}. No automatic cleaning applied.'})
    return changes

def clean_mixed_language_clike(code: str) -> List[Dict]:
    changes = []
    s = code
    s_new = re.sub('\\basm\\s*\\(\\s*".*?nop.*?"\\s*\\)\\s*;', '', s, flags=re.DOTALL | re.IGNORECASE)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed inline asm nop occurrences (mixed-language cleaning)'})
    else:
        findings = detect_mixed_language(code)
        if findings:
            changes.append({'original': '', 'cleaned': '', 'reason': f'Detected mixed-language constructs: {findings}. No automatic cleaning applied.'})
    return changes -> """
Detect mixed-language obfuscation signals, such as:
 - inline assembly or ASM blocks inside C/C++  
 - presence of JNI-like bridging code (native method definitions)  
 - generated code markers or embedded Java/Kotlin code segments in C comments
Cleaning: only report and optionally remove pure ASM nop sections or trivial inline assembler used as junk.
"""
import re
from typing import List, Dict

def detect_mixed_language(code: str) -> List[Dict]:
    findings = []
    if re.search('\\b(__asm__|asm)\\s*\\(', code):
        findings.append({'type': 'inline_asm', 'reason': 'Inline assembler block detected'})
    if re.search('#\\s*include\\s*<jni.h>', code) or re.search('System\\.loadLibrary', code):
        findings.append({'type': 'jni_bridge', 'reason': 'JNI/native bridge detected'})
    if re.search('class\\s+[A-Z]\\w+\\s*\\{', code) and re.search('#include', code):
        findings.append({'type': 'mixed_java_c', 'reason': 'Mixed Java/C code smells (both class and #include present)'})
    return findings

def clean_mixed_language_python(code: str) -> List[Dict]:
    changes = []
    findings = detect_mixed_language(code)
    if findings:
        changes.append({'original': '', 'cleaned': '', 'reason': f'Detected mixed-language constructs: {findings}. No automatic cleaning applied.'})
    return changes

def clean_mixed_language_clike(code: str) -> List[Dict]:
    changes = []
    s = code
    s_new = re.sub('\\basm\\s*\\(\\s*".*?nop.*?"\\s*\\)\\s*;', '', s, flags=re.DOTALL | re.IGNORECASE)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed inline asm nop occurrences (mixed-language cleaning)'})
    else:
        findings = detect_mixed_language(code)
        if findings:
            changes.append({'original': '', 'cleaned': '', 'reason': f'Detected mixed-language constructs: {findings}. No automatic cleaning applied.'})
    return changes (Full cleaned file (Python opaque predicate simplification))
input\nameIdentifier.py: import re
import ast
import keyword
import builtins

# ----------------------------------------
# Reserved keywords for multiple languages
# ----------------------------------------
LANG_KEYWORDS = {
    "python": set(keyword.kwlist) | set(dir(builtins)),
    "c": {
        "auto","break","case","char","const","continue","default","do","double",
        "else","enum","extern","float","for","goto","if","inline","int","long",
        "register","restrict","return","short","signed","sizeof","static",
        "struct","switch","typedef","union","unsigned","void","volatile","while"
    },
    "cpp": {
        "asm","auto","bool","break","case","catch","char","class","const","const_cast",
        "continue","default","delete","do","double","dynamic_cast","else","enum","explicit",
        "export","extern","false","float","for","friend","goto","if","inline","int","long",
        "mutable","namespace","new","operator","private","protected","public","register",
        "reinterpret_cast","return","short","signed","sizeof","static","static_cast",
        "struct","switch","template","this","throw","true","try","typedef","typeid",
        "typename","union","unsigned","using","virtual","void","volatile","wchar_t","while"
    },
    "java": {
        "abstract","assert","boolean","break","byte","case","catch","char","class","const",
        "continue","default","do","double","else","enum","extends","final","finally","float",
        "for","goto","if","implements","import","instanceof","int","interface","long",
        "native","new","package","private","protected","public","return","short","static",
        "strictfp","super","switch","synchronized","this","throw","throws","transient","try",
        "void","volatile","while"
    },
    "kotlin": {
        "as","break","class","continue","do","else","false","for","fun","if","in",
        "interface","is","null","object","package","return","super","this","throw",
        "true","try","typealias","typeof","val","var","when","while"
    }
}

# ----------------------------------------
# Identifier Obfuscation Detection
# ----------------------------------------
def is_obfuscated_name(name: str, language: str = "python") -> bool:
    """Detect obfuscated identifiers like x1a3, a1, f2 but exclude language keywords."""
    reserved = LANG_KEYWORDS.get(language, set())
    if name in reserved:
        return False
    # Rule: short name with numbers inside
    return bool(re.fullmatch(r"[a-zA-Z]"+)"\d+[a-zA-Z0-9]*", name))


# ----------------------------------------
# AST Visitor for Python
# ----------------------------------------
class NameCollector(ast.NodeVisitor):
    """Collects identifiers from Python AST."""
    def __init__(self, language="python"):
        self.funcs = set()
        self.classes = set()
        self.vars = set()
        self.language = language

    def visit_FunctionDef(self, node):
        if is_obfuscated_name(node.name, self.language):
            self.funcs.add(node.name)
        for arg in node.args.args:
            if is_obfuscated_name(arg.arg, self.language):
                self.vars.add(arg.arg)
        self.generic_visit(node)

    def visit_ClassDef(self, node):
        if is_obfuscated_name(node.name, self.language):
            self.classes.add(node.name)
        self.generic_visit(node)

    def visit_Name(self, node):
        if is_obfuscated_name(node.id, self.language):
            self.vars.add(node.id)


# ----------------------------------------
# Main Cleaner Class (like FakeConditionCleaner)
# ----------------------------------------
class IdentifierCleaner:
    """Detects obfuscated identifiers and returns original, cleaned, reason."""

    def __init__(self, language="python"):
        self.language = language

    def detect_and_clean(self, code):
        """
        Returns:
            changes: list of dicts with keys ['original', 'cleaned', 'reason']
            cleaned_code: code after replacing obfuscated identifiers
        """
        mapping = {}
        changes = []
        func_count, class_count, var_count = 1, 1, 1

        # ----------------------------------------
        # Python AST-based collection
        # ----------------------------------------
        if self.language == "python":
            tree = ast.parse(code)
            collector = NameCollector(self.language)
            collector.visit(tree)

            for f in sorted(collector.funcs):
                mapping[f] = f"func{func_count}"; func_count += 1
            for c in sorted(collector.classes):
                mapping[c] = f"Class{class_count}"; class_count += 1
            for v in sorted(collector.vars):
                mapping[v] = f"var{var_count}"; var_count += 1

        # ----------------------------------------
        # Regex-based collection for other languages
        # ----------------------------------------
        else:
            identifiers = re.findall(r"\b[a-zA-Z_][a-zA-Z0-9_]*\b", code)
            for name in set(identifiers):
                if is_obfuscated_name(name, self.language):
                    if re.match(r"^[A-Z]", name):  # Class
                        mapping[name] = f"Class{class_count}"; class_count += 1
                    elif re.match(r"^[a-z]", name):
                        if re.search(r"\d", name):  # func-like
                            mapping[name] = f"func{func_count}"; func_count += 1
                        else:
                            mapping[name] = f"var{var_count}"; var_count += 1

        # ----------------------------------------
        # Apply mapping and generate change log
        # ----------------------------------------
        def replace_identifier(match):
            word = match.group(0)
            new_word = mapping.get(word, word)
            if word != new_word:
                changes.append({
                    "original": word,
                    "cleaned": new_word,
                    "reason": f"Obfuscated identifier replaced ({word} → {new_word})"
                })
            return new_word

        cleaned_code = re.sub(r"\b[a-zA-Z_][a-zA-Z0-9_]*\b", replace_identifier, code)
        return changes, cleaned_code


# ----------------------------------------
# Language Detection Helper
# ----------------------------------------
def detect_language(filename: str) -> str:
    """Detect programming language from file extension."""
    ext = filename.split(".")[-1].lower()
    if ext == "py":
        return "python"
    elif ext in ("c", "h"):
        return "c"
    elif ext == "cpp":
        return "cpp"
    elif ext == "java":
        return "java"
    elif ext == "kt":
        return "kotlin"
    return "unknown" -> import re
import ast
import keyword
import builtins

# ----------------------------------------
# Reserved keywords for multiple languages
# ----------------------------------------
LANG_KEYWORDS = {
    "python": set(keyword.kwlist) | set(dir(builtins)),
    "c": {
        "auto","break","case","char","const","continue","default","do","double",
        "else","enum","extern","float","for","goto","if","inline","int","long",
        "register","restrict","return","short","signed","sizeof","static",
        "struct","switch","typedef","union","unsigned","void","volatile","while"
    },
    "cpp": {
        "asm","auto","bool","break","case","catch","char","class","const","const_cast",
        "continue","default","delete","do","double","dynamic_cast","else","enum","explicit",
        "export","extern","false","float","for","friend","goto","if","inline","int","long",
        "mutable","namespace","new","operator","private","protected","public","register",
        "reinterpret_cast","return","short","signed","sizeof","static","static_cast",
        "struct","switch","template","this","throw","true","try","typedef","typeid",
        "typename","union","unsigned","using","virtual","void","volatile","wchar_t","while"
    },
    "java": {
        "abstract","assert","boolean","break","byte","case","catch","char","class","const",
        "continue","default","do","double","else","enum","extends","final","finally","float",
        "for","goto","if","implements","import","instanceof","int","interface","long",
        "native","new","package","private","protected","public","return","short","static",
        "strictfp","super","switch","synchronized","this","throw","throws","transient","try",
        "void","volatile","while"
    },
    "kotlin": {
        "as","break","class","continue","do","else","false","for","fun","if","in",
        "interface","is","null","object","package","return","super","this","throw",
        "true","try","typealias","typeof","val","var","when","while"
    }
}

# ----------------------------------------
# Identifier Obfuscation Detection
# ----------------------------------------
def is_obfuscated_name(name: str, language: str = "python") -> bool:
    """Detect obfuscated identifiers like x1a3, a1, f2 but exclude language keywords."""
    reserved = LANG_KEYWORDS.get(language, set())
    if name in reserved:
        return False
    # Rule: short name with numbers inside
    return bool(re.fullmatch(r"[a-zA-Z]"+)"\d+[a-zA-Z0-9]*", name))


# ----------------------------------------
# AST Visitor for Python
# ----------------------------------------
class NameCollector(ast.NodeVisitor):
    """Collects identifiers from Python AST."""
    def __init__(self, language="python"):
        self.funcs = set()
        self.classes = set()
        self.vars = set()
        self.language = language

    def visit_FunctionDef(self, node):
        if is_obfuscated_name(node.name, self.language):
            self.funcs.add(node.name)
        for arg in node.args.args:
            if is_obfuscated_name(arg.arg, self.language):
                self.vars.add(arg.arg)
        self.generic_visit(node)

    def visit_ClassDef(self, node):
        if is_obfuscated_name(node.name, self.language):
            self.classes.add(node.name)
        self.generic_visit(node)

    def visit_Name(self, node):
        if is_obfuscated_name(node.id, self.language):
            self.vars.add(node.id)


# ----------------------------------------
# Main Cleaner Class (like FakeConditionCleaner)
# ----------------------------------------
class IdentifierCleaner:
    """Detects obfuscated identifiers and returns original, cleaned, reason."""

    def __init__(self, language="python"):
        self.language = language

    def detect_and_clean(self, code):
        """
        Returns:
            changes: list of dicts with keys ['original', 'cleaned', 'reason']
            cleaned_code: code after replacing obfuscated identifiers
        """
        mapping = {}
        changes = []
        func_count, class_count, var_count = 1, 1, 1

        # ----------------------------------------
        # Python AST-based collection
        # ----------------------------------------
        if self.language == "python":
            tree = ast.parse(code)
            collector = NameCollector(self.language)
            collector.visit(tree)

            for f in sorted(collector.funcs):
                mapping[f] = f"func{func_count}"; func_count += 1
            for c in sorted(collector.classes):
                mapping[c] = f"Class{class_count}"; class_count += 1
            for v in sorted(collector.vars):
                mapping[v] = f"var{var_count}"; var_count += 1

        # ----------------------------------------
        # Regex-based collection for other languages
        # ----------------------------------------
        else:
            identifiers = re.findall(r"\b[a-zA-Z_][a-zA-Z0-9_]*\b", code)
            for name in set(identifiers):
                if is_obfuscated_name(name, self.language):
                    if re.match(r"^[A-Z]", name):  # Class
                        mapping[name] = f"Class{class_count}"; class_count += 1
                    elif re.match(r"^[a-z]", name):
                        if re.search(r"\d", name):  # func-like
                            mapping[name] = f"func{func_count}"; func_count += 1
                        else:
                            mapping[name] = f"var{var_count}"; var_count += 1

        # ----------------------------------------
        # Apply mapping and generate change log
        # ----------------------------------------
        def replace_identifier(match):
            word = match.group(0)
            new_word = mapping.get(word, word)
            if word != new_word:
                changes.append({
                    "original": word,
                    "cleaned": new_word,
                    "reason": f"Obfuscated identifier replaced ({word} → {new_word})"
                })
            return new_word

        cleaned_code = re.sub(r"\b[a-zA-Z_][a-zA-Z0-9_]*\b", replace_identifier, code)
        return changes, cleaned_code


# ----------------------------------------
# Language Detection Helper
# ----------------------------------------
def detect_language(filename: str) -> str:
    """Detect programming language from file extension."""
    ext = filename.split(".")[-1].lower()
    if ext == "py":
        return "python"
    elif ext in ("c", "h"):
        return "c"
    elif ext == "cpp":
        return "cpp"
    elif ext == "java":
        return "java"
    elif ext == "kt":
        return "kotlin"
    return "unknown" (parse_error: unmatched ')' (<unknown>, line 50))
input\opaque_predicate.py: # Opaque Predicate Complex Test Cases

# 1. Always true with redundant check inside loop

"""for i in range(2):
    if (2 + 2 == 4) and (3 > 1):
        print("Loop always true:", i)

# 2. Always false predicate (never executes)
for j in range(3):
    if (5 < 2) or (10 < 3):
        print("This will never print", j)

# 3. Constant comparison with while loop
k = 0
while k < 2:
    if (100 == 100):
        print("While loop always true", k)
    k += 1

# 4. Arithmetic inside comparison
if (2 * 3 == 6) and (4 - 1 == 3):
    print("Inline arithmetic always true")

# 5. Complex but always true condition in function
def check_predicate():
    if (50 - 25 == 25) and (4**2 == 16):
        return "Function always true"
    return "Unreachable"

print(check_predicate())

# 6. Complex but false inside loop
for i in range(2):
    if (9 % 2 == 0) or (7 < 3):
        print("Never executes")

# 7. Nested opaque predicates
if ((10/2) == 5):
    if ((3*3) == 9):
        print("Nested always true")

# 8. Redundant always true inside loop
for i in range(2):
    if (8 > 3) and (2 < 5):
        print("Redundant always true", i)

# 9. Impossible opaque condition
if (1 == 2) or (0 > 10):
    print("Impossible branch")

# 10. Hidden constant compare inside function + loop
def hidden_check(x):
    if (x * 2 == 8) and (16/4 == 4):
        return True
    return False

for val in "./":
    if hidden_check(val):
        print("Hidden opaque true for", val)"""


# analyzers/opaque_predicate.py
import ast
import re
from typing import List, Dict

# Reuse the same safe AST evaluator from inline_expansion; to avoid circular import, copy minimal evaluator:
_ALLOWED_BINOPS = (ast.Add, ast.Sub, ast.Mult, ast.Div, ast.Mod, ast.Pow,
                   ast.LShift, ast.RShift, ast.BitAnd, ast.BitOr, ast.BitXor, ast.FloorDiv)
_ALLOWED_UNARYOPS = (ast.UAdd, ast.USub, ast.Invert)

def _eval_constant_ast(node):
    if isinstance(node, ast.Constant):
        return node.value
    if isinstance(node, ast.UnaryOp) and isinstance(node.op, _ALLOWED_UNARYOPS):
        val = _eval_constant_ast(node.operand)
        if isinstance(node.op, ast.UAdd): return +val
        if isinstance(node.op, ast.USub): return -val
        if isinstance(node.op, ast.Invert): return ~val
    if isinstance(node, ast.BinOp) and isinstance(node.op, _ALLOWED_BINOPS):
        L = _eval_constant_ast(node.left)
        R = _eval_constant_ast(node.right)
        op = node.op
        if isinstance(op, ast.Add): return L + R
        if isinstance(op, ast.Sub): return L - R
        if isinstance(op, ast.Mult): return L * R
        if isinstance(op, ast.Div): return L / R
        if isinstance(op, ast.FloorDiv): return L // R
        if isinstance(op, ast.Mod): return L % R
        if isinstance(op, ast.Pow): return L ** R
        if isinstance(op, ast.LShift): return L << R
        if isinstance(op, ast.RShift): return L >> R
        if isinstance(op, ast.BitAnd): return L & R
        if isinstance(op, ast.BitOr): return L | R
        if isinstance(op, ast.BitXor): return L ^ R
    if isinstance(node, ast.Compare):
        left = _eval_constant_ast(node.left)
        # single comparator supported
        comp = node.comparators"*"
        right = _eval_constant_ast(comp)
        op = node.ops"*"
        if isinstance(op, ast.Eq): return left == right
        if isinstance(op, ast.NotEq): return left != right
        if isinstance(op, ast.Lt): return left < right
        if isinstance(op, ast.LtE): return left <= right
        if isinstance(op, ast.Gt): return left > right
        if isinstance(op, ast.GtE): return left >= right
    if isinstance(node, ast.BoolOp):
        # evaluate values if possible
        values = [_eval_constant_ast(v) for v in node.values]
        if isinstance(node.op, ast.And):
            return all(values)
        else:
            return any(values)
    raise ValueError("Not constant-evaluable")

# ---------------- Python detection/cleaning ----------------
def detect_opaque_predicate_python(code: str) -> List[Dict]:
    findings = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{"type": "parse_error", "reason": str(e)}]
    class V(ast.NodeVisitor):
        def visit_If(self, node):
            # try to evaluate the test
            try:
                val = _eval_constant_ast(node.test)
                findings.append({"type": "opaque_always", "lineno": node.lineno, "value": bool(val), "expr": ast.unparse(node.test)})
            except Exception:
                # check for Compare with constant operands inside BoolOp
                if isinstance(node.test, ast.BoolOp):
                    for v in node.test.values:
                        if isinstance(v, ast.Compare):
                            left = v.left
                            if isinstance(left, ast.BinOp) and isinstance(left.left, ast.Constant) and isinstance(left.right, ast.Constant):
                                findings.append({"type": "opaque_arith", "lineno": node.lineno, "expr": ast.unparse(v)})
            self.generic_visit(node)
    V().visit(tree)
    return findings

def clean_opaque_predicate_python(code: str) -> List[Dict]:
    """
    Replace opaque predicates that evaluate to True with their body,
    remove those that evaluate to False.
    """
    results = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{"original": code, "cleaned": code, "reason": f"parse_error: {e}"}]

    class Transformer(ast.NodeTransformer):
        def __init__(self):
            self.changes = []
        def visit_If(self, node):
            # try eval test
            try:
                val = _eval_constant_ast(node.test)
                orig = ast.unparse(node)
                if bool(val):
                    # keep body (inline)
                    cleaned = "\n".join([ast.unparse(n) for n in node.body])
                    self.changes.append({"original": orig, "cleaned": cleaned, "reason": "Opaque predicate evaluated True -> inlined body"})
                    return node.body
                else:
                    # remove if entirely or keep else if present
                    cleaned = ""
                    if node.orelse:
                        cleaned = "\n".join([ast.unparse(n) for n in node.orelse])
                    self.changes.append({"original": orig, "cleaned": cleaned, "reason": "Opaque predicate evaluated False -> removed or replaced with else"})
                    # replace with else-body if exists
                    return node.orelse or []
            except Exception:
                return self.generic_visit(node)

    t = Transformer()
    new_tree = t.visit(tree)
    try:
        new_code = ast.unparse(new_tree)
    except Exception:
        new_code = code
    results.extend(t.changes)
    results.append({"original": code, "cleaned": new_code, "reason": "Full cleaned file (Python opaque predicate simplification)"})
    return results

# ---------------- C-like detection/cleaning (regex) ----------------
_cmp_re = re.compile(r'\b(\d+(?:\s*[\+\-\*\/]\s*\d+)*)\s*(==|!=|>|<|>=|<=)\s*(\d+(?:\s*[\+\-\*\/]\s*\d+)*)')

def _safe_eval_num_expr(expr: str):
    # only digits, whitespace, and operators allowed
    if not re.fullmatch(r'[0-9\+\-\*\/%\s\(\)]+', expr):
        raise ValueError("unsafe expr")
    # evaluate using Python integer math (floor division)
    # replace / with // for integer division
    expr2 = expr.replace('/', '//')
    return eval(expr2)

def detect_opaque_predicate_clike(code: str, lang="C-like") -> List[Dict]:
    findings = []
    for i, line in enumerate(code.splitlines(), start=1):
        for m in _cmp_re.finditer(line):
            left, op, right = m.groups()
            try:
                lv = _safe_eval_num_expr(left)
                rv = _safe_eval_num_expr(right)
                # compare
                ok = False
                if op == '==': ok = (lv == rv)
                elif op == '!=': ok = (lv != rv)
                elif op == '<': ok = (lv < rv)
                elif op == '<=': ok = (lv <= rv)
                elif op == '>': ok = (lv > rv)
                elif op == '>=': ok = (lv >= rv)
                findings.append({"type": "opaque_cmp_const", "lineno": i, "expr": m.group(0), "value": ok, "lang": lang})
            except Exception:
                findings.append({"type": "opaque_cmp_unknown", "lineno": i, "expr": m.group(0), "lang": lang})
    return findings

def clean_opaque_predicate_clike(code: str) -> List[Dict]:
    """
    For identified constant comparisons, attempt to simplify:
      - if condition is always true: replace `if(cond){block}else{else}` -> keep block
      - if always false: remove block or keep else
    Very conservative textual approach: only handles simple one-line if statements and braced blocks.
    """
    changes = []
    s = code
    # find simple if (...) { ... } else { ... } patterns with constant numeric comparisons inside parentheses
    if_pattern = re.compile(r'if\s*\(\s*([^\)]+)\s*\)\s*(\{(?:[^{}]|\{[^}]*\})*\}|[^\n;]*;)\s*(else\s*(\{(?:[^{}]|\{[^}]*\})*\}|[^\n;]*;))?', re.DOTALL)
    pos = 0
    while True:
        m = if_pattern.search(s, pos)
        if not m:
            break
        cond = m.group(1)
        body = m.group(2)
        else_part = m.group(3) or ""
        try:
            # attempt to evaluate cond if it's a simple arithmetic comparison
            mm = _cmp_re.search(cond)
            if mm:
                left, op, right = mm.groups()
                lv = _safe_eval_num_expr(left)
                rv = _safe_eval_num_expr(right)
                if op == '==': val = (lv == rv)
                elif op == '!=': val = (lv != rv)
                elif op == '<': val = (lv < rv)
                elif op == '<=': val = (lv <= rv)
                elif op == '>': val = (lv > rv)
                elif op == '>=': val = (lv >= rv)
                if val:
                    # keep body, remove if(...) and else
                    cleaned = body
                    changes.append({"original": m.group(0), "cleaned": cleaned, "reason": "Opaque condition evaluated True — inlined body"})
                    s = s[:m.start()] + cleaned + s[m.end():]
                    pos = m.start() + len(cleaned)
                    continue
                else:
                    # remove body, keep else if present
                    cleaned = else_part if else_part else ""
                    changes.append({"original": m.group(0), "cleaned": cleaned, "reason": "Opaque condition evaluated False — removed body / kept else"})
                    s = s[:m.start()] + cleaned + s[m.end():]
                    pos = m.start() + len(cleaned)
                    continue
        except Exception:
            pass
        pos = m.end()
    if changes:
        changes.append({"original": code, "cleaned": s, "reason": "Applied simple opaque predicate simplification (C-like)"})
    return changes
 -> # Opaque Predicate Complex Test Cases

# 1. Always true with redundant check inside loop

"""for i in range(2):
    if (2 + 2 == 4) and (3 > 1):
        print("Loop always true:", i)

# 2. Always false predicate (never executes)
for j in range(3):
    if (5 < 2) or (10 < 3):
        print("This will never print", j)

# 3. Constant comparison with while loop
k = 0
while k < 2:
    if (100 == 100):
        print("While loop always true", k)
    k += 1

# 4. Arithmetic inside comparison
if (2 * 3 == 6) and (4 - 1 == 3):
    print("Inline arithmetic always true")

# 5. Complex but always true condition in function
def check_predicate():
    if (50 - 25 == 25) and (4**2 == 16):
        return "Function always true"
    return "Unreachable"

print(check_predicate())

# 6. Complex but false inside loop
for i in range(2):
    if (9 % 2 == 0) or (7 < 3):
        print("Never executes")

# 7. Nested opaque predicates
if ((10/2) == 5):
    if ((3*3) == 9):
        print("Nested always true")

# 8. Redundant always true inside loop
for i in range(2):
    if (8 > 3) and (2 < 5):
        print("Redundant always true", i)

# 9. Impossible opaque condition
if (1 == 2) or (0 > 10):
    print("Impossible branch")

# 10. Hidden constant compare inside function + loop
def hidden_check(x):
    if (x * 2 == 8) and (16/4 == 4):
        return True
    return False

for val in "./":
    if hidden_check(val):
        print("Hidden opaque true for", val)"""


# analyzers/opaque_predicate.py
import ast
import re
from typing import List, Dict

# Reuse the same safe AST evaluator from inline_expansion; to avoid circular import, copy minimal evaluator:
_ALLOWED_BINOPS = (ast.Add, ast.Sub, ast.Mult, ast.Div, ast.Mod, ast.Pow,
                   ast.LShift, ast.RShift, ast.BitAnd, ast.BitOr, ast.BitXor, ast.FloorDiv)
_ALLOWED_UNARYOPS = (ast.UAdd, ast.USub, ast.Invert)

def _eval_constant_ast(node):
    if isinstance(node, ast.Constant):
        return node.value
    if isinstance(node, ast.UnaryOp) and isinstance(node.op, _ALLOWED_UNARYOPS):
        val = _eval_constant_ast(node.operand)
        if isinstance(node.op, ast.UAdd): return +val
        if isinstance(node.op, ast.USub): return -val
        if isinstance(node.op, ast.Invert): return ~val
    if isinstance(node, ast.BinOp) and isinstance(node.op, _ALLOWED_BINOPS):
        L = _eval_constant_ast(node.left)
        R = _eval_constant_ast(node.right)
        op = node.op
        if isinstance(op, ast.Add): return L + R
        if isinstance(op, ast.Sub): return L - R
        if isinstance(op, ast.Mult): return L * R
        if isinstance(op, ast.Div): return L / R
        if isinstance(op, ast.FloorDiv): return L // R
        if isinstance(op, ast.Mod): return L % R
        if isinstance(op, ast.Pow): return L ** R
        if isinstance(op, ast.LShift): return L << R
        if isinstance(op, ast.RShift): return L >> R
        if isinstance(op, ast.BitAnd): return L & R
        if isinstance(op, ast.BitOr): return L | R
        if isinstance(op, ast.BitXor): return L ^ R
    if isinstance(node, ast.Compare):
        left = _eval_constant_ast(node.left)
        # single comparator supported
        comp = node.comparators"*"
        right = _eval_constant_ast(comp)
        op = node.ops"*"
        if isinstance(op, ast.Eq): return left == right
        if isinstance(op, ast.NotEq): return left != right
        if isinstance(op, ast.Lt): return left < right
        if isinstance(op, ast.LtE): return left <= right
        if isinstance(op, ast.Gt): return left > right
        if isinstance(op, ast.GtE): return left >= right
    if isinstance(node, ast.BoolOp):
        # evaluate values if possible
        values = [_eval_constant_ast(v) for v in node.values]
        if isinstance(node.op, ast.And):
            return all(values)
        else:
            return any(values)
    raise ValueError("Not constant-evaluable")

# ---------------- Python detection/cleaning ----------------
def detect_opaque_predicate_python(code: str) -> List[Dict]:
    findings = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{"type": "parse_error", "reason": str(e)}]
    class V(ast.NodeVisitor):
        def visit_If(self, node):
            # try to evaluate the test
            try:
                val = _eval_constant_ast(node.test)
                findings.append({"type": "opaque_always", "lineno": node.lineno, "value": bool(val), "expr": ast.unparse(node.test)})
            except Exception:
                # check for Compare with constant operands inside BoolOp
                if isinstance(node.test, ast.BoolOp):
                    for v in node.test.values:
                        if isinstance(v, ast.Compare):
                            left = v.left
                            if isinstance(left, ast.BinOp) and isinstance(left.left, ast.Constant) and isinstance(left.right, ast.Constant):
                                findings.append({"type": "opaque_arith", "lineno": node.lineno, "expr": ast.unparse(v)})
            self.generic_visit(node)
    V().visit(tree)
    return findings

def clean_opaque_predicate_python(code: str) -> List[Dict]:
    """
    Replace opaque predicates that evaluate to True with their body,
    remove those that evaluate to False.
    """
    results = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{"original": code, "cleaned": code, "reason": f"parse_error: {e}"}]

    class Transformer(ast.NodeTransformer):
        def __init__(self):
            self.changes = []
        def visit_If(self, node):
            # try eval test
            try:
                val = _eval_constant_ast(node.test)
                orig = ast.unparse(node)
                if bool(val):
                    # keep body (inline)
                    cleaned = "\n".join([ast.unparse(n) for n in node.body])
                    self.changes.append({"original": orig, "cleaned": cleaned, "reason": "Opaque predicate evaluated True -> inlined body"})
                    return node.body
                else:
                    # remove if entirely or keep else if present
                    cleaned = ""
                    if node.orelse:
                        cleaned = "\n".join([ast.unparse(n) for n in node.orelse])
                    self.changes.append({"original": orig, "cleaned": cleaned, "reason": "Opaque predicate evaluated False -> removed or replaced with else"})
                    # replace with else-body if exists
                    return node.orelse or []
            except Exception:
                return self.generic_visit(node)

    t = Transformer()
    new_tree = t.visit(tree)
    try:
        new_code = ast.unparse(new_tree)
    except Exception:
        new_code = code
    results.extend(t.changes)
    results.append({"original": code, "cleaned": new_code, "reason": "Full cleaned file (Python opaque predicate simplification)"})
    return results

# ---------------- C-like detection/cleaning (regex) ----------------
_cmp_re = re.compile(r'\b(\d+(?:\s*[\+\-\*\/]\s*\d+)*)\s*(==|!=|>|<|>=|<=)\s*(\d+(?:\s*[\+\-\*\/]\s*\d+)*)')

def _safe_eval_num_expr(expr: str):
    # only digits, whitespace, and operators allowed
    if not re.fullmatch(r'[0-9\+\-\*\/%\s\(\)]+', expr):
        raise ValueError("unsafe expr")
    # evaluate using Python integer math (floor division)
    # replace / with // for integer division
    expr2 = expr.replace('/', '//')
    return eval(expr2)

def detect_opaque_predicate_clike(code: str, lang="C-like") -> List[Dict]:
    findings = []
    for i, line in enumerate(code.splitlines(), start=1):
        for m in _cmp_re.finditer(line):
            left, op, right = m.groups()
            try:
                lv = _safe_eval_num_expr(left)
                rv = _safe_eval_num_expr(right)
                # compare
                ok = False
                if op == '==': ok = (lv == rv)
                elif op == '!=': ok = (lv != rv)
                elif op == '<': ok = (lv < rv)
                elif op == '<=': ok = (lv <= rv)
                elif op == '>': ok = (lv > rv)
                elif op == '>=': ok = (lv >= rv)
                findings.append({"type": "opaque_cmp_const", "lineno": i, "expr": m.group(0), "value": ok, "lang": lang})
            except Exception:
                findings.append({"type": "opaque_cmp_unknown", "lineno": i, "expr": m.group(0), "lang": lang})
    return findings

def clean_opaque_predicate_clike(code: str) -> List[Dict]:
    """
    For identified constant comparisons, attempt to simplify:
      - if condition is always true: replace `if(cond){block}else{else}` -> keep block
      - if always false: remove block or keep else
    Very conservative textual approach: only handles simple one-line if statements and braced blocks.
    """
    changes = []
    s = code
    # find simple if (...) { ... } else { ... } patterns with constant numeric comparisons inside parentheses
    if_pattern = re.compile(r'if\s*\(\s*([^\)]+)\s*\)\s*(\{(?:[^{}]|\{[^}]*\})*\}|[^\n;]*;)\s*(else\s*(\{(?:[^{}]|\{[^}]*\})*\}|[^\n;]*;))?', re.DOTALL)
    pos = 0
    while True:
        m = if_pattern.search(s, pos)
        if not m:
            break
        cond = m.group(1)
        body = m.group(2)
        else_part = m.group(3) or ""
        try:
            # attempt to evaluate cond if it's a simple arithmetic comparison
            mm = _cmp_re.search(cond)
            if mm:
                left, op, right = mm.groups()
                lv = _safe_eval_num_expr(left)
                rv = _safe_eval_num_expr(right)
                if op == '==': val = (lv == rv)
                elif op == '!=': val = (lv != rv)
                elif op == '<': val = (lv < rv)
                elif op == '<=': val = (lv <= rv)
                elif op == '>': val = (lv > rv)
                elif op == '>=': val = (lv >= rv)
                if val:
                    # keep body, remove if(...) and else
                    cleaned = body
                    changes.append({"original": m.group(0), "cleaned": cleaned, "reason": "Opaque condition evaluated True — inlined body"})
                    s = s[:m.start()] + cleaned + s[m.end():]
                    pos = m.start() + len(cleaned)
                    continue
                else:
                    # remove body, keep else if present
                    cleaned = else_part if else_part else ""
                    changes.append({"original": m.group(0), "cleaned": cleaned, "reason": "Opaque condition evaluated False — removed body / kept else"})
                    s = s[:m.start()] + cleaned + s[m.end():]
                    pos = m.start() + len(cleaned)
                    continue
        except Exception:
            pass
        pos = m.end()
    if changes:
        changes.append({"original": code, "cleaned": s, "reason": "Applied simple opaque predicate simplification (C-like)"})
    return changes
 (parse_error: invalid syntax (<unknown>, line 100))
input\stringEncryption.py: import re

def xor_decrypt(enc_list, key=42):
    """XOR decrypt a list of integers to a string."""
    try:
        return ''.join((chr(c ^ key) for c in enc_list))
    except Exception:
        return None

class StringDecryptor:
    """Detects and decrypts XOR-encrypted strings in code."""

    def __init__(self, key=42):
        self.key = key

    def detect_strings(self, code: str):
        """Detect candidate encrypted strings as list of integers."""
        pattern = re.compile('[\\[{]([0-9,\\s]+)[\\]}]')
        results = []
        for match in pattern.finditer(code):
            str_bytes = match.group(1)
            try:
                enc_list = [int(b.strip()) for b in str_bytes.split(',') if b.strip().isdigit()]
                decrypted = xor_decrypt(enc_list, self.key)
                if decrypted and all((32 <= ord(ch) <= 126 for ch in decrypted)):
                    results.append({'original': match.group(0), 'decrypted': decrypted, 'position': match.start(), 'reason': 'XOR-encrypted string detected and decrypted'})
            except Exception:
                continue
        return results

    def detect_and_clean(self, code: str):
        """Detect encrypted strings, replace them, and return changes and final code."""
        results = self.detect_strings(code)
        cleaned_code = code
        for res in reversed(results):
            start_idx = cleaned_code.find(res['original'])
            if start_idx != -1:
                cleaned_code = cleaned_code[:start_idx] + f'"{res['decrypted']}"' + cleaned_code[start_idx + len(res['original']):]
                res['cleaned'] = f'"{res['decrypted']}"'
        return (results, cleaned_code) -> import re

def xor_decrypt(enc_list, key=42):
    """XOR decrypt a list of integers to a string."""
    try:
        return ''.join((chr(c ^ key) for c in enc_list))
    except Exception:
        return None

class StringDecryptor:
    """Detects and decrypts XOR-encrypted strings in code."""

    def __init__(self, key=42):
        self.key = key

    def detect_strings(self, code: str):
        """Detect candidate encrypted strings as list of integers."""
        pattern = re.compile('[\\[{]([0-9,\\s]+)[\\]}]')
        results = []
        for match in pattern.finditer(code):
            str_bytes = match.group(1)
            try:
                enc_list = [int(b.strip()) for b in str_bytes.split(',') if b.strip().isdigit()]
                decrypted = xor_decrypt(enc_list, self.key)
                if decrypted and all((32 <= ord(ch) <= 126 for ch in decrypted)):
                    results.append({'original': match.group(0), 'decrypted': decrypted, 'position': match.start(), 'reason': 'XOR-encrypted string detected and decrypted'})
            except Exception:
                continue
        return results

    def detect_and_clean(self, code: str):
        """Detect encrypted strings, replace them, and return changes and final code."""
        results = self.detect_strings(code)
        cleaned_code = code
        for res in reversed(results):
            start_idx = cleaned_code.find(res['original'])
            if start_idx != -1:
                cleaned_code = cleaned_code[:start_idx] + f'"{res['decrypted']}"' + cleaned_code[start_idx + len(res['original']):]
                res['cleaned'] = f'"{res['decrypted']}"'
        return (results, cleaned_code) (Full cleaned file (Python opaque predicate simplification))



===== Control Flow Flattening =====

input\controlflow_flattening.py:  ->  (Detected Python flattened control-flow patterns. Manual reconstruction recommended.)
input\inlineExpansion.py:  ->  (Detected Python flattened control-flow patterns. Manual reconstruction recommended.)



===== Instruction Substitution =====

input\instruction_substitution.py: x - (-1) -> x + 1 (Canonicalized: neg-neg to plus)
input\instruction_substitution.py: x + x -> 2 * x (Canonicalized: x+x to 2*x)
input\instruction_substitution.py: x+x -> 2 * x (Canonicalized: x+x to 2*x)
input\instruction_substitution.py: x+x -> 2 * x (Canonicalized: x+x to 2*x)
input\instruction_substitution.py: """
Detect instruction substitution like:
  - x - (-1)  -> x + 1
  - x << 1    -> x * 2
  - x + x     -> 2 * x  (or x * 2)
  - bitwise tricks (x ^ -1) etc.
We'll canonicalize a few safe patterns.
"""
import re
from typing import List, Dict
_CLIKE_PATTERNS = [(re.compile('([A-Za-z_]\\w*)\\s*-\\s*\\(\\s*-\\s*1\\s*\\)'), '\\1 + 1', 'neg-neg to plus'), (re.compile('([A-Za-z_]\\w*)\\s*<<\\s*1\\b'), '\\1 * 2', 'shift-left to multiply'), (re.compile('\\b([A-Za-z_]\\w*)\\s*\\+\\s*\\1\\b'), '2 * \\1', 'x+x to 2*x'), (re.compile('--([A-Za-z_]\\w*)'), '\\1', 'double-neg')]

def detect_instruction_substitution_clike(code: str) -> List[Dict]:
    findings = []
    for pat, repl, reason in _CLIKE_PATTERNS:
        for m in pat.finditer(code):
            findings.append({'type': 'instr_sub', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0), 'suggest': repl, 'reason': reason})
    return findings

def clean_instruction_substitution_clike(code: str) -> List[Dict]:
    changes = []
    s = code
    for pat, repl, reason in _CLIKE_PATTERNS:
        for m in pat.finditer(s):
            orig = m.group(0)
            new = pat.sub(repl, orig)
            changes.append({'original': orig, 'cleaned': new, 'reason': f'Canonicalized: {reason}'})
        s = pat.sub(repl, s)
    if changes:
        changes.append({'original': code, 'cleaned': s, 'reason': 'Applied instruction substitution canonicalization (C-like)'})
    return changes
_PY_PATTERNS = [(re.compile('([A-Za-z_]\\w*)\\s*-\\s*\\(\\s*-\\s*1\\s*\\)'), '\\1 + 1', 'neg-neg to plus'), (re.compile('\\b([A-Za-z_]\\w*)\\s*\\+\\s*\\1\\b'), '2 * \\1', 'x+x to 2*x')]

def detect_instruction_substitution_python(code: str) -> List[Dict]:
    findings = []
    for pat, repl, reason in _PY_PATTERNS:
        for m in pat.finditer(code):
            findings.append({'type': 'instr_sub_py', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0), 'suggest': repl, 'reason': reason})
    return findings

def clean_instruction_substitution_python(code: str) -> List[Dict]:
    s = code
    changes = []
    for pat, repl, reason in _PY_PATTERNS:
        for m in pat.finditer(s):
            orig = m.group(0)
            new = pat.sub(repl, orig)
            changes.append({'original': orig, 'cleaned': new, 'reason': f'Canonicalized: {reason}'})
        s = pat.sub(repl, s)
    if changes:
        changes.append({'original': code, 'cleaned': s, 'reason': 'Applied instruction substitution canonicalization (Python)'})
    return changes -> """
Detect instruction substitution like:
  - x + 1  -> x + 1
  - x << 1    -> x * 2
  - 2 * x     -> 2 * x  (or x * 2)
  - bitwise tricks (x ^ -1) etc.
We'll canonicalize a few safe patterns.
"""
import re
from typing import List, Dict
_CLIKE_PATTERNS = [(re.compile('([A-Za-z_]\\w*)\\s*-\\s*\\(\\s*-\\s*1\\s*\\)'), '\\1 + 1', 'neg-neg to plus'), (re.compile('([A-Za-z_]\\w*)\\s*<<\\s*1\\b'), '\\1 * 2', 'shift-left to multiply'), (re.compile('\\b([A-Za-z_]\\w*)\\s*\\+\\s*\\1\\b'), '2 * \\1', '2 * x to 2*x'), (re.compile('--([A-Za-z_]\\w*)'), '\\1', 'double-neg')]

def detect_instruction_substitution_clike(code: str) -> List[Dict]:
    findings = []
    for pat, repl, reason in _CLIKE_PATTERNS:
        for m in pat.finditer(code):
            findings.append({'type': 'instr_sub', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0), 'suggest': repl, 'reason': reason})
    return findings

def clean_instruction_substitution_clike(code: str) -> List[Dict]:
    changes = []
    s = code
    for pat, repl, reason in _CLIKE_PATTERNS:
        for m in pat.finditer(s):
            orig = m.group(0)
            new = pat.sub(repl, orig)
            changes.append({'original': orig, 'cleaned': new, 'reason': f'Canonicalized: {reason}'})
        s = pat.sub(repl, s)
    if changes:
        changes.append({'original': code, 'cleaned': s, 'reason': 'Applied instruction substitution canonicalization (C-like)'})
    return changes
_PY_PATTERNS = [(re.compile('([A-Za-z_]\\w*)\\s*-\\s*\\(\\s*-\\s*1\\s*\\)'), '\\1 + 1', 'neg-neg to plus'), (re.compile('\\b([A-Za-z_]\\w*)\\s*\\+\\s*\\1\\b'), '2 * \\1', '2 * x to 2*x')]

def detect_instruction_substitution_python(code: str) -> List[Dict]:
    findings = []
    for pat, repl, reason in _PY_PATTERNS:
        for m in pat.finditer(code):
            findings.append({'type': 'instr_sub_py', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0), 'suggest': repl, 'reason': reason})
    return findings

def clean_instruction_substitution_python(code: str) -> List[Dict]:
    s = code
    changes = []
    for pat, repl, reason in _PY_PATTERNS:
        for m in pat.finditer(s):
            orig = m.group(0)
            new = pat.sub(repl, orig)
            changes.append({'original': orig, 'cleaned': new, 'reason': f'Canonicalized: {reason}'})
        s = pat.sub(repl, s)
    if changes:
        changes.append({'original': code, 'cleaned': s, 'reason': 'Applied instruction substitution canonicalization (Python)'})
    return changes (Applied instruction substitution canonicalization (Python))



===== Dynamic Code Loading =====

input\controlFlow.py:  ->  (Detected dynamic constructs (eval/exec/compile/reflection). Manual review required: [{'type': 'dynamic_py', 'lineno': 17, 'snippet': 'compile(', 'reason': 'dynamic execution/reflection'}, {'type': 'dynamic_py', 'lineno': 18, 'snippet': 'compile(', 'reason': 'dynamic execution/reflection'}, {'type': 'dynamic_py', 'lineno': 19, 'snippet': 'compile(', 'reason': 'dynamic execution/reflection'}, {'type': 'dynamic_py', 'lineno': 24, 'snippet': 'compile(', 'reason': 'dynamic execution/reflection'}, {'type': 'dynamic_py', 'lineno': 25, 'snippet': 'compile(', 'reason': 'dynamic execution/reflection'}, {'type': 'dynamic_py', 'lineno': 26, 'snippet': 'compile(', 'reason': 'dynamic execution/reflection'}])
input\controlflow_flattening.py:  ->  (Detected dynamic constructs (eval/exec/compile/reflection). Manual review required: [{'type': 'dynamic_py', 'lineno': 11, 'snippet': 'compile(', 'reason': 'dynamic execution/reflection'}])
input\deadCode.py:  ->  (Detected dynamic constructs (eval/exec/compile/reflection). Manual review required: [{'type': 'dynamic_py', 'lineno': 228, 'snippet': 'compile(', 'reason': 'dynamic execution/reflection'}, {'type': 'dynamic_py', 'lineno': 237, 'snippet': 'compile(', 'reason': 'dynamic execution/reflection'}, {'type': 'dynamic_py', 'lineno': 252, 'snippet': 'compile(', 'reason': 'dynamic execution/reflection'}, {'type': 'dynamic_py', 'lineno': 129, 'snippet': 'getattr(', 'reason': 'dynamic execution/reflection'}, {'type': 'dynamic_py', 'lineno': 144, 'snippet': 'getattr(', 'reason': 'dynamic execution/reflection'}])
input\dynamic_loading.py:  ->  (Detected dynamic constructs (eval/exec/compile/reflection). Manual review required: [{'type': 'dynamic_py', 'lineno': 11, 'snippet': 'compile(', 'reason': 'dynamic execution/reflection'}, {'type': 'dynamic_py', 'lineno': 11, 'snippet': 'compile(', 'reason': 'dynamic execution/reflection'}, {'type': 'dynamic_py', 'lineno': 11, 'snippet': 'compile(', 'reason': 'dynamic execution/reflection'}, {'type': 'dynamic_py', 'lineno': 11, 'snippet': 'compile(', 'reason': 'dynamic execution/reflection'}, {'type': 'dynamic_py', 'lineno': 11, 'snippet': 'compile(', 'reason': 'dynamic execution/reflection'}, {'type': 'dynamic_py', 'lineno': 11, 'snippet': 'compile(', 'reason': 'dynamic execution/reflection'}])
input\inlineExpansion.py:  ->  (Detected dynamic constructs (eval/exec/compile/reflection). Manual review required: [{'type': 'dynamic_py', 'lineno': 153, 'snippet': 'compile(', 'reason': 'dynamic execution/reflection'}])
input\instruction_substitution.py:  ->  (Detected dynamic constructs (eval/exec/compile/reflection). Manual review required: [{'type': 'dynamic_py', 'lineno': 11, 'snippet': 'compile(', 'reason': 'dynamic execution/reflection'}, {'type': 'dynamic_py', 'lineno': 11, 'snippet': 'compile(', 'reason': 'dynamic execution/reflection'}, {'type': 'dynamic_py', 'lineno': 11, 'snippet': 'compile(', 'reason': 'dynamic execution/reflection'}, {'type': 'dynamic_py', 'lineno': 11, 'snippet': 'compile(', 'reason': 'dynamic execution/reflection'}, {'type': 'dynamic_py', 'lineno': 32, 'snippet': 'compile(', 'reason': 'dynamic execution/reflection'}, {'type': 'dynamic_py', 'lineno': 32, 'snippet': 'compile(', 'reason': 'dynamic execution/reflection'}])
input\opaque_predicate.py:  ->  (Detected dynamic constructs (eval/exec/compile/reflection). Manual review required: [{'type': 'dynamic_py', 'lineno': 198, 'snippet': 'eval(', 'reason': 'dynamic execution/reflection'}, {'type': 'dynamic_py', 'lineno': 189, 'snippet': 'compile(', 'reason': 'dynamic execution/reflection'}, {'type': 'dynamic_py', 'lineno': 231, 'snippet': 'compile(', 'reason': 'dynamic execution/reflection'}])
input\stringEncryption.py:  ->  (Detected dynamic constructs (eval/exec/compile/reflection). Manual review required: [{'type': 'dynamic_py', 'lineno': 18, 'snippet': 'compile(', 'reason': 'dynamic execution/reflection'}])



===== Junk Code =====

input\deadCode.py: """# Dead Code Test Cases

# 1. Unused variable
x = 10   # dead
y = 20
print(y)

# 2. If condition always True
print("Always runs")
else:
    print("Dead branch")

# 3. If condition always False
else:
    print("Always runs")

# 4. Code after return
def f1():
    return 5
    print("Dead")  # dead

# 5. Code after break
for i in range(3):
    break
    print("Dead")  # dead

# 6. Unreachable else
print("Run")
else:
    print("Dead")

# 7. While False loop
while False:
    print("Never runs")  # dead

# 8. Constant condition (0 is False)
if 0:
    print("Dead")
else:
    print("Runs")

# 9. Constant condition (non-zero is True)
if 1:
    print("Runs")
else:
    print("Dead")

# 10. Multiple returns
def f2(x):
    if x > 0:
        return 1
        print("Dead")  # dead
    else:
        return -1
"""

# analyzers/deadcode.py
import ast
import re
from typing import List, Dict, Tuple

# --------------------------
# Python (AST) helpers
# --------------------------
class _DeadCodeRemover(ast.NodeTransformer):
    """
    Transformations:
      - remove `
    def visit_If(self, node: ast.If):
        # evaluate constant tests only
        try:
            if isinstance(node.test, ast.Constant):
                val = node.test.value
                if val is False:
                    original = ast.get_source_segment(self.source_text, node) if hasattr(self, "source_text") else ast.unparse(node)
                    # remove the entire if-block
                    self.changes.append((original, "", "If condition is constant False (dead code)"))
                    return None  # remove node
                elif val is True:
                    # keep body in place of if
                    body_nodes = [self.visit(b) for b in node.body]
                    original = ast.get_source_segment(self.source_text, node) if hasattr(self, "source_text") else ast.unparse(node)
                    cleaned = "\n".join([ast.unparse(b) for b in body_nodes if b is not None])
                    self.changes.append((original, cleaned, "If condition is constant True (inlined body)"))
                    return body_nodes  # splice body
        except Exception:
            pass
        self.generic_visit(node)
        return node

    def run(self, tree: ast.AST, source_text: str):
        self.source_text = source_text
        new_tree = self.visit(tree)
        return new_tree, self.changes


def detect_deadcode_python(code: str) -> List[Dict]:
    """
    Detect dead-code patterns in Python source using AST scanning.
    Returns list of findings (simple descriptions and line numbers).
    """
    findings = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        findings.append({"type": "parse_error", "reason": str(e)})
        return findings

    # If/While constant tests
    class V(ast.NodeVisitor):
        def visit_If(self, node):
            if isinstance(node.test, ast.Constant):
                if node.test.value is False:
                    findings.append({"type": "dead_if_false", "lineno": node.lineno, "snippet": ast.unparse(node.test)})
                elif node.test.value is True:
                    findings.append({"type": "dead_else", "lineno": node.lineno, "snippet": ast.unparse(node.test)})
            self.generic_visit(node)

        def visit_While(self, node):
            if isinstance(node.test, ast.Constant) and node.test.value is False:
                findings.append({"type": "dead_while_false", "lineno": node.lineno})
            self.generic_visit(node)

        def visit_FunctionDef(self, node):
            # detect code after return in function body
            for i, stmt in enumerate(node.body):
                if isinstance(stmt, ast.Return):
                    for later in node.body[i+1:]:
                        findings.append({"type": "dead_after_return", "lineno": getattr(later, "lineno", None), "func": node.name})
            self.generic_visit(node)

        def visit_Assign(self, node):
            # naive assigned variable capture (we'll refine in unused)
            self.generic_visit(node)

    V().visit(tree)

    # Unused variables: track simple assignments and loads
    assigned = {}
    used = set()
    class U(ast.NodeVisitor):
        def visit_Assign(self, node):
            if len(node.targets) == 1 and isinstance(node.targets"*", ast.Name):
                assigned[node.targets"*".id] = getattr(node, "lineno", None)
            self.generic_visit(node)
        def visit_Name(self, node):
            if isinstance(node.ctx, ast.Load):
                used.add(node.id)
    U().visit(tree)
    for var, lineno in assigned.items():
        if var not in used:
            findings.append({"type": "unused_var", "var": var, "lineno": lineno})

    return findings


def clean_deadcode_python(code: str) -> List[Dict]:
    """
    Attempt to remove dead code in Python source.
    Returns list of changes: {"original":..., "cleaned":..., "reason":...}
    """
    results = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{"original": code, "cleaned": code, "reason": f"parse_error: {e}"}]

    remover = _DeadCodeRemover()
    new_tree, changes = remover.run(tree, code)
    # unparse new_tree (may be list when splicing body — handle carefully)
    try:
        cleaned_code = ast.unparse(new_tree) if not isinstance(new_tree, list) else "\n".join(ast.unparse(n) for n in new_tree)
    except Exception:
        # fallback: do not change
        cleaned_code = code

    for orig, cleaned, reason in changes:
        results.append({"original": orig, "cleaned": cleaned, "reason": reason})

    # Also remove simple unused assignments by regex (safe: only single-name assigns to literal)
    # e.g., `x = 4` where x not used — remove those lines if they exist exactly.
    # We already reported unused vars above; here perform textual removal for simple case.
    facts = detect_deadcode_python(code)
    for f in facts:
        if f.get("type") == "unused_var" and isinstance(f.get("lineno"), int):
            lines = cleaned_code.splitlines()
            idx = f["lineno"] - 1
            if 0 <= idx < len(lines):
                orig_line = lines[idx]
                # verify assignment pattern
                if re.match(r'^\s*' + re.escape(f["var"]) + r'\s*=\s*[^#\n]+', orig_line):
                    lines[idx] = ""  # remove
                    results.append({"original": orig_line + "\n", "cleaned": "", "reason": f"Removed unused assignment '{f['var']}'"})
                    cleaned_code = "\n".join(lines)
    # Return changes and cleaned code appended as last item
    results.append({"original": code, "cleaned": cleaned_code, "reason": "Full cleaned file (Python deadcode removal)"})
    return results


# --------------------------
# C-like regex helpers
# --------------------------
def detect_deadcode_clike(code: str, ext_tag: str = "C-like") -> List[Dict]:
    findings = []
    lines = code.splitlines()
    for i, line in enumerate(lines, start=1):
        if re.search(r'\bif\s*\(\s*(false|0)\s*\)', line, re.IGNORECASE):
            findings.append({"type": "dead_if_false", "lineno": i, "snippet": line.strip(), "lang": ext_tag})
        if re.search(r'\bwhile\s*\(\s*(false|0)\s*\)', line, re.IGNORECASE):
            findings.append({"type": "dead_while_false", "lineno": i, "snippet": line.strip(), "lang": ext_tag})
        if re.search(r'\breturn\b.*;', line) and i < len(lines) and lines[i].strip():
            findings.append({"type": "after_return", "lineno": i+1, "snippet": lines[i].strip(), "lang": ext_tag})
    return findings


def clean_deadcode_clike(code: str) -> List[Dict]:
    """
    Clean simple C-like dead code:
      - remove `
      - replace `{ ... }` with block contents (strip braces)
      - remove single-line unused var assignments that are literal and not used elsewhere (conservative)
    Returns list of changes
    """
    changes = []
    s = code

    # remove 
    pattern_false_block = re.compile(r'\bif\s*\(\s*(?:false|0)\s*\)\s*(\{(?:[^{}]*|\{[^}]*\})*\}|[^;]*;)', re.IGNORECASE | re.DOTALL)
    while True:
        m = pattern_false_block.search(s)
        if not m: break
        orig = m.group(0)
        s = s[:m.start()] + s[m.end():]
        changes.append({"original": orig, "cleaned": "", "reason": "

    # inline { block } => replace with block contents
    pattern_true_block = re.compile(r'\bif\s*\(\s*(?:true|1)\s*\)\s*(\{(?:[^{}]*|\{[^}]*\})*\}|[^;]*;)', re.IGNORECASE | re.DOTALL)
    while True:
        m = pattern_true_block.search(s)
        if not m: break
        orig = m.group(0)
        blk = m.group(1)
        # strip outer braces if present
        if blk.strip().startswith("{") and blk.strip().endswith("}"):
            inner = blk.strip()[1:-1]
        else:
            inner = blk
        s = s[:m.start()] + inner + s[m.end():]
        changes.append({"original": orig, "cleaned": inner, "reason": " inlined (kept body)"})

    # conservative removal of simple unused assignments: pattern `int x = 4;` only if var name does not appear elsewhere
    assign_pattern = re.compile(r'\b(?:int|long|char|float|double)\s+([A-Za-z_]\w*)\s*=\s*[^;]+;')
    for m in assign_pattern.finditer(s):
        var = m.group(1)
        # if var occurs only once (the definition), remove it
        if len(re.findall(r'\b' + re.escape(var) + r'\b', s)) == 1:
            orig = m.group(0)
            s = s[:m.start()] + s[m.end():]
            changes.append({"original": orig, "cleaned": "", "reason": f"Removed likely-unused declaration '{var}'"})

    changes.append({"original": code, "cleaned": s, "reason": "Full cleaned file (C-like deadcode removal)"})
    return changes
 -> """# Dead Code Test Cases

# 1. Unused variable
x = 10   # dead
y = 20
print(y)

# 2. If condition always True
print("Always runs")
else:
    print("Dead branch")

# 3. If condition always False
else:
    print("Always runs")

# 4. Code after return
def f1():
    return 5
    print("Dead")  # dead

# 5. Code after break
for i in range(3):
    break
    print("Dead")  # dead

# 6. Unreachable else
print("Run")
else:
    print("Dead")

# 7. While False loop
while False:
    print("Never runs")  # dead

# 8. Constant condition (0 is False)
if 0:
    print("Dead")
else:
    print("Runs")

# 9. Constant condition (non-zero is True)
if 1:
    print("Runs")
else:
    print("Dead")

# 10. Multiple returns
def f2(x):
    if x > 0:
        return 1
        print("Dead")  # dead
    else:
        return -1
"""

# analyzers/deadcode.py
import ast
import re
from typing import List, Dict, Tuple

# --------------------------
# Python (AST) helpers
# --------------------------
class _DeadCodeRemover(ast.NodeTransformer):
    """
    Transformations:
      - remove `
    def visit_If(self, node: ast.If):
        # evaluate constant tests only
        try:
            if isinstance(node.test, ast.Constant):
                val = node.test.value
                if val is False:
                    original = ast.get_source_segment(self.source_text, node) if hasattr(self, "source_text") else ast.unparse(node)
                    # remove the entire if-block
                    self.changes.append((original, "", "If condition is constant False (dead code)"))
                    return None  # remove node
                elif val is True:
                    # keep body in place of if
                    body_nodes = [self.visit(b) for b in node.body]
                    original = ast.get_source_segment(self.source_text, node) if hasattr(self, "source_text") else ast.unparse(node)
                    cleaned = "\n".join([ast.unparse(b) for b in body_nodes if b is not None])
                    self.changes.append((original, cleaned, "If condition is constant True (inlined body)"))
                    return body_nodes  # splice body
        except Exception:
        self.generic_visit(node)
        return node

    def run(self, tree: ast.AST, source_text: str):
        self.source_text = source_text
        new_tree = self.visit(tree)
        return new_tree, self.changes


def detect_deadcode_python(code: str) -> List[Dict]:
    """
    Detect dead-code patterns in Python source using AST scanning.
    Returns list of findings (simple descriptions and line numbers).
    """
    findings = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        findings.append({"type": "parse_error", "reason": str(e)})
        return findings

    # If/While constant tests
    class V(ast.NodeVisitor):
        def visit_If(self, node):
            if isinstance(node.test, ast.Constant):
                if node.test.value is False:
                    findings.append({"type": "dead_if_false", "lineno": node.lineno, "snippet": ast.unparse(node.test)})
                elif node.test.value is True:
                    findings.append({"type": "dead_else", "lineno": node.lineno, "snippet": ast.unparse(node.test)})
            self.generic_visit(node)

        def visit_While(self, node):
            if isinstance(node.test, ast.Constant) and node.test.value is False:
                findings.append({"type": "dead_while_false", "lineno": node.lineno})
            self.generic_visit(node)

        def visit_FunctionDef(self, node):
            # detect code after return in function body
            for i, stmt in enumerate(node.body):
                if isinstance(stmt, ast.Return):
                    for later in node.body[i+1:]:
                        findings.append({"type": "dead_after_return", "lineno": getattr(later, "lineno", None), "func": node.name})
            self.generic_visit(node)

        def visit_Assign(self, node):
            # naive assigned variable capture (we'll refine in unused)
            self.generic_visit(node)

    V().visit(tree)

    # Unused variables: track simple assignments and loads
    assigned = {}
    used = set()
    class U(ast.NodeVisitor):
        def visit_Assign(self, node):
            if len(node.targets) == 1 and isinstance(node.targets"*", ast.Name):
                assigned[node.targets"*".id] = getattr(node, "lineno", None)
            self.generic_visit(node)
        def visit_Name(self, node):
            if isinstance(node.ctx, ast.Load):
                used.add(node.id)
    U().visit(tree)
    for var, lineno in assigned.items():
        if var not in used:
            findings.append({"type": "unused_var", "var": var, "lineno": lineno})

    return findings


def clean_deadcode_python(code: str) -> List[Dict]:
    """
    Attempt to remove dead code in Python source.
    Returns list of changes: {"original":..., "cleaned":..., "reason":...}
    """
    results = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{"original": code, "cleaned": code, "reason": f"parse_error: {e}"}]

    remover = _DeadCodeRemover()
    new_tree, changes = remover.run(tree, code)
    # unparse new_tree (may be list when splicing body — handle carefully)
    try:
        cleaned_code = ast.unparse(new_tree) if not isinstance(new_tree, list) else "\n".join(ast.unparse(n) for n in new_tree)
    except Exception:
        # fallback: do not change
        cleaned_code = code

    for orig, cleaned, reason in changes:
        results.append({"original": orig, "cleaned": cleaned, "reason": reason})

    # Also remove simple unused assignments by regex (safe: only single-name assigns to literal)
    # e.g., `x = 4` where x not used — remove those lines if they exist exactly.
    # We already reported unused vars above; here perform textual removal for simple case.
    facts = detect_deadcode_python(code)
    for f in facts:
        if f.get("type") == "unused_var" and isinstance(f.get("lineno"), int):
            lines = cleaned_code.splitlines()
            idx = f["lineno"] - 1
            if 0 <= idx < len(lines):
                orig_line = lines[idx]
                # verify assignment pattern
                if re.match(r'^\s*' + re.escape(f["var"]) + r'\s*=\s*[^#\n]+', orig_line):
                    lines[idx] = ""  # remove
                    results.append({"original": orig_line + "\n", "cleaned": "", "reason": f"Removed unused assignment '{f['var']}'"})
                    cleaned_code = "\n".join(lines)
    # Return changes and cleaned code appended as last item
    results.append({"original": code, "cleaned": cleaned_code, "reason": "Full cleaned file (Python deadcode removal)"})
    return results


# --------------------------
# C-like regex helpers
# --------------------------
def detect_deadcode_clike(code: str, ext_tag: str = "C-like") -> List[Dict]:
    findings = []
    lines = code.splitlines()
    for i, line in enumerate(lines, start=1):
        if re.search(r'\bif\s*\(\s*(false|0)\s*\)', line, re.IGNORECASE):
            findings.append({"type": "dead_if_false", "lineno": i, "snippet": line.strip(), "lang": ext_tag})
        if re.search(r'\bwhile\s*\(\s*(false|0)\s*\)', line, re.IGNORECASE):
            findings.append({"type": "dead_while_false", "lineno": i, "snippet": line.strip(), "lang": ext_tag})
        if re.search(r'\breturn\b.*;', line) and i < len(lines) and lines[i].strip():
            findings.append({"type": "after_return", "lineno": i+1, "snippet": lines[i].strip(), "lang": ext_tag})
    return findings


def clean_deadcode_clike(code: str) -> List[Dict]:
    """
    Clean simple C-like dead code:
      - remove `
      - replace `{ ... }` with block contents (strip braces)
      - remove single-line unused var assignments that are literal and not used elsewhere (conservative)
    Returns list of changes
    """
    changes = []
    s = code

    # remove 
    pattern_false_block = re.compile(r'\bif\s*\(\s*(?:false|0)\s*\)\s*(\{(?:[^{}]*|\{[^}]*\})*\}|[^;]*;)', re.IGNORECASE | re.DOTALL)
    while True:
        m = pattern_false_block.search(s)
        if not m: break
        orig = m.group(0)
        s = s[:m.start()] + s[m.end():]
        changes.append({"original": orig, "cleaned": "", "reason": "

    # inline { block } => replace with block contents
    pattern_true_block = re.compile(r'\bif\s*\(\s*(?:true|1)\s*\)\s*(\{(?:[^{}]*|\{[^}]*\})*\}|[^;]*;)', re.IGNORECASE | re.DOTALL)
    while True:
        m = pattern_true_block.search(s)
        if not m: break
        orig = m.group(0)
        blk = m.group(1)
        # strip outer braces if present
        if blk.strip().startswith("{") and blk.strip().endswith("}"):
            inner = blk.strip()[1:-1]
        else:
            inner = blk
        s = s[:m.start()] + inner + s[m.end():]
        changes.append({"original": orig, "cleaned": inner, "reason": " inlined (kept body)"})

    # conservative removal of simple unused assignments: pattern `int x = 4;` only if var name does not appear elsewhere
    assign_pattern = re.compile(r'\b(?:int|long|char|float|double)\s+([A-Za-z_]\w*)\s*=\s*[^;]+;')
    for m in assign_pattern.finditer(s):
        var = m.group(1)
        # if var occurs only once (the definition), remove it
        if len(re.findall(r'\b' + re.escape(var) + r'\b', s)) == 1:
            orig = m.group(0)
            s = s[:m.start()] + s[m.end():]
            changes.append({"original": orig, "cleaned": "", "reason": f"Removed likely-unused declaration '{var}'"})

    changes.append({"original": code, "cleaned": s, "reason": "Full cleaned file (C-like deadcode removal)"})
    return changes
 (Removed redundant pass statements)
input\junkcode.py: """
Detect/remove junk code: NOPs, identity operations, redundant arithmetic, dead stores used only for obfuscation.
Conservative cleaning: only remove clear NOP-like constructs and no-op arithmetic on local vars not used in observable way.
"""
import re
from typing import List, Dict

def detect_junk_code_clike(code: str) -> List[Dict]:
    findings = []
    for m in re.finditer('\\basm\\s*\\(\\s*".*?nop.*?"\\s*\\)\\s*;', code, re.IGNORECASE | re.DOTALL):
        findings.append({'type': 'asm_nop', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*([+\\-\\*\\/])\\s*0\\b', code):
        findings.append({'type': 'identity_add_zero', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\*\\s*1\\b', code):
        findings.append({'type': 'identity_mul_one', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    lines = code.splitlines()
    for i in range(len(lines) - 1):
        a = lines[i].strip()
        b = lines[i + 1].strip()
        var1 = re.match('([A-Za-z_]\\w*)\\s*=\\s*[^;]+;', a)
        var2 = re.match('([A-Za-z_]\\w*)\\s*=\\s*[^;]+;', b)
        if var1 and var2 and (var1.group(1) == var2.group(1)):
            findings.append({'type': 'dead_store_sequence', 'lineno': i + 1, 'snippet': a + ' ' + b})
    return findings

def clean_junk_code_clike(code: str) -> List[Dict]:
    s = code
    changes = []
    s_new = re.sub('\\basm\\s*\\(\\s*".*?nop.*?"\\s*\\)\\s*;', '', s, flags=re.IGNORECASE | re.DOTALL)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed inline asm NOPs (C-like)'})
        s = s_new
    s_new = re.sub('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\+\\s*0\\s*;', '', s)
    s_new = re.sub('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\*\\s*1\\s*;', s_new)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed identity arithmetic (x = x + 0 / x = x * 1)'})
        s = s_new
    lines = s.splitlines()
    out_lines = []
    i = 0
    while i < len(lines):
        if i < len(lines) - 1:
            a = lines[i].strip()
            b = lines[i + 1].strip()
            var1 = re.match('([A-Za-z_]\\w*)\\s*=\\s*[^;]+;', a)
            var2 = re.match('([A-Za-z_]\\w*)\\s*=\\s*[^;]+;', b)
            if var1 and var2 and (var1.group(1) == var2.group(1)):
                changes.append({'original': a + '\n' + b + '\n', 'cleaned': b + '\n', 'reason': 'Removed redundant earlier store (dead store)'})
                out_lines.append(b)
                i += 2
                continue
        out_lines.append(lines[i])
        i += 1
    cleaned = '\n'.join(out_lines)
    if cleaned != code and (not changes):
        changes.append({'original': code, 'cleaned': cleaned, 'reason': 'Junk cleaning applied (C-like)'})
    elif cleaned != code:
        changes.append({'original': code, 'cleaned': cleaned, 'reason': 'Junk cleaning applied (C-like)'})
    return changes

def detect_junk_code_python(code: str) -> List[Dict]:
    findings = []
    for m in re.finditer('^\\s*pass\\s*$', code, re.MULTILINE):
        findings.append({'type': 'pass_stmt', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\+\\s*0\\b', code):
        findings.append({'type': 'identity_add_zero', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    return findings

def clean_junk_code_python(code: str) -> List[Dict]:
    s = code
    changes = []
    s_new = re.sub('^\\s*pass\\s*$(?:\\n)?', '', s, flags=re.MULTILINE)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed redundant pass statements'})
        s = s_new
    s_new = re.sub('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\+\\s*0\\b', '\\1 = \\1', s)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed identity addition (x = x + 0).'})
        s = s_new
    return changes -> """
Detect/remove junk code: NOPs, identity operations, redundant arithmetic, dead stores used only for obfuscation.
Conservative cleaning: only remove clear NOP-like constructs and no-op arithmetic on local vars not used in observable way.
"""
import re
from typing import List, Dict

def detect_junk_code_clike(code: str) -> List[Dict]:
    findings = []
    for m in re.finditer('\\basm\\s*\\(\\s*".*?nop.*?"\\s*\\)\\s*;', code, re.IGNORECASE | re.DOTALL):
        findings.append({'type': 'asm_nop', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*([+\\-\\*\\/])\\s*0\\b', code):
        findings.append({'type': 'identity_add_zero', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\*\\s*1\\b', code):
        findings.append({'type': 'identity_mul_one', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    lines = code.splitlines()
    for i in range(len(lines) - 1):
        a = lines[i].strip()
        b = lines[i + 1].strip()
        var1 = re.match('([A-Za-z_]\\w*)\\s*=\\s*[^;]+;', a)
        var2 = re.match('([A-Za-z_]\\w*)\\s*=\\s*[^;]+;', b)
        if var1 and var2 and (var1.group(1) == var2.group(1)):
            findings.append({'type': 'dead_store_sequence', 'lineno': i + 1, 'snippet': a + ' ' + b})
    return findings

def clean_junk_code_clike(code: str) -> List[Dict]:
    s = code
    changes = []
    s_new = re.sub('\\basm\\s*\\(\\s*".*?nop.*?"\\s*\\)\\s*;', '', s, flags=re.IGNORECASE | re.DOTALL)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed inline asm NOPs (C-like)'})
        s = s_new
    s_new = re.sub('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\+\\s*0\\s*;', '', s)
    s_new = re.sub('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\*\\s*1\\s*;', s_new)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed identity arithmetic (x = x / x = x * 1)'})
        s = s_new
    lines = s.splitlines()
    out_lines = []
    i = 0
    while i < len(lines):
        if i < len(lines) - 1:
            a = lines[i].strip()
            b = lines[i + 1].strip()
            var1 = re.match('([A-Za-z_]\\w*)\\s*=\\s*[^;]+;', a)
            var2 = re.match('([A-Za-z_]\\w*)\\s*=\\s*[^;]+;', b)
            if var1 and var2 and (var1.group(1) == var2.group(1)):
                changes.append({'original': a + '\n' + b + '\n', 'cleaned': b + '\n', 'reason': 'Removed redundant earlier store (dead store)'})
                out_lines.append(b)
                i += 2
                continue
        out_lines.append(lines[i])
        i += 1
    cleaned = '\n'.join(out_lines)
    if cleaned != code and (not changes):
        changes.append({'original': code, 'cleaned': cleaned, 'reason': 'Junk cleaning applied (C-like)'})
    elif cleaned != code:
        changes.append({'original': code, 'cleaned': cleaned, 'reason': 'Junk cleaning applied (C-like)'})
    return changes

def detect_junk_code_python(code: str) -> List[Dict]:
    findings = []
    for m in re.finditer('^\\s*pass\\s*$', code, re.MULTILINE):
        findings.append({'type': 'pass_stmt', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    for m in re.finditer('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\+\\s*0\\b', code):
        findings.append({'type': 'identity_add_zero', 'lineno': code[:m.start()].count('\n') + 1, 'snippet': m.group(0)})
    return findings

def clean_junk_code_python(code: str) -> List[Dict]:
    s = code
    changes = []
    s_new = re.sub('^\\s*pass\\s*$(?:\\n)?', '', s, flags=re.MULTILINE)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed redundant pass statements'})
        s = s_new
    s_new = re.sub('\\b([A-Za-z_]\\w*)\\s*=\\s*\\1\\s*\\+\\s*0\\b', '\\1 = \\1', s)
    if s_new != s:
        changes.append({'original': s, 'cleaned': s_new, 'reason': 'Removed identity addition (x = x).'})
        s = s_new
    return changes (Removed identity addition (x = x + 0).)
input\opaque_predicate.py: # Opaque Predicate Complex Test Cases

# 1. Always true with redundant check inside loop

"""for i in range(2):
    if (2 + 2 == 4) and (3 > 1):
        print("Loop always true:", i)

# 2. Always false predicate (never executes)
for j in range(3):
    if (5 < 2) or (10 < 3):
        print("This will never print", j)

# 3. Constant comparison with while loop
k = 0
while k < 2:
    if (100 == 100):
        print("While loop always true", k)
    k += 1

# 4. Arithmetic inside comparison
if (2 * 3 == 6) and (4 - 1 == 3):
    print("Inline arithmetic always true")

# 5. Complex but always true condition in function
def check_predicate():
    if (50 - 25 == 25) and (4**2 == 16):
        return "Function always true"
    return "Unreachable"

print(check_predicate())

# 6. Complex but false inside loop
for i in range(2):
    if (9 % 2 == 0) or (7 < 3):
        print("Never executes")

# 7. Nested opaque predicates
if ((10/2) == 5):
    if ((3*3) == 9):
        print("Nested always true")

# 8. Redundant always true inside loop
for i in range(2):
    if (8 > 3) and (2 < 5):
        print("Redundant always true", i)

# 9. Impossible opaque condition
if (1 == 2) or (0 > 10):
    print("Impossible branch")

# 10. Hidden constant compare inside function + loop
def hidden_check(x):
    if (x * 2 == 8) and (16/4 == 4):
        return True
    return False

for val in "./":
    if hidden_check(val):
        print("Hidden opaque true for", val)"""


# analyzers/opaque_predicate.py
import ast
import re
from typing import List, Dict

# Reuse the same safe AST evaluator from inline_expansion; to avoid circular import, copy minimal evaluator:
_ALLOWED_BINOPS = (ast.Add, ast.Sub, ast.Mult, ast.Div, ast.Mod, ast.Pow,
                   ast.LShift, ast.RShift, ast.BitAnd, ast.BitOr, ast.BitXor, ast.FloorDiv)
_ALLOWED_UNARYOPS = (ast.UAdd, ast.USub, ast.Invert)

def _eval_constant_ast(node):
    if isinstance(node, ast.Constant):
        return node.value
    if isinstance(node, ast.UnaryOp) and isinstance(node.op, _ALLOWED_UNARYOPS):
        val = _eval_constant_ast(node.operand)
        if isinstance(node.op, ast.UAdd): return +val
        if isinstance(node.op, ast.USub): return -val
        if isinstance(node.op, ast.Invert): return ~val
    if isinstance(node, ast.BinOp) and isinstance(node.op, _ALLOWED_BINOPS):
        L = _eval_constant_ast(node.left)
        R = _eval_constant_ast(node.right)
        op = node.op
        if isinstance(op, ast.Add): return L + R
        if isinstance(op, ast.Sub): return L - R
        if isinstance(op, ast.Mult): return L * R
        if isinstance(op, ast.Div): return L / R
        if isinstance(op, ast.FloorDiv): return L // R
        if isinstance(op, ast.Mod): return L % R
        if isinstance(op, ast.Pow): return L ** R
        if isinstance(op, ast.LShift): return L << R
        if isinstance(op, ast.RShift): return L >> R
        if isinstance(op, ast.BitAnd): return L & R
        if isinstance(op, ast.BitOr): return L | R
        if isinstance(op, ast.BitXor): return L ^ R
    if isinstance(node, ast.Compare):
        left = _eval_constant_ast(node.left)
        # single comparator supported
        comp = node.comparators"*"
        right = _eval_constant_ast(comp)
        op = node.ops"*"
        if isinstance(op, ast.Eq): return left == right
        if isinstance(op, ast.NotEq): return left != right
        if isinstance(op, ast.Lt): return left < right
        if isinstance(op, ast.LtE): return left <= right
        if isinstance(op, ast.Gt): return left > right
        if isinstance(op, ast.GtE): return left >= right
    if isinstance(node, ast.BoolOp):
        # evaluate values if possible
        values = [_eval_constant_ast(v) for v in node.values]
        if isinstance(node.op, ast.And):
            return all(values)
        else:
            return any(values)
    raise ValueError("Not constant-evaluable")

# ---------------- Python detection/cleaning ----------------
def detect_opaque_predicate_python(code: str) -> List[Dict]:
    findings = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{"type": "parse_error", "reason": str(e)}]
    class V(ast.NodeVisitor):
        def visit_If(self, node):
            # try to evaluate the test
            try:
                val = _eval_constant_ast(node.test)
                findings.append({"type": "opaque_always", "lineno": node.lineno, "value": bool(val), "expr": ast.unparse(node.test)})
            except Exception:
                # check for Compare with constant operands inside BoolOp
                if isinstance(node.test, ast.BoolOp):
                    for v in node.test.values:
                        if isinstance(v, ast.Compare):
                            left = v.left
                            if isinstance(left, ast.BinOp) and isinstance(left.left, ast.Constant) and isinstance(left.right, ast.Constant):
                                findings.append({"type": "opaque_arith", "lineno": node.lineno, "expr": ast.unparse(v)})
            self.generic_visit(node)
    V().visit(tree)
    return findings

def clean_opaque_predicate_python(code: str) -> List[Dict]:
    """
    Replace opaque predicates that evaluate to True with their body,
    remove those that evaluate to False.
    """
    results = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{"original": code, "cleaned": code, "reason": f"parse_error: {e}"}]

    class Transformer(ast.NodeTransformer):
        def __init__(self):
            self.changes = []
        def visit_If(self, node):
            # try eval test
            try:
                val = _eval_constant_ast(node.test)
                orig = ast.unparse(node)
                if bool(val):
                    # keep body (inline)
                    cleaned = "\n".join([ast.unparse(n) for n in node.body])
                    self.changes.append({"original": orig, "cleaned": cleaned, "reason": "Opaque predicate evaluated True -> inlined body"})
                    return node.body
                else:
                    # remove if entirely or keep else if present
                    cleaned = ""
                    if node.orelse:
                        cleaned = "\n".join([ast.unparse(n) for n in node.orelse])
                    self.changes.append({"original": orig, "cleaned": cleaned, "reason": "Opaque predicate evaluated False -> removed or replaced with else"})
                    # replace with else-body if exists
                    return node.orelse or []
            except Exception:
                return self.generic_visit(node)

    t = Transformer()
    new_tree = t.visit(tree)
    try:
        new_code = ast.unparse(new_tree)
    except Exception:
        new_code = code
    results.extend(t.changes)
    results.append({"original": code, "cleaned": new_code, "reason": "Full cleaned file (Python opaque predicate simplification)"})
    return results

# ---------------- C-like detection/cleaning (regex) ----------------
_cmp_re = re.compile(r'\b(\d+(?:\s*[\+\-\*\/]\s*\d+)*)\s*(==|!=|>|<|>=|<=)\s*(\d+(?:\s*[\+\-\*\/]\s*\d+)*)')

def _safe_eval_num_expr(expr: str):
    # only digits, whitespace, and operators allowed
    if not re.fullmatch(r'[0-9\+\-\*\/%\s\(\)]+', expr):
        raise ValueError("unsafe expr")
    # evaluate using Python integer math (floor division)
    # replace / with // for integer division
    expr2 = expr.replace('/', '//')
    return eval(expr2)

def detect_opaque_predicate_clike(code: str, lang="C-like") -> List[Dict]:
    findings = []
    for i, line in enumerate(code.splitlines(), start=1):
        for m in _cmp_re.finditer(line):
            left, op, right = m.groups()
            try:
                lv = _safe_eval_num_expr(left)
                rv = _safe_eval_num_expr(right)
                # compare
                ok = False
                if op == '==': ok = (lv == rv)
                elif op == '!=': ok = (lv != rv)
                elif op == '<': ok = (lv < rv)
                elif op == '<=': ok = (lv <= rv)
                elif op == '>': ok = (lv > rv)
                elif op == '>=': ok = (lv >= rv)
                findings.append({"type": "opaque_cmp_const", "lineno": i, "expr": m.group(0), "value": ok, "lang": lang})
            except Exception:
                findings.append({"type": "opaque_cmp_unknown", "lineno": i, "expr": m.group(0), "lang": lang})
    return findings

def clean_opaque_predicate_clike(code: str) -> List[Dict]:
    """
    For identified constant comparisons, attempt to simplify:
      - if condition is always true: replace `if(cond){block}else{else}` -> keep block
      - if always false: remove block or keep else
    Very conservative textual approach: only handles simple one-line if statements and braced blocks.
    """
    changes = []
    s = code
    # find simple if (...) { ... } else { ... } patterns with constant numeric comparisons inside parentheses
    if_pattern = re.compile(r'if\s*\(\s*([^\)]+)\s*\)\s*(\{(?:[^{}]|\{[^}]*\})*\}|[^\n;]*;)\s*(else\s*(\{(?:[^{}]|\{[^}]*\})*\}|[^\n;]*;))?', re.DOTALL)
    pos = 0
    while True:
        m = if_pattern.search(s, pos)
        if not m:
            break
        cond = m.group(1)
        body = m.group(2)
        else_part = m.group(3) or ""
        try:
            # attempt to evaluate cond if it's a simple arithmetic comparison
            mm = _cmp_re.search(cond)
            if mm:
                left, op, right = mm.groups()
                lv = _safe_eval_num_expr(left)
                rv = _safe_eval_num_expr(right)
                if op == '==': val = (lv == rv)
                elif op == '!=': val = (lv != rv)
                elif op == '<': val = (lv < rv)
                elif op == '<=': val = (lv <= rv)
                elif op == '>': val = (lv > rv)
                elif op == '>=': val = (lv >= rv)
                if val:
                    # keep body, remove if(...) and else
                    cleaned = body
                    changes.append({"original": m.group(0), "cleaned": cleaned, "reason": "Opaque condition evaluated True — inlined body"})
                    s = s[:m.start()] + cleaned + s[m.end():]
                    pos = m.start() + len(cleaned)
                    continue
                else:
                    # remove body, keep else if present
                    cleaned = else_part if else_part else ""
                    changes.append({"original": m.group(0), "cleaned": cleaned, "reason": "Opaque condition evaluated False — removed body / kept else"})
                    s = s[:m.start()] + cleaned + s[m.end():]
                    pos = m.start() + len(cleaned)
                    continue
        except Exception:
            pass
        pos = m.end()
    if changes:
        changes.append({"original": code, "cleaned": s, "reason": "Applied simple opaque predicate simplification (C-like)"})
    return changes
 -> # Opaque Predicate Complex Test Cases

# 1. Always true with redundant check inside loop

"""for i in range(2):
    if (2 + 2 == 4) and (3 > 1):
        print("Loop always true:", i)

# 2. Always false predicate (never executes)
for j in range(3):
    if (5 < 2) or (10 < 3):
        print("This will never print", j)

# 3. Constant comparison with while loop
k = 0
while k < 2:
    if (100 == 100):
        print("While loop always true", k)
    k += 1

# 4. Arithmetic inside comparison
if (2 * 3 == 6) and (4 - 1 == 3):
    print("Inline arithmetic always true")

# 5. Complex but always true condition in function
def check_predicate():
    if (50 - 25 == 25) and (4**2 == 16):
        return "Function always true"
    return "Unreachable"

print(check_predicate())

# 6. Complex but false inside loop
for i in range(2):
    if (9 % 2 == 0) or (7 < 3):
        print("Never executes")

# 7. Nested opaque predicates
if ((10/2) == 5):
    if ((3*3) == 9):
        print("Nested always true")

# 8. Redundant always true inside loop
for i in range(2):
    if (8 > 3) and (2 < 5):
        print("Redundant always true", i)

# 9. Impossible opaque condition
if (1 == 2) or (0 > 10):
    print("Impossible branch")

# 10. Hidden constant compare inside function + loop
def hidden_check(x):
    if (x * 2 == 8) and (16/4 == 4):
        return True
    return False

for val in "./":
    if hidden_check(val):
        print("Hidden opaque true for", val)"""


# analyzers/opaque_predicate.py
import ast
import re
from typing import List, Dict

# Reuse the same safe AST evaluator from inline_expansion; to avoid circular import, copy minimal evaluator:
_ALLOWED_BINOPS = (ast.Add, ast.Sub, ast.Mult, ast.Div, ast.Mod, ast.Pow,
                   ast.LShift, ast.RShift, ast.BitAnd, ast.BitOr, ast.BitXor, ast.FloorDiv)
_ALLOWED_UNARYOPS = (ast.UAdd, ast.USub, ast.Invert)

def _eval_constant_ast(node):
    if isinstance(node, ast.Constant):
        return node.value
    if isinstance(node, ast.UnaryOp) and isinstance(node.op, _ALLOWED_UNARYOPS):
        val = _eval_constant_ast(node.operand)
        if isinstance(node.op, ast.UAdd): return +val
        if isinstance(node.op, ast.USub): return -val
        if isinstance(node.op, ast.Invert): return ~val
    if isinstance(node, ast.BinOp) and isinstance(node.op, _ALLOWED_BINOPS):
        L = _eval_constant_ast(node.left)
        R = _eval_constant_ast(node.right)
        op = node.op
        if isinstance(op, ast.Add): return L + R
        if isinstance(op, ast.Sub): return L - R
        if isinstance(op, ast.Mult): return L * R
        if isinstance(op, ast.Div): return L / R
        if isinstance(op, ast.FloorDiv): return L // R
        if isinstance(op, ast.Mod): return L % R
        if isinstance(op, ast.Pow): return L ** R
        if isinstance(op, ast.LShift): return L << R
        if isinstance(op, ast.RShift): return L >> R
        if isinstance(op, ast.BitAnd): return L & R
        if isinstance(op, ast.BitOr): return L | R
        if isinstance(op, ast.BitXor): return L ^ R
    if isinstance(node, ast.Compare):
        left = _eval_constant_ast(node.left)
        # single comparator supported
        comp = node.comparators"*"
        right = _eval_constant_ast(comp)
        op = node.ops"*"
        if isinstance(op, ast.Eq): return left == right
        if isinstance(op, ast.NotEq): return left != right
        if isinstance(op, ast.Lt): return left < right
        if isinstance(op, ast.LtE): return left <= right
        if isinstance(op, ast.Gt): return left > right
        if isinstance(op, ast.GtE): return left >= right
    if isinstance(node, ast.BoolOp):
        # evaluate values if possible
        values = [_eval_constant_ast(v) for v in node.values]
        if isinstance(node.op, ast.And):
            return all(values)
        else:
            return any(values)
    raise ValueError("Not constant-evaluable")

# ---------------- Python detection/cleaning ----------------
def detect_opaque_predicate_python(code: str) -> List[Dict]:
    findings = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{"type": "parse_error", "reason": str(e)}]
    class V(ast.NodeVisitor):
        def visit_If(self, node):
            # try to evaluate the test
            try:
                val = _eval_constant_ast(node.test)
                findings.append({"type": "opaque_always", "lineno": node.lineno, "value": bool(val), "expr": ast.unparse(node.test)})
            except Exception:
                # check for Compare with constant operands inside BoolOp
                if isinstance(node.test, ast.BoolOp):
                    for v in node.test.values:
                        if isinstance(v, ast.Compare):
                            left = v.left
                            if isinstance(left, ast.BinOp) and isinstance(left.left, ast.Constant) and isinstance(left.right, ast.Constant):
                                findings.append({"type": "opaque_arith", "lineno": node.lineno, "expr": ast.unparse(v)})
            self.generic_visit(node)
    V().visit(tree)
    return findings

def clean_opaque_predicate_python(code: str) -> List[Dict]:
    """
    Replace opaque predicates that evaluate to True with their body,
    remove those that evaluate to False.
    """
    results = []
    try:
        tree = ast.parse(code)
    except Exception as e:
        return [{"original": code, "cleaned": code, "reason": f"parse_error: {e}"}]

    class Transformer(ast.NodeTransformer):
        def __init__(self):
            self.changes = []
        def visit_If(self, node):
            # try eval test
            try:
                val = _eval_constant_ast(node.test)
                orig = ast.unparse(node)
                if bool(val):
                    # keep body (inline)
                    cleaned = "\n".join([ast.unparse(n) for n in node.body])
                    self.changes.append({"original": orig, "cleaned": cleaned, "reason": "Opaque predicate evaluated True -> inlined body"})
                    return node.body
                else:
                    # remove if entirely or keep else if present
                    cleaned = ""
                    if node.orelse:
                        cleaned = "\n".join([ast.unparse(n) for n in node.orelse])
                    self.changes.append({"original": orig, "cleaned": cleaned, "reason": "Opaque predicate evaluated False -> removed or replaced with else"})
                    # replace with else-body if exists
                    return node.orelse or []
            except Exception:
                return self.generic_visit(node)

    t = Transformer()
    new_tree = t.visit(tree)
    try:
        new_code = ast.unparse(new_tree)
    except Exception:
        new_code = code
    results.extend(t.changes)
    results.append({"original": code, "cleaned": new_code, "reason": "Full cleaned file (Python opaque predicate simplification)"})
    return results

# ---------------- C-like detection/cleaning (regex) ----------------
_cmp_re = re.compile(r'\b(\d+(?:\s*[\+\-\*\/]\s*\d+)*)\s*(==|!=|>|<|>=|<=)\s*(\d+(?:\s*[\+\-\*\/]\s*\d+)*)')

def _safe_eval_num_expr(expr: str):
    # only digits, whitespace, and operators allowed
    if not re.fullmatch(r'[0-9\+\-\*\/%\s\(\)]+', expr):
        raise ValueError("unsafe expr")
    # evaluate using Python integer math (floor division)
    # replace / with // for integer division
    expr2 = expr.replace('/', '//')
    return eval(expr2)

def detect_opaque_predicate_clike(code: str, lang="C-like") -> List[Dict]:
    findings = []
    for i, line in enumerate(code.splitlines(), start=1):
        for m in _cmp_re.finditer(line):
            left, op, right = m.groups()
            try:
                lv = _safe_eval_num_expr(left)
                rv = _safe_eval_num_expr(right)
                # compare
                ok = False
                if op == '==': ok = (lv == rv)
                elif op == '!=': ok = (lv != rv)
                elif op == '<': ok = (lv < rv)
                elif op == '<=': ok = (lv <= rv)
                elif op == '>': ok = (lv > rv)
                elif op == '>=': ok = (lv >= rv)
                findings.append({"type": "opaque_cmp_const", "lineno": i, "expr": m.group(0), "value": ok, "lang": lang})
            except Exception:
                findings.append({"type": "opaque_cmp_unknown", "lineno": i, "expr": m.group(0), "lang": lang})
    return findings

def clean_opaque_predicate_clike(code: str) -> List[Dict]:
    """
    For identified constant comparisons, attempt to simplify:
      - if condition is always true: replace `if(cond){block}else{else}` -> keep block
      - if always false: remove block or keep else
    Very conservative textual approach: only handles simple one-line if statements and braced blocks.
    """
    changes = []
    s = code
    # find simple if (...) { ... } else { ... } patterns with constant numeric comparisons inside parentheses
    if_pattern = re.compile(r'if\s*\(\s*([^\)]+)\s*\)\s*(\{(?:[^{}]|\{[^}]*\})*\}|[^\n;]*;)\s*(else\s*(\{(?:[^{}]|\{[^}]*\})*\}|[^\n;]*;))?', re.DOTALL)
    pos = 0
    while True:
        m = if_pattern.search(s, pos)
        if not m:
            break
        cond = m.group(1)
        body = m.group(2)
        else_part = m.group(3) or ""
        try:
            # attempt to evaluate cond if it's a simple arithmetic comparison
            mm = _cmp_re.search(cond)
            if mm:
                left, op, right = mm.groups()
                lv = _safe_eval_num_expr(left)
                rv = _safe_eval_num_expr(right)
                if op == '==': val = (lv == rv)
                elif op == '!=': val = (lv != rv)
                elif op == '<': val = (lv < rv)
                elif op == '<=': val = (lv <= rv)
                elif op == '>': val = (lv > rv)
                elif op == '>=': val = (lv >= rv)
                if val:
                    # keep body, remove if(...) and else
                    cleaned = body
                    changes.append({"original": m.group(0), "cleaned": cleaned, "reason": "Opaque condition evaluated True — inlined body"})
                    s = s[:m.start()] + cleaned + s[m.end():]
                    pos = m.start() + len(cleaned)
                    continue
                else:
                    # remove body, keep else if present
                    cleaned = else_part if else_part else ""
                    changes.append({"original": m.group(0), "cleaned": cleaned, "reason": "Opaque condition evaluated False — removed body / kept else"})
                    s = s[:m.start()] + cleaned + s[m.end():]
                    pos = m.start() + len(cleaned)
                    continue
        except Exception:
        pos = m.end()
    if changes:
        changes.append({"original": code, "cleaned": s, "reason": "Applied simple opaque predicate simplification (C-like)"})
    return changes
 (Removed redundant pass statements)



===== API Redirection =====

No cases detected.



===== Mixed Language Obfuscation =====

No cases detected.

